#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡å…¨é¢æ•°æ®é‡‡é›†å™¨ - è½®è¯¢å¤šæ•°æ®æº
æ”¯æŒ Tushareã€akshareã€yfinanceã€è…¾è®¯è´¢ç»ç­‰å¤šä¸ªæ•°æ®æº
æ¯æ¬¡é‡‡é›†10åªè‚¡ç¥¨ï¼Œé¿å…è§¦å‘æ¥å£é™åˆ¶ï¼Œæ’é™¤åˆ›ä¸šæ¿
"""

import json
import os
import time
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

# å°è¯•å¯¼å…¥è·¯å¾„é…ç½®
try:
    import path_config
    HAS_PATH_CONFIG = True
except ImportError:
    HAS_PATH_CONFIG = False

# æ•°æ®æºå¯ç”¨æ€§æ£€æŸ¥
try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
    AKSHARE_CONNECTED = True  # ğŸ”´ ä¿®å¤ï¼šå‡è®¾å·²å®‰è£…çš„akshareæ˜¯å¯ç”¨çš„
    print("[INFO] akshare å·²åŠ è½½")
except ImportError:
    AKSHARE_AVAILABLE = False
    AKSHARE_CONNECTED = False
    print("[WARN] akshare æœªå®‰è£…")

try:
    import tushare as ts
    TUSHARE_AVAILABLE = True
    print("[INFO] tushare å·²åŠ è½½")
except ImportError:
    TUSHARE_AVAILABLE = False
    print("[WARN] tushare æœªå®‰è£…")

try:
    import yfinance as yf

    # ğŸ”´ å¼ºåˆ¶ç¦ç”¨yfinanceï¼ˆä¸­å›½ç½‘ç»œä¸ç¨³å®šä¸”é¢‘ç‡é™åˆ¶ä¸¥æ ¼ï¼‰
    YFINANCE_AVAILABLE = False
    print("[INFO] yfinance å·²ç¦ç”¨ï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼Œä½¿ç”¨å›½å†…æ•°æ®æºï¼‰")
except ImportError:
    YFINANCE_AVAILABLE = False
    print("[WARN] yfinance æœªå®‰è£…")

try:
    import requests
    REQUESTS_AVAILABLE = True
    print("[INFO] requests å·²åŠ è½½")
except ImportError:
    REQUESTS_AVAILABLE = False
    print("[WARN] requests æœªå®‰è£…")

try:
    from jina_api import JinaAPI
    JINA_AVAILABLE = True
    print("[INFO] JinaAPI å·²åŠ è½½")
except ImportError:
    JINA_AVAILABLE = False
    print("[WARN] JinaAPI æœªåŠ è½½")

# JoinQuant API æ”¯æŒ
try:
    from joinquant_api import JoinQuantAPI
    JOINQUANT_AVAILABLE = True
    print("[INFO] JoinQuant API å·²åŠ è½½")
except ImportError:
    JOINQUANT_AVAILABLE = False
    print("[WARN] JoinQuant API æœªæ‰¾åˆ°")

# Alpha Vantage API æ”¯æŒ
try:
    from alpha_vantage_api import AlphaVantageAPI
    ALPHA_VANTAGE_AVAILABLE = True
    ALPHA_VANTAGE_API_KEY = "52N6YLT15MUAA46B"
    print("[INFO] Alpha Vantage API å·²åŠ è½½")
except ImportError:
    ALPHA_VANTAGE_AVAILABLE = False
    print("[WARN] Alpha Vantage API æœªæ‰¾åˆ°")

# Polygon.io API æ”¯æŒ
try:
    from polygon_api import PolygonAPI
    POLYGON_AVAILABLE = True
    print("[INFO] Polygon.io API å·²åŠ è½½")
except ImportError:
    POLYGON_AVAILABLE = False
    print("[WARN] Polygon.io API æœªå®‰è£…")

# è…¾è®¯Kçº¿APIæ”¯æŒ
try:
    from tencent_kline_api import TencentKlineAPI
    TENCENT_KLINE_AVAILABLE = True
    print("[INFO] è…¾è®¯Kçº¿API å·²åŠ è½½")
except ImportError:
    TENCENT_KLINE_AVAILABLE = False
    print("[WARN] è…¾è®¯Kçº¿API æœªæ‰¾åˆ°")

# æ–°æµªKçº¿APIæ”¯æŒ
try:
    from sina_kline_api import SinaKLineAPI
    SINA_KLINE_AVAILABLE = True
    print("[INFO] æ–°æµªKçº¿API å·²åŠ è½½")
except ImportError:
    SINA_KLINE_AVAILABLE = False
    print("[WARN] æ–°æµªKçº¿API æœªæ‰¾åˆ°")

# BaoStock API æ”¯æŒï¼ˆå…è´¹Kçº¿æ•°æ®å…œåº•ï¼‰
try:
    from TradingShared.api.baostock_api import BaoStockAPI
    BAOSTOCK_AVAILABLE = True
    print("[INFO] BaoStock API å·²åŠ è½½")
except ImportError:
    try:
        # å›é€€åˆ°ç›¸å¯¹å¯¼å…¥
        from baostock_api import BaoStockAPI
        BAOSTOCK_AVAILABLE = True
        print("[INFO] BaoStock API å·²åŠ è½½")
    except ImportError:
        BAOSTOCK_AVAILABLE = False
        print("[WARN] BaoStock API æœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…: pip install baostock")

# è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨
try:
    from TradingShared.api.stock_status_checker import StockStatusChecker
    STOCK_STATUS_CHECKER_AVAILABLE = True
    print("[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨å·²åŠ è½½")
except ImportError:
    try:
        from stock_status_checker import StockStatusChecker
        STOCK_STATUS_CHECKER_AVAILABLE = True
        print("[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨å·²åŠ è½½")
    except ImportError:
        STOCK_STATUS_CHECKER_AVAILABLE = False
        print("[WARN] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨æœªæ‰¾åˆ°")

# Choiceé‡‘èç»ˆç«¯
try:
    from config import (CHOICE_PASSWORD, CHOICE_USERNAME, ENABLE_CHOICE,
                        TUSHARE_TOKEN)
except ImportError:
    ENABLE_CHOICE = False
    CHOICE_USERNAME = ""
    CHOICE_PASSWORD = ""
    TUSHARE_TOKEN = "4a1bd8dea786a5525663fafcf729a2b081f9f66145a0671c8adf2f28"
    print("[WARN] Choice/Tushareé…ç½®æœªæ‰¾åˆ°")

print(f"[INFO] BaoStockåˆ†æ: å…è´¹ç¨³å®šçš„Aè‚¡Kçº¿æ•°æ®æºï¼Œä½œä¸ºæœ€ç»ˆå…œåº•æ–¹æ¡ˆï¼š")
print(f"       - Kçº¿æ•°æ®: å…è´¹ç¨³å®šï¼ˆæ—¥Kçº¿ï¼‰")
print(f"       - å†å²æ•°æ®: è¦†ç›–å…¨é¢ï¼ˆAè‚¡å…¨å¸‚åœºï¼‰")
print(f"       - å®æ—¶æ€§: é€‚åˆå†å²åˆ†æï¼Œéå®æ—¶")
print(f"       - ä½¿ç”¨é™åˆ¶: å…è´¹ï¼Œä½†æœ‰é¢‘ç‡é™åˆ¶")
print(f"       - å»ºè®®è§’è‰²: Kçº¿æ•°æ®çš„æœ€ç»ˆå…œåº•æ–¹æ¡ˆ")


class DateTimeEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†æ—¥æœŸå’Œæ—¶é—´å¯¹è±¡"""
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        return super().default(obj)
    
    @staticmethod
    def clean_data_for_json(data):
        """æ¸…ç†æ•°æ®ä¸­çš„ä¸å¯åºåˆ—åŒ–å¯¹è±¡"""
        if isinstance(data, dict):
            return {k: DateTimeEncoder.clean_data_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [DateTimeEncoder.clean_data_for_json(item) for item in data]
        elif isinstance(data, (datetime, date)):
            return data.isoformat()
        elif isinstance(data, pd.Timestamp):
            return data.isoformat()
        elif hasattr(data, 'dtype') and 'int' in str(data.dtype):
            return int(data)
        elif hasattr(data, 'dtype') and 'float' in str(data.dtype):
            return float(data)
        elif isinstance(data, np.ndarray):
            return data.tolist()
        elif pd.isna(data):
            return None
        else:
            return data

class ComprehensiveDataCollector:
    """å…¨é¢æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, use_choice=None):
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå…¶æ¬¡ä» config.py è·å–ï¼Œæœ€åä½¿ç”¨ç¡¬ç¼–ç å…œåº•
        self.tushare_token = os.environ.get('TUSHARE_TOKEN', TUSHARE_TOKEN)
        self.data_sources = ['tushare', 'baostock', 'yfinance', 'tencent', 'akshare']  # ç§»é™¤choice API
        self.current_source_index = 0
        self.use_choice = use_choice  # æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨æˆ–ç¦ç”¨Choiceæ•°æ®æº
        
        # åˆå§‹åŒ–è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨
        self.status_checker = None
        if STOCK_STATUS_CHECKER_AVAILABLE:
            try:
                self.status_checker = StockStatusChecker(self.tushare_token)
                print("[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ç­‰å¾…æœŸé—´æ•°æ®æºç­–ç•¥
        self.wait_period_strategy = {
            'industry_concept': ['baostock', 'akshare'],  # è¡Œä¸šæ¦‚å¿µæ•°æ®ä¼˜å…ˆä½¿ç”¨baostock
            'financial_data': ['tencent', 'baostock', 'akshare'],   # è´¢åŠ¡æ•°æ®ï¼šè…¾è®¯â†’baostockâ†’akshare  
            'basic_info': ['tencent', 'yfinance', 'baostock', 'jina'], # åŸºç¡€ä¿¡æ¯ï¼šè…¾è®¯â†’yfinanceâ†’baostockâ†’jina
            'fund_flow': ['tencent', 'akshare']          # èµ„é‡‘æµå‘ä½¿ç”¨è…¾è®¯/akshare
        }
        self.collected_data = {}
        
        # ä½¿ç”¨ç»Ÿä¸€çš„è·¯å¾„é…ç½® - ä¼˜å…ˆå®šä½ TradingShared/data
        data_dir = None
        try:
            # 1. ä¼˜å…ˆä½¿ç”¨ path_config
            if HAS_PATH_CONFIG and hasattr(path_config, 'DATA_DIR'):
                data_dir = path_config.DATA_DIR
                print(f"[INFO] ä½¿ç”¨ path_config å®šä½æ•°æ®ç›®å½•: {data_dir}")
            
            # 2. å¦‚æœ path_config ä¸å¯ç”¨ï¼Œå°è¯•åŸºäºå½“å‰æ–‡ä»¶è·¯å¾„å®šä½
            if not data_dir or not os.path.exists(data_dir):
                # å½“å‰æ–‡ä»¶åœ¨ TradingShared/api/comprehensive_data_collector.py
                api_dir = os.path.dirname(os.path.abspath(__file__))
                shared_root = os.path.dirname(api_dir)
                potential_data_dir = os.path.join(shared_root, 'data')
                
                if os.path.exists(potential_data_dir):
                    data_dir = potential_data_dir
                    print(f"[INFO] åŸºäºæ–‡ä»¶è·¯å¾„å®šä½æ•°æ®ç›®å½•: {data_dir}")
            
            # 3. å°è¯•ç›¸å¯¹äºå·¥ä½œç›®å½•å®šä½
            if not data_dir or not os.path.exists(data_dir):
                cwd = os.getcwd()
                # æ£€æŸ¥ TradingShared/data
                potential_data_dir = os.path.join(cwd, 'TradingShared', 'data')
                if os.path.exists(potential_data_dir):
                    data_dir = potential_data_dir
                    print(f"[INFO] åŸºäºå·¥ä½œç›®å½•å®šä½æ•°æ®ç›®å½•: {data_dir}")
            
            if data_dir and os.path.exists(data_dir):
                self.output_file = os.path.join(data_dir, 'comprehensive_stock_data.json')
            else:
                # å›é€€åˆ° root/data (ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•)
                self.output_file = os.path.abspath('data/comprehensive_stock_data.json')
                print(f"[WARN] æœªæ‰¾åˆ°å…±äº«æ•°æ®ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {self.output_file}")
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(self.output_file), exist_ok=True)
                
        except Exception as e:
            print(f"[WARN] è·¯å¾„å®šä½å¤±è´¥: {e}")
            self.output_file = os.path.abspath('data/comprehensive_stock_data.json')
        
        # æ‰¹é‡Kçº¿æ•°æ®é‡‡é›†ç›¸å…³é…ç½®ï¼ˆåŸºäºæµ‹è¯•ä¼˜åŒ–ï¼‰
        self.batch_kline_cache = {}  # ç¼“å­˜æ‰¹é‡è·å–çš„Kçº¿æ•°æ®
        self.kline_batch_size = 15   # æ¯æ¬¡æ‰¹é‡è·å–15åªè‚¡ç¥¨ï¼ˆ100%æˆåŠŸç‡ï¼‰
        self.kline_batch_size_max = 20  # æœ€å¤§æ‰¹é‡20åªè‚¡ç¥¨ï¼ˆ75%æˆåŠŸç‡ä½†æ›´å¿«ï¼‰
        self.kline_days = 60         # è·å–60å¤©çš„Kçº¿æ•°æ®ï¼ˆç”¨äºMA60ç­‰æŒ‡æ ‡ï¼‰
        self.last_tushare_call = 0   # ä¸Šæ¬¡tushareè°ƒç”¨æ—¶é—´
        self.adaptive_batch = True   # å¯ç”¨è‡ªé€‚åº”æ‰¹é‡å¤§å°
        
        # ç­‰å¾…æœŸé—´æ•°æ®æ”¶é›†ä¼˜åŒ–
        self.wait_period_data = {}   # åœ¨ç­‰å¾…æœŸé—´æ”¶é›†çš„å…¶ä»–æ•°æ®
        self.enable_wait_period_collection = True  # å¯ç”¨ç­‰å¾…æœŸé—´æ•°æ®æ”¶é›†
        
        # Kçº¿æ•°æ®æ”¶é›†ç­–ç•¥ä¼˜åŒ–
        self.kline_sources = ['tushare', 'yfinance']  # Kçº¿æ•°æ®æºè½®æ¢
        self.current_kline_source_index = 0
        self.last_yfinance_call = 0  # ä¸Šæ¬¡yfinanceè°ƒç”¨æ—¶é—´
        self.yfinance_wait_seconds = 120  # yfinanceç­‰å¾…æ—¶é—´(2åˆ†é’Ÿ)
        
        # APIè½®æ¢ç›¸å…³åˆå§‹åŒ–
        self.last_api_switch_time = 0
        self.api_rotation_index = 0
        
        # AKShareåŠ¨æ€ç›‘æ§æœºåˆ¶
        self.akshare_call_count = 0      # AKShareè°ƒç”¨æ¬¡æ•°
        self.akshare_success_count = 0   # AKShareæˆåŠŸæ¬¡æ•°
        self.akshare_fail_count = 0      # AKShareå¤±è´¥æ¬¡æ•°
        self.akshare_enabled = AKSHARE_AVAILABLE  # AKShareæ˜¯å¦å¯ç”¨
        
        # åˆå§‹åŒ– tushare
        if TUSHARE_AVAILABLE and self.tushare_token:
            try:
                ts.set_token(self.tushare_token)
                self.ts_pro = ts.pro_api()
                print("[INFO] tushare åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] tushare åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ– JoinQuant API
        self.joinquant = None
        if JOINQUANT_AVAILABLE:
            try:
                self.joinquant = JoinQuantAPI()
                print("[INFO] JoinQuant API åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] JoinQuant API åˆå§‹åŒ–å¤±è´¥: {e}")

        # åˆå§‹åŒ– Jina API
        self.jina_api_key = "YOUR_JINA_API_KEY" # è¯·æ›¿æ¢ä¸ºå®é™…çš„API Key
        self.jina_api = JinaAPI(self.jina_api_key) if JINA_AVAILABLE else None
        if self.jina_api:
            print("[INFO] JinaAPI åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ– Baostock API
        self.bs_login = False
        self.baostock = None  # ğŸ”´ ä¿®å¤ï¼šç¡®ä¿å±æ€§å§‹ç»ˆå­˜åœ¨
        if BAOSTOCK_AVAILABLE:
            try:
                self.baostock = BaoStockAPI()
                if self.baostock.is_connected:
                    print("[INFO] BaoStock API åˆå§‹åŒ–æˆåŠŸï¼ˆKçº¿æ•°æ®å…œåº•ï¼‰")
                    self.bs_login = True
                else:
                    print("[WARN] BaoStock API è¿æ¥å¤±è´¥")
                    self.baostock = None
            except Exception as e:
                print(f"[WARN] BaoStock API åˆå§‹åŒ–å¤±è´¥: {e}")
                self.baostock = None
        else:
            print("[INFO] BaoStock ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
        
        # åˆå§‹åŒ– Tencent Kline API
        self.tencent_kline = None
        if TENCENT_KLINE_AVAILABLE:
            try:
                self.tencent_kline = TencentKlineAPI()
                print("[INFO] è…¾è®¯Kçº¿API åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] è…¾è®¯Kçº¿API åˆå§‹åŒ–å¤±è´¥: {e}")

        # åˆå§‹åŒ– Sina Kline API
        self.sina_kline = None
        if SINA_KLINE_AVAILABLE:
            try:
                self.sina_kline = SinaKLineAPI()
                print("[INFO] æ–°æµªKçº¿API åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] æ–°æµªKçº¿API åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ– Alpha Vantage API
        self.alpha_vantage = None
        if ALPHA_VANTAGE_AVAILABLE:
            try:
                self.alpha_vantage = AlphaVantageAPI(ALPHA_VANTAGE_API_KEY)
                print("[INFO] Alpha Vantage API åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] Alpha Vantage API åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ– Polygon API
        self.polygon = None
        if POLYGON_AVAILABLE:
            try:
                self.polygon = PolygonAPI()
                print("[INFO] Polygon API åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[WARN] Polygon API åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if STOCK_STATUS_CHECKER_AVAILABLE:
            try:
                self.status_checker = StockStatusChecker()
                print("[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨å·²åˆå§‹åŒ–")
            except Exception as e:
                print(f"[WARN] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.status_checker = None
        else:
            self.status_checker = None
            print("[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.output_file), exist_ok=True)
        
        # ä¸åœ¨åˆå§‹åŒ–æ—¶æµ‹è¯•AKShareï¼Œæ”¹ä¸ºåŠ¨æ€ç›‘æ§
        if AKSHARE_AVAILABLE:
            print("[INFO] AKShareå¯ç”¨ï¼Œå°†åœ¨å®é™…ä½¿ç”¨ä¸­åŠ¨æ€ç›‘æ§å…¶æˆåŠŸç‡")
    
    def _get_next_api(self):
        """
        APIè½®æ¢é€‰æ‹©å™¨ - é¿å…Alpha Vantageçš„12ç§’ç­‰å¾…
        åœ¨Alpha Vantageå’ŒPolygon.ioä¹‹é—´è½®æ¢ä½¿ç”¨
        """
        current_time = time.time()
        
        # å¦‚æœè·ç¦»ä¸Šæ¬¡åˆ‡æ¢å·²ç»è¿‡äº†è¶³å¤Ÿæ—¶é—´ï¼Œå¯ä»¥åˆ‡æ¢API
        if current_time - self.last_api_switch_time > 1:  # 1ç§’é—´éš”åˆ‡æ¢
            self.api_rotation_index = 1 - self.api_rotation_index  # 0<->1 åˆ‡æ¢
            self.last_api_switch_time = current_time
            print(f"[DEBUG] APIè½®æ¢åˆ‡æ¢åˆ°ç´¢å¼•: {self.api_rotation_index}")
            
        # è¿”å›å½“å‰é€‰æ‹©çš„API
        if self.api_rotation_index == 0 and self.alpha_vantage:
            return 'alpha_vantage', self.alpha_vantage
        elif self.api_rotation_index == 1 and self.polygon and self.polygon.is_available:
            return 'polygon', self.polygon
        
        # å¦‚æœé¦–é€‰APIä¸å¯ç”¨ï¼Œå°è¯•å¦ä¸€ä¸ª
        if self.alpha_vantage:
            return 'alpha_vantage', self.alpha_vantage
        elif self.polygon and self.polygon.is_available:
            return 'polygon', self.polygon
        
        return None, None
    
    def _is_us_stock(self, code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç¾è‚¡ä»£ç """
        if not code:
            return False
            
        # ç¾è‚¡ä»£ç é€šå¸¸æ˜¯å­—æ¯ç»„åˆ
        if code.isalpha() and len(code) >= 1:
            return True
        
        # æ’é™¤æ˜æ˜¾çš„Aè‚¡ä»£ç æ ¼å¼
        if code.isdigit() and len(code) == 6:
            return False
            
        # åŒ…å«.çš„å¯èƒ½æ˜¯ç¾è‚¡æˆ–å…¶ä»–å¸‚åœº
        if '.' in code:
            return True
            
        return False
    
    def _detect_market(self, code: str) -> str:
        """
        æ£€æµ‹è‚¡ç¥¨ä»£ç æ‰€å±å¸‚åœº
        
        Returns:
            'cn': ä¸­å›½Aè‚¡
            'us': ç¾è‚¡
            'other': å…¶ä»–å¸‚åœº
        """
        if not code:
            return 'other'
        
        code = code.upper().strip()
        
        # Aè‚¡ä»£ç æ¨¡å¼ï¼š6ä½æ•°å­—
        if code.isdigit() and len(code) == 6:
            return 'cn'
        
        # å¸¦äº¤æ˜“æ‰€åç¼€çš„ä»£ç 
        if '.' in code:
            base_code, suffix = code.split('.', 1)
            suffix = suffix.upper()
            if suffix in ['SS', 'SZ', 'HK']:  # ä¸Šäº¤æ‰€ã€æ·±äº¤æ‰€ã€æ¸¯äº¤æ‰€
                return 'cn'
            elif suffix in ['US', 'NASDAQ', 'NYSE']:  # ç¾è‚¡
                return 'us'
            # å¦‚æœåç¼€ä¸æ˜ç¡®ï¼Œç»§ç»­æ ¹æ®åŸºç¡€ä»£ç åˆ¤æ–­
            code = base_code
        
        # ç¾è‚¡ä»£ç æ¨¡å¼ï¼š1-5ä½å­—æ¯
        if code.isalpha() and 1 <= len(code) <= 5:
            return 'us'
        
        # æ··åˆå­—æ¯æ•°å­—çš„å¤æ‚æƒ…å†µ
        if code.isdigit():
            return 'cn'  # çº¯æ•°å­—å€¾å‘äºAè‚¡
        elif code.isalpha():
            return 'us'  # çº¯å­—æ¯å€¾å‘äºç¾è‚¡
        
        return 'other'
    
    def collect_multi_market_kline_data(self, codes: List[str], days: int = 30) -> Dict[str, Any]:
        """
        å¤šå¸‚åœºKçº¿æ•°æ®æ”¶é›†ï¼ˆæ”¯æŒAè‚¡å’Œç¾è‚¡ï¼‰
        
        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¯åŒ…å«Aè‚¡å’Œç¾è‚¡ä»£ç 
            days: è·å–å¤©æ•°
            
        Returns:
            åŒ…å«Kçº¿æ•°æ®çš„å­—å…¸ï¼ŒæŒ‰å¸‚åœºåˆ†ç±»
        """
        print(f"[INFO] å¤šå¸‚åœºKçº¿æ•°æ®æ”¶é›†: {len(codes)} åªè‚¡ç¥¨")
        
        # æŒ‰å¸‚åœºåˆ†ç±»è‚¡ç¥¨ä»£ç 
        cn_stocks = []  # Aè‚¡
        us_stocks = []  # ç¾è‚¡
        other_stocks = []  # å…¶ä»–
        
        for code in codes:
            market = self._detect_market(code)
            if market == 'cn':
                cn_stocks.append(code)
            elif market == 'us':
                us_stocks.append(code)
            else:
                other_stocks.append(code)
        
        print(f"[INFO] å¸‚åœºåˆ†ç±»: Aè‚¡ {len(cn_stocks)} åª, ç¾è‚¡ {len(us_stocks)} åª, å…¶ä»– {len(other_stocks)} åª")
        
        result = {
            'cn_data': {},  # Aè‚¡æ•°æ®
            'us_data': {},  # ç¾è‚¡æ•°æ®
            'summary': {
                'total_codes': len(codes),
                'cn_count': len(cn_stocks),
                'us_count': len(us_stocks),
                'other_count': len(other_stocks),
                'cn_success': 0,
                'us_success': 0
            }
        }
        
        # æ”¶é›†Aè‚¡æ•°æ®ï¼ˆä½¿ç”¨ç°æœ‰æ–¹æ³•ï¼‰
        if cn_stocks:
            print(f"\n[INFO] æ”¶é›†Aè‚¡æ•°æ®: {len(cn_stocks)} åª")
            try:
                cn_data = self.collect_batch_kline_data(cn_stocks)
                result['cn_data'] = cn_data
                result['summary']['cn_success'] = len(cn_data)
                print(f"[SUCCESS] Aè‚¡æ•°æ®æ”¶é›†å®Œæˆ: {len(cn_data)}/{len(cn_stocks)}")
            except Exception as e:
                print(f"[ERROR] Aè‚¡æ•°æ®æ”¶é›†å¼‚å¸¸: {e}")
        
        # æ”¶é›†ç¾è‚¡æ•°æ®ï¼ˆPolygon.ioä½œä¸ºå¤‡é€‰ï¼‰
        if us_stocks:
            print(f"\n[INFO] æ”¶é›†ç¾è‚¡æ•°æ®: {len(us_stocks)} åª")
            us_data = {}
            
            # ä½¿ç”¨Polygon.ioè¡¥å……
            remaining_stocks = [code for code in us_stocks if code not in us_data]
            if remaining_stocks and self.polygon and self.polygon.is_available:
                print(f"[INFO] ä½¿ç”¨Polygon.ioè¡¥å……å‰©ä½™ {len(remaining_stocks)} åªè‚¡ç¥¨")
                try:
                    polygon_data = self.polygon.batch_get_us_klines(remaining_stocks, days)
                    us_data.update(polygon_data)
                    print(f"[SUCCESS] Polygon.ioè¡¥å…… {len(polygon_data)} åªè‚¡ç¥¨æ•°æ®")
                except Exception as e:
                    print(f"[ERROR] Polygon.ioæ•°æ®æ”¶é›†å¼‚å¸¸: {e}")
            
            result['us_data'] = us_data
            result['summary']['us_success'] = len(us_data)
            print(f"[SUCCESS] ç¾è‚¡æ•°æ®æ”¶é›†å®Œæˆ: {len(us_data)}/{len(us_stocks)}")
        elif us_stocks:
            print(f"[WARN] å‘ç° {len(us_stocks)} åªç¾è‚¡ä»£ç ï¼Œä½†ç¾è‚¡APIä¸å¯ç”¨")
        
        # å…¶ä»–å¸‚åœºæç¤º
        if other_stocks:
            print(f"[WARN] å‘ç° {len(other_stocks)} åªå…¶ä»–å¸‚åœºä»£ç ï¼Œæš‚ä¸æ”¯æŒ: {other_stocks[:5]}")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        total_success = result['summary']['cn_success'] + result['summary']['us_success']
        success_rate = total_success / len(codes) * 100 if codes else 0
        
        print(f"\n[SUMMARY] å¤šå¸‚åœºæ•°æ®æ”¶é›†å®Œæˆ:")
        print(f"  æ€»è®¡: {total_success}/{len(codes)} ({success_rate:.1f}%)")
        print(f"  Aè‚¡: {result['summary']['cn_success']}/{result['summary']['cn_count']}")
        print(f"  ç¾è‚¡: {result['summary']['us_success']}/{result['summary']['us_count']}")
        
        return result

    def get_global_market_news(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–å…¨çƒå¸‚åœºæ–°é—» (åˆ©ç”¨ Polygon.io çš„å¼ºé¡¹)
        
        Args:
            limit: è·å–æ–°é—»æ¡æ•°
        """
        if self.polygon and self.polygon.is_available:
            print(f"[INFO] ä½¿ç”¨ Polygon.io è·å–å…¨çƒå¸‚åœºæ–°é—» ({limit} æ¡)...")
            return self.polygon.get_market_news(limit)
        else:
            print("[WARN] Polygon.io ä¸å¯ç”¨ï¼Œæ— æ³•è·å–å…¨çƒæ–°é—»")
            return []
    
    def collect_multi_market_basic_info(self, codes: List[str]) -> Dict[str, Any]:
        """
        å¤šå¸‚åœºåŸºæœ¬ä¿¡æ¯æ”¶é›†ï¼ˆæ”¯æŒAè‚¡å’Œç¾è‚¡ï¼‰
        
        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¯åŒ…å«Aè‚¡å’Œç¾è‚¡ä»£ç 
            
        Returns:
            åŒ…å«åŸºæœ¬ä¿¡æ¯çš„å­—å…¸ï¼ŒæŒ‰å¸‚åœºåˆ†ç±»
        """
        print(f"[INFO] å¤šå¸‚åœºåŸºæœ¬ä¿¡æ¯æ”¶é›†: {len(codes)} åªè‚¡ç¥¨")
        
        # æŒ‰å¸‚åœºåˆ†ç±»
        cn_stocks = []
        us_stocks = []
        
        for code in codes:
            market = self._detect_market(code)
            if market == 'cn':
                cn_stocks.append(code)
            elif market == 'us':
                us_stocks.append(code)
        
        result = {
            'cn_data': {},
            'us_data': {},
            'summary': {
                'cn_success': 0,
                'us_success': 0
            }
        }
        
        # æ”¶é›†Aè‚¡åŸºæœ¬ä¿¡æ¯
        if cn_stocks:
            print(f"[INFO] æ”¶é›†Aè‚¡åŸºæœ¬ä¿¡æ¯: {len(cn_stocks)} åª")
            cn_info = self.collect_batch_basic_info(cn_stocks)
            result['cn_data'] = cn_info
            result['summary']['cn_success'] = len(cn_info)
        
        # æ”¶é›†ç¾è‚¡åŸºæœ¬ä¿¡æ¯ï¼ˆPolygon.ioä½œä¸ºå¤‡é€‰ï¼‰
        if us_stocks:
            print(f"[INFO] æ”¶é›†ç¾è‚¡åŸºæœ¬ä¿¡æ¯: {len(us_stocks)} åª")
            us_info = {}
            
            # ä½¿ç”¨Polygon.ioè¡¥å……
            remaining_stocks = [code for code in us_stocks if code not in us_info]
            if remaining_stocks and self.polygon and self.polygon.is_available:
                print(f"[INFO] ä½¿ç”¨Polygon.ioè¡¥å……å‰©ä½™ {len(remaining_stocks)} åªè‚¡ç¥¨")
                for symbol in remaining_stocks:
                    try:
                        info = self.polygon.get_company_info(symbol)
                        if info:
                            us_info[symbol] = info
                    except Exception as e:
                        print(f"[WARN] Polygon.ioè·å– {symbol} ä¿¡æ¯å¤±è´¥: {e}")
            
            result['us_data'] = us_info
            result['summary']['us_success'] = len(us_info)
            print(f"[SUCCESS] ç¾è‚¡ä¿¡æ¯æ”¶é›†å®Œæˆ: {len(us_info)}/{len(us_stocks)}")
        
        return result
            
        # Aè‚¡ä»£ç æ¨¡å¼
        if code.isdigit() and len(code) == 6:
            return 'cn'
            
        # ç¾è‚¡ä»£ç æ¨¡å¼
        if code.isalpha() and 1 <= len(code) <= 5:
            return 'us'
            
        # å¸¦äº¤æ˜“æ‰€åç¼€çš„ä»£ç 
        if '.' in code:
            suffix = code.split('.')[-1].upper()
            if suffix in ['SS', 'SZ', 'HK']:  # ä¸Šäº¤æ‰€ã€æ·±äº¤æ‰€ã€æ¸¯äº¤æ‰€
                return 'cn'
            elif suffix in ['US', 'NASDAQ', 'NYSE']:  # ç¾è‚¡
                return 'us'
                
        # é»˜è®¤æŒ‰å­—æ¯æ•°å­—æ¯”ä¾‹åˆ¤æ–­
        if code.isalpha():
            return 'us'
        elif code.isdigit():
            return 'cn'
            
        return 'other'
    
    def _check_akshare_health(self) -> None:
        """
        æ£€æŸ¥AKShareå¥åº·çŠ¶å†µï¼Œå¦‚æœå¤±è´¥ç‡è¶…è¿‡50%åˆ™ç¦ç”¨
        """
        if self.akshare_call_count < 10:  # è‡³å°‘éœ€è¦10æ¬¡è°ƒç”¨æ‰èƒ½åˆ¤æ–­
            return
        
        fail_rate = self.akshare_fail_count / self.akshare_call_count
        
        if fail_rate > 0.5 and self.akshare_enabled:
            self.akshare_enabled = False
            print(f"[WARN] AKShareå¤±è´¥ç‡è¿‡é«˜ ({fail_rate*100:.1f}%)ï¼Œå·²è‡ªåŠ¨ç¦ç”¨")
            print(f"[INFO] ç»Ÿè®¡: æ€»è°ƒç”¨{self.akshare_call_count}æ¬¡ï¼ŒæˆåŠŸ{self.akshare_success_count}æ¬¡ï¼Œå¤±è´¥{self.akshare_fail_count}æ¬¡")
        elif fail_rate <= 0.3 and not self.akshare_enabled and self.akshare_call_count >= 20:
            # å¦‚æœå¤±è´¥ç‡é™è‡³30%ä»¥ä¸‹ï¼Œä¸”å·²æœ‰è¶³å¤Ÿæ ·æœ¬ï¼Œé‡æ–°å¯ç”¨
            self.akshare_enabled = True
            print(f"[INFO] AKShareå¤±è´¥ç‡å·²é™ä½ ({fail_rate*100:.1f}%)ï¼Œé‡æ–°å¯ç”¨")
    
    def _record_akshare_call(self, success: bool) -> None:
        """
        è®°å½•AKShareè°ƒç”¨ç»“æœ
        
        Args:
            success: è°ƒç”¨æ˜¯å¦æˆåŠŸ
        """
        self.akshare_call_count += 1
        if success:
            self.akshare_success_count += 1
        else:
            self.akshare_fail_count += 1
        
        # æ¯10æ¬¡è°ƒç”¨æ£€æŸ¥ä¸€æ¬¡å¥åº·çŠ¶å†µ
        if self.akshare_call_count % 10 == 0:
            self._check_akshare_health()
    
    def _test_akshare_connectivity(self) -> bool:
        """
        ã€å·²åºŸå¼ƒã€‘æµ‹è¯•AKShareè¿é€šæ€§
        ç°åœ¨ä½¿ç”¨åŠ¨æ€ç›‘æ§æœºåˆ¶ï¼Œä¸å†åœ¨åˆå§‹åŒ–æ—¶æµ‹è¯•
        
        Returns:
            bool: Trueè¡¨ç¤ºè¿æ¥æˆåŠŸï¼ŒFalseè¡¨ç¤ºè¿æ¥å¤±è´¥
        """
        global AKSHARE_CONNECTED
        
        if not AKSHARE_AVAILABLE:
            print("[INFO] AKShareæœªå®‰è£…ï¼Œè·³è¿‡è¿é€šæ€§æµ‹è¯•")
            AKSHARE_CONNECTED = False
            return False
        
        print("[INFO] å¼€å§‹æµ‹è¯•AKShareè¿é€šæ€§...")
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šç®€å•çš„è‚¡ç¥¨ä¿¡æ¯æŸ¥è¯¢
        test_cases = [
            {
                'name': 'è‚¡ç¥¨ä»£ç åˆ—è¡¨',
                'function': lambda: ak.stock_info_a_code_name().head(1),
                'timeout': 10
            },
            {
                'name': 'å®æ—¶è¡Œæƒ…',
                'function': lambda: ak.stock_zh_a_spot_em().head(1), 
                'timeout': 8
            },
            {
                'name': 'åŸºæœ¬ä¿¡æ¯',
                'function': lambda: ak.stock_individual_info_em(symbol="000001"),
                'timeout': 8
            }
        ]
        
        success_count = 0
        total_tests = len(test_cases)
        
        for i, test_case in enumerate(test_cases):
            try:
                print(f"  [{i+1}/{total_tests}] æµ‹è¯•{test_case['name']}...", end="")
                
                # è®¾ç½®è¶…æ—¶æœºåˆ¶
                import signal
                def timeout_handler(signum, frame):
                    raise TimeoutError("æµ‹è¯•è¶…æ—¶")
                
                # Windowsç³»ç»Ÿä½¿ç”¨çº¿ç¨‹è¶…æ—¶
                if os.name == 'nt':
                    import threading
                    result = [None]
                    exception = [None]
                    
                    def test_thread():
                        try:
                            result[0] = test_case['function']()
                        except Exception as e:
                            exception[0] = e
                    
                    thread = threading.Thread(target=test_thread)
                    thread.daemon = True
                    thread.start()
                    thread.join(timeout=test_case['timeout'])
                    
                    if thread.is_alive():
                        print(" âŒ è¶…æ—¶")
                        continue
                    elif exception[0]:
                        error_msg = str(exception[0])
                        error_type = type(exception[0]).__name__
                        print(f" âŒ å¼‚å¸¸: {error_type}")
                        # è¯¦ç»†è¯Šæ–­AKShareå¸¸è§é”™è¯¯
                        if 'timeout' in error_msg.lower() or 'timed out' in error_msg.lower():
                            print(f"    [è¯Šæ–­] ç½‘ç»œè¶…æ—¶ - å¯èƒ½ç½‘ç»œè¿æ¥ä¸ç¨³å®šæˆ–AKShareæœåŠ¡å™¨å“åº”æ…¢")
                        elif 'connection' in error_msg.lower() or 'network' in error_msg.lower():
                            print(f"    [è¯Šæ–­] ç½‘ç»œè¿æ¥é—®é¢˜ - è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
                        elif '502' in error_msg or '503' in error_msg or '504' in error_msg:
                            print(f"    [è¯Šæ–­] æœåŠ¡å™¨é”™è¯¯ - AKShareåç«¯æœåŠ¡å¯èƒ½æš‚æ—¶ä¸å¯ç”¨")
                        elif 'ssl' in error_msg.lower() or 'certificate' in error_msg.lower():
                            print(f"    [è¯Šæ–­] SSLè¯ä¹¦é—®é¢˜ - å¯èƒ½éœ€è¦æ›´æ–°è¯ä¹¦æˆ–å…³é—­SSLéªŒè¯")
                        elif 'forbidden' in error_msg.lower() or '403' in error_msg:
                            print(f"    [è¯Šæ–­] è®¿é—®è¢«æ‹’ç» - å¯èƒ½IPè¢«é™åˆ¶æˆ–éœ€è¦æ›´æ–°AKShareç‰ˆæœ¬")
                        continue
                    elif result[0] is not None and not result[0].empty:
                        print(" âœ… æˆåŠŸ")
                        success_count += 1
                    else:
                        print(" âŒ æ— æ•°æ®")
                else:
                    # Unixç³»ç»Ÿä½¿ç”¨signalè¶…æ—¶
                    signal.signal(signal.SIGALRM, timeout_handler)
                    signal.alarm(test_case['timeout'])
                    
                    try:
                        result = test_case['function']()
                        signal.alarm(0)
                        
                        if result is not None and not result.empty:
                            print(" âœ… æˆåŠŸ")
                            success_count += 1
                        else:
                            print(" âŒ æ— æ•°æ®")
                    except TimeoutError:
                        print(" âŒ è¶…æ—¶")
                        signal.alarm(0)
                    except Exception as e:
                        print(f" âŒ å¼‚å¸¸: {type(e).__name__}")
                        signal.alarm(0)
                        
            except Exception as e:
                print(f" âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}")
                continue
            
            # æµ‹è¯•é—´éš”
            time.sleep(1)
        
        # è¯„ä¼°è¿é€šæ€§
        success_rate = success_count / total_tests
        
        if success_rate >= 0.8:  # 80%ä»¥ä¸Šæµ‹è¯•æˆåŠŸæ‰è®¤ä¸ºè¿æ¥æ­£å¸¸
            AKSHARE_CONNECTED = True
            print(f"[SUCCESS] AKShareè¿é€šæ€§æµ‹è¯•é€šè¿‡ ({success_count}/{total_tests}, {success_rate*100:.0f}%)")
            print("[INFO] AKShareå°†ä½œä¸ºæ•°æ®æºä½¿ç”¨")
            return True
        else:
            AKSHARE_CONNECTED = False
            print(f"[WARN] AKShareè¿é€šæ€§æµ‹è¯•å¤±è´¥ ({success_count}/{total_tests}, {success_rate*100:.0f}%)")
            print("[INFO] AKShareå°†è¢«è·³è¿‡ï¼Œä½¿ç”¨å…¶ä»–æ•°æ®æº")
            return False
    
    def get_stock_list_excluding_cyb(self, limit: int = 50) -> List[str]:
        """è·å–å…¨éƒ¨ä¸»æ¿è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ’é™¤åˆ›ä¸šæ¿300ã€ç§‘åˆ›æ¿688å’ŒETFï¼‰"""
        stock_codes = []
        # ä¼˜å…ˆä» akshare è·å–å®Œæ•´åˆ—è¡¨
        if AKSHARE_AVAILABLE and self.akshare_enabled:
            try:
                print("[INFO] å°è¯•ä» akshare è·å–è‚¡ç¥¨åˆ—è¡¨...")
                df = ak.stock_info_a_code_name()
                all_codes = df['code'].astype(str).tolist()
                self._record_akshare_call(True)  # è®°å½•æˆåŠŸ
                # åªä¿ç•™ä¸»æ¿è‚¡ç¥¨ï¼šæ²ªå¸‚ä¸»æ¿(60å¼€å¤´) + æ·±å¸‚ä¸»æ¿(000å¼€å¤´) + æ·±å¸‚ä¸­å°æ¿(002å¼€å¤´)
                main_board_codes = [code for code in all_codes 
                                  if (code.startswith('60') or code.startswith('000') or code.startswith('002'))
                                  and not code.startswith('688') and not code.startswith('300') and not code.startswith('ETF')]
                stock_codes = main_board_codes
                print(f"[SUCCESS] ä» akshare è·å– {len(stock_codes)} åªä¸»æ¿è‚¡ç¥¨ï¼ˆå·²æ’é™¤åˆ›ä¸šæ¿300ã€ç§‘åˆ›æ¿688å’ŒETFï¼‰")
                return stock_codes
            except Exception as e:
                self._record_akshare_call(False)  # è®°å½•å¤±è´¥
                print(f"[ERROR] akshare è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {type(e).__name__}: {e}")
        # å°è¯•ä» Baostock è·å–
        if BAOSTOCK_AVAILABLE:
            try:
                print(f"[INFO] å°è¯•ä» Baostock è·å–è‚¡ç¥¨åˆ—è¡¨...")
                import baostock as bs
                lg = bs.login()
                rs = bs.query_all_stock(day=datetime.now().strftime('%Y-%m-%d'))
                if rs.error_code == '0':
                    all_codes = []
                    while rs.next():
                        row = rs.get_row_data()
                        if len(row) > 0:
                            full_code = row[0]
                            if '.' in full_code:
                                code = full_code.split('.')[1]
                                all_codes.append(code)
                    main_board_codes = [code for code in all_codes 
                                      if (code.startswith('60') or code.startswith('000') or code.startswith('002'))
                                      and not code.startswith('688') and not code.startswith('300') and not code.startswith('ETF')]
                    stock_codes = main_board_codes
                    if stock_codes:
                        print(f"[SUCCESS] ä» Baostock è·å– {len(stock_codes)} åªä¸»æ¿è‚¡ç¥¨")
                        return stock_codes
            except Exception as e:
                print(f"[ERROR] Baostock è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        print(f"[INFO] åˆ‡æ¢åˆ°å¤‡ç”¨ä¸»æ¿è‚¡ç¥¨æ± ...")
        print(f"[WARN] akshare å’Œ Baostock å‡è·å–å¤±è´¥ï¼Œä½¿ç”¨æ‰©å±•å¤‡ç”¨è‚¡ç¥¨æ± ï¼ˆ1000+åªä¸»æ¿è‚¡ç¥¨ï¼‰")
        fallback_codes = []
        for i in range(1000):
            code = f"60{i:04d}"
            fallback_codes.append(code)
        for i in range(1000, 2000):
            code = f"60{i:04d}"
            fallback_codes.append(code)
        for i in range(1, 1000):
            code = f"000{i:03d}"
            fallback_codes.append(code)
        for i in range(1, 1000):
            code = f"002{i:03d}"
            fallback_codes.append(code)
        # è¿‡æ»¤åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ã€ETF
        fallback_codes = [code for code in fallback_codes if not code.startswith('688') and not code.startswith('300') and not code.startswith('ETF')]
        print(f"[INFO] å¤‡ç”¨è‚¡ç¥¨æ± å…±ç”Ÿæˆ {len(fallback_codes)} åªä¸»æ¿è‚¡ç¥¨ä»£ç ")
        return fallback_codes
    
    def get_stock_list_by_type(self, stock_type: str = "ä¸»æ¿", limit: int = 50) -> List[str]:
        """æ ¹æ®è‚¡ç¥¨ç±»å‹è·å–è‚¡ç¥¨åˆ—è¡¨"""
        if stock_type == "ä¸»æ¿":
            # ä¸»æ¿è‚¡ç¥¨ï¼š60/000/002å¼€å¤´ï¼Œæ’é™¤30åˆ›ä¸šæ¿å’Œ688ç§‘åˆ›æ¿
            return self.get_stock_list_excluding_cyb(limit)
        elif stock_type == "å…¨éƒ¨":
            # è·å–æ‰€æœ‰è‚¡ç¥¨ï¼ˆåŒ…æ‹¬åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰
            return self.get_all_stock_list(limit)
        elif stock_type == "ETF":
            # è·å–ETFåˆ—è¡¨
            return self.get_etf_list(limit)
        else:
            # é»˜è®¤è¿”å›ä¸»æ¿
            return self.get_stock_list_excluding_cyb(limit)
    
    def get_etf_list(self, limit: int = 50) -> List[str]:
        """è·å–ETFåˆ—è¡¨"""
        etf_codes = []
        
        if AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
            try:
                print("[INFO] å°è¯•ä» akshare è·å–ETFåˆ—è¡¨...")
                df = ak.fund_etf_spot_em()
                all_codes = df['ä»£ç '].astype(str).tolist()
                etf_codes = all_codes[:limit]
                print(f"[SUCCESS] ä» akshare è·å– {len(etf_codes)} åªETF")
                return etf_codes
            except Exception as e:
                print(f"[ERROR] akshare è·å–ETFåˆ—è¡¨å¤±è´¥: {e}")
        
        # å¤‡é€‰ETFåˆ—è¡¨
        fallback_etf = [
            '510050', '510300', '510500', '510880', '512100', '512690', '512880',
            '513050', '515050', '515790', '516160', '518880', '159915', '159919',
            '159949', '159995', '159996'
        ]
        return fallback_etf[:limit]
    
    def get_all_stock_list(self, limit: int = 5500) -> List[str]:
        """è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨ï¼Œæ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿"""
        stock_codes = []
        
        # ä¼˜å…ˆä» akshare è·å–å®Œæ•´åˆ—è¡¨
        if AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
            try:
                df = ak.stock_info_a_code_name()
                all_codes = df['code'].astype(str).tolist()
                # æ’é™¤åˆ›ä¸šæ¿(300)å’Œç§‘åˆ›æ¿(688)
                filtered_codes = [code for code in all_codes if not (code.startswith('300') or code.startswith('688'))]
                stock_codes = filtered_codes[:limit]
                print(f"[INFO] ä» akshare è·å– {len(stock_codes)} åªä¸»æ¿è‚¡ç¥¨ï¼ˆå·²æ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰")
                return stock_codes
            except Exception as e:
                print(f"[WARN] akshare è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        
        # å¤‡é€‰ï¼šä» BaoStock è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨
        if BAOSTOCK_AVAILABLE and hasattr(self, 'bs'):
            try:
                print("[INFO] å°è¯•ä» BaoStock è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨...")
                
                # è·å–æ‰€æœ‰è‚¡ç¥¨ï¼ˆæ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰
                rs = bs.query_all_stock()
                if rs.error_code != '0':
                    raise Exception(f"BaoStock æŸ¥è¯¢é”™è¯¯: {rs.error_msg}")
                
                all_stocks = []
                while rs.next():
                    code = rs.get_row_data()[0]
                    if code and '.' in code:
                        # è½¬æ¢æ ¼å¼ï¼šsh.600000 -> 600000
                        clean_code = code.split('.')[1]
                        if len(clean_code) == 6 and clean_code.isdigit():
                            # æ’é™¤åˆ›ä¸šæ¿(300)å’Œç§‘åˆ›æ¿(688)
                            if not (clean_code.startswith('300') or clean_code.startswith('688')):
                                all_stocks.append(clean_code)
                
                stock_codes = all_stocks[:limit]
                print(f"[SUCCESS] ä» BaoStock è·å– {len(stock_codes)} åªä¸»æ¿è‚¡ç¥¨ï¼ˆå·²æ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰")
                return stock_codes
                
            except Exception as e:
                print(f"[WARN] BaoStock è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        
        # æœ€åå¤‡é€‰ï¼šä»ç°æœ‰æ•°æ®æ–‡ä»¶ä¸­è·å–è‚¡ç¥¨åˆ—è¡¨
        try:
            import json

            # ä¼˜å…ˆä½¿ç”¨åˆå§‹åŒ–æ—¶ç¡®å®šçš„æ•°æ®ç›®å½•
            data_dir = os.path.dirname(self.output_file)
            index_file = os.path.join(data_dir, "stock_file_index.json")
            
            if not os.path.exists(index_file):
                # å›é€€åˆ°ç›¸å¯¹è·¯å¾„
                index_file = "data/stock_file_index.json"
                
            if os.path.exists(index_file):
                with open(index_file, "r", encoding="utf-8") as f:
                    index_data = json.load(f)
                    # æ’é™¤åˆ›ä¸šæ¿(300)å’Œç§‘åˆ›æ¿(688)
                    filtered_codes = [code for code in index_data.keys() if not (code.startswith('300') or code.startswith('688'))]
                    stock_codes = filtered_codes[:limit]
                    print(f"[INFO] ä»ç°æœ‰æ•°æ®æ–‡ä»¶ {index_file} è·å– {len(stock_codes)} åªä¸»æ¿è‚¡ç¥¨ï¼ˆå·²æ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰")
                    return stock_codes
        except Exception as e:
            print(f"[WARN] ä»æ•°æ®æ–‡ä»¶è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        
        # æœ€ç»ˆå¤‡é€‰ï¼šå†…ç½®ä¸»æ¿è‚¡ç¥¨æ± ï¼ˆæ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰
        fallback_codes = [
            # æ²ªå¸‚ä¸»æ¿
            '600000', '600036', '600519', '600276', '600887', '600585', '600309', '600028',
            '601318', '601166', '601328', '601398', '601288', '601939', '601988', '601012',
            '600031', '600048', '600196', '600688', '600745', '600547', '600900', '600660',
            
            # æ·±å¸‚ä¸»æ¿
            '000001', '000002', '000063', '000100', '000157', '000166', '000568', '000596',
            '000625', '000651', '000725', '000858', '000876', '000895', '000938', '000977',
            '002001', '002027', '002050', '002120', '002129', '002142', '002304', '002352',
            '002714', '002415', '002594', '002174', '002475'
        ]
        print(f"[INFO] ä½¿ç”¨å†…ç½®ä¸»æ¿è‚¡ç¥¨æ±  {len(fallback_codes)} åªè‚¡ç¥¨ï¼ˆå·²æ’é™¤åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ï¼‰")
        return fallback_codes[:limit]
    
    def standardize_kline_columns(self, df: pd.DataFrame, source: str = 'unknown') -> pd.DataFrame:
        """æ ‡å‡†åŒ–Kçº¿æ•°æ®DataFrameçš„åˆ—å"""
        if df is None or df.empty:
            return df
        
        # å®šä¹‰æ ‡å‡†åˆ—åæ˜ å°„
        column_mappings = {
            'choice': {
                'æ—¥æœŸ': 'date', 'äº¤æ˜“æ—¥': 'date', 'date': 'date', 'trade_date': 'date',
                'å¼€ç›˜': 'open', 'å¼€ç›˜ä»·': 'open', 'open': 'open',
                'æœ€é«˜': 'high', 'æœ€é«˜ä»·': 'high', 'high': 'high',
                'æœ€ä½': 'low', 'æœ€ä½ä»·': 'low', 'low': 'low',
                'æ”¶ç›˜': 'close', 'æ”¶ç›˜ä»·': 'close', 'close': 'close',
                'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount', 'volume': 'volume', 'vol': 'volume',
                'è‚¡ç¥¨ä»£ç ': 'code', 'code': 'code', 'ä»£ç ': 'code'
            },
            'tushare': {
                'trade_date': 'date', 'ts_code': 'code', 
                'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'vol': 'volume'
            },
            'akshare': {
                'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æ”¶ç›˜': 'close', 'æˆäº¤é‡': 'volume',
                'date': 'date', 'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'
            },
            'yfinance': {
                'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'
            },
            'alpha_vantage': {
                'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'
            },
            'joinquant': {
                'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æ”¶ç›˜': 'close', 'æˆäº¤é‡': 'volume',
                'date': 'date', 'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume',
                'code': 'code'
            },
            'sina': {
                'day': 'date', 'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume',
                'date': 'date'
            },
            'tencent': {
                'date': 'date', 'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'
            },
            'baostock': {
                'date': 'date', 'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'
            }
        }
        
        try:
            # å°è¯•è·å–å¯¹åº”æ•°æ®æºçš„æ˜ å°„
            mapping = column_mappings.get(source, {})
            
            # å¦‚æœæ²¡æœ‰æ˜ å°„ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
            if not mapping:
                for src, map_dict in column_mappings.items():
                    if any(col in df.columns for col in map_dict.keys()):
                        mapping = map_dict
                        source = src
                        break
            
            # åº”ç”¨åˆ—åæ˜ å°„
            if mapping:
                df = df.rename(columns=mapping)
                print(f"[DEBUG] {source}æ•°æ®åˆ—åå·²æ ‡å‡†åŒ–: {list(df.columns)}")
            
            # ç¡®ä¿å¿…é¡»çš„åˆ—å­˜åœ¨
            required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
            existing_columns = [col for col in required_columns if col in df.columns]
            
            if len(existing_columns) >= 4:  # è‡³å°‘æœ‰åŸºç¡€çš„OHLCæ•°æ®
                df = df[existing_columns].copy()
                
                # ğŸ”´ æ”¹è¿›ï¼šç»Ÿä¸€æ—¥æœŸæ ¼å¼å¹¶æŒ‰æ—¥æœŸå‡åºæ’åˆ—ï¼ˆæŠ€æœ¯æŒ‡æ ‡è®¡ç®—éœ€è¦å‡åºï¼‰
                if 'date' in df.columns:
                    def normalize_date_func(d):
                        d_str = str(d).split(' ')[0].replace('-', '').replace('/', '')
                        if len(d_str) >= 8:
                            return f"{d_str[:4]}-{d_str[4:6]}-{d_str[6:8]}"
                        return str(d)
                    
                    df['date'] = df['date'].apply(normalize_date_func)
                    df = df.sort_values('date')
                
                # ç¡®ä¿æ•°å€¼åˆ—ä¸ºæµ®ç‚¹å‹
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                return df.dropna(subset=['close']) # è‡³å°‘è¦æœ‰æ”¶ç›˜ä»·
            else:
                print(f"[WARN] æ•°æ®åˆ—ä¸è¶³ï¼Œç°æœ‰åˆ—: {list(df.columns)}")
                return df
                
        except Exception as e:
            print(f"[ERROR] åˆ—åæ ‡å‡†åŒ–å¤±è´¥: {e}")
            return df
    
    def collect_batch_kline_data(self, codes: List[str], source: str = 'auto', start_date_override: Optional[str] = None) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡é‡‡é›†Kçº¿æ•°æ® - æ–°ç­–ç•¥: åŸºäºæ—¶é—´æ§åˆ¶çš„TUSHAREä¼˜å…ˆ â†’ AKShareæ›¿ä»£ â†’ è…¾è®¯Kçº¿å…œåº•"""
        result = {}
        total_codes = len(codes)
        
        # ç¡®å®šæ˜¯å¦å¯ç”¨Choice
        try:
            from config import CHOICE_PASSWORD, CHOICE_USERNAME, ENABLE_CHOICE
            effective_enable_choice = self.use_choice if self.use_choice is not None else ENABLE_CHOICE
            choice_active = effective_enable_choice and CHOICE_USERNAME and CHOICE_PASSWORD
        except:
            choice_active = False

        print(f"[INFO] å¼€å§‹é‡‡é›†Kçº¿æ•°æ®ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        if choice_active:
            print(f"[INFO] æ–°é‡‡é›†ç­–ç•¥: Choiceé‡‘èç»ˆç«¯ä¼˜å…ˆ â†’ TUSHARE â†’ AKShare â†’ è…¾è®¯Kçº¿å…œåº•")
        else:
            print(f"[INFO] æ–°é‡‡é›†ç­–ç•¥: TUSHAREä¼˜å…ˆ â†’ AKShare â†’ è…¾è®¯Kçº¿å…œåº• (Choiceå·²ç¦ç”¨)")
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        
        # ğŸ”´ æ”¹è¿›ï¼šæ™ºèƒ½è°ƒæ•´åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼ˆå‘¨ä¸€è‡³å‘¨äº”ï¼‰
        # å¦‚æœä»Šå¤©æ˜¯å‘¨å…­(5)æˆ–å‘¨æ—¥(6)ï¼Œå›é€€åˆ°ä¸Šå‘¨äº”
        weekday = end_date.weekday()
        if weekday == 5:  # å‘¨å…­
            end_date = end_date - timedelta(days=1)  # å›åˆ°å‘¨äº”
            print(f"[INFO] ä»Šå¤©æ˜¯å‘¨å…­ï¼ˆä¼‘å¸‚ï¼‰ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°ä¸Šå‘¨äº”: {end_date.strftime('%Y-%m-%d')}")
        elif weekday == 6:  # å‘¨æ—¥
            end_date = end_date - timedelta(days=2)  # å›åˆ°å‘¨äº”
            print(f"[INFO] ä»Šå¤©æ˜¯å‘¨æ—¥ï¼ˆä¼‘å¸‚ï¼‰ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°ä¸Šå‘¨äº”: {end_date.strftime('%Y-%m-%d')}")
        
        if start_date_override:
            try:
                # ç»Ÿä¸€æ ¼å¼ä¸º YYYYMMDD æˆ– YYYY-MM-DD
                if '-' in start_date_override:
                    start_date = datetime.strptime(start_date_override, '%Y-%m-%d')
                else:
                    start_date = datetime.strptime(start_date_override, '%Y%m%d')
                
                # ğŸ”´ ä¿®å¤ï¼šå¦‚æœ start_date_override ä¹Ÿæ˜¯å‘¨æœ«ï¼Œéœ€è¦è°ƒæ•´
                start_weekday = start_date.weekday()
                if start_weekday == 5:  # å‘¨å…­
                    start_date = start_date - timedelta(days=1)
                    print(f"[INFO] èµ·å§‹æ—¥æœŸæ˜¯å‘¨å…­ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°å‘¨äº”: {start_date.strftime('%Y-%m-%d')}")
                elif start_weekday == 6:  # å‘¨æ—¥
                    start_date = start_date - timedelta(days=2)
                    print(f"[INFO] èµ·å§‹æ—¥æœŸæ˜¯å‘¨æ—¥ï¼Œè‡ªåŠ¨è°ƒæ•´åˆ°å‘¨äº”: {start_date.strftime('%Y-%m-%d')}")
                    
                # ç¡®ä¿ start_date ä¸æ™šäº end_date
                if start_date > end_date:
                    print(f"[WARN] èµ·å§‹æ—¥æœŸ ({start_date.strftime('%Y-%m-%d')}) æ™šäºç»“æŸæ—¥æœŸ ({end_date.strftime('%Y-%m-%d')}),è‡ªåŠ¨è°ƒæ•´")
                    start_date = end_date - timedelta(days=self.kline_days)
            except:
                start_date = end_date - timedelta(days=self.kline_days)
        else:
            start_date = end_date - timedelta(days=self.kline_days)
            
        start_str = start_date.strftime('%Y%m%d')
        end_str = end_date.strftime('%Y%m%d')
        start_iso = start_date.strftime('%Y-%m-%d')
        end_iso = end_date.strftime('%Y-%m-%d')
        
        print(f"[INFO] è·å–æ—¥æœŸèŒƒå›´: {start_iso} åˆ° {end_iso}")
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨Choiceæ•°æ®æº
        primary_source = None
        primary_codes = codes.copy()
        
        # å°è¯•ä½¿ç”¨Choiceä½œä¸ºä¸»æ•°æ®æºï¼ˆå¦‚æœå¯ç”¨ä¸”é…ç½®æ­£ç¡®ï¼‰
        try:
            from config import CHOICE_PASSWORD, CHOICE_USERNAME, ENABLE_CHOICE

            # ä¼˜å…ˆä½¿ç”¨å®ä¾‹è®¾ç½®çš„ use_choiceï¼Œå¦åˆ™ä½¿ç”¨ config ä¸­çš„ ENABLE_CHOICE
            effective_enable_choice = self.use_choice if self.use_choice is not None else ENABLE_CHOICE
            choice_enabled = effective_enable_choice and CHOICE_USERNAME and CHOICE_PASSWORD
            
            if choice_enabled:
                print(f"[INFO] Choiceæ•°æ®æºå·²å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨Choiceè·å– {len(codes)} åªè‚¡ç¥¨")
                try:
                    # å¯¼å…¥Choiceç›¸å…³å‡½æ•°
                    import os
                    import sys
                    api_dir = os.path.dirname(os.path.abspath(__file__))
                    tradingshared_dir = os.path.dirname(api_dir)
                    if api_dir not in sys.path:
                        sys.path.insert(0, api_dir)
                    if tradingshared_dir not in sys.path:
                        sys.path.insert(0, tradingshared_dir)
                    
                    import pandas as pd

                    from TradingShared.api.get_choice_data import \
                        get_kline_data_css

                    # ä½¿ç”¨Choiceæ‰¹é‡è·å–Kçº¿æ•°æ®
                    choice_success = []
                    
                    # ç¡®å®šæ—¥æœŸæ ¼å¼
                    c_start_iso = start_iso
                    c_end_iso = end_iso
                    
                    for code in codes:
                        try:
                            # è½¬æ¢è‚¡ç¥¨ä»£ç ä¸ºChoiceæ ¼å¼ (000001 -> 000001.SZ)
                            if code.startswith(('000', '001', '002', '300')):
                                choice_code = f"{code}.SZ"
                            else:
                                choice_code = f"{code}.SH"
                            
                            # Choice APIè·å–Kçº¿æ•°æ®
                            kline_data = get_kline_data_css(choice_code, c_start_iso, c_end_iso)
                            
                            if kline_data and 'dates' in kline_data and kline_data['dates']:
                                # å°†Choiceè¿”å›çš„æ•°æ®è½¬æ¢ä¸ºDataFrame
                                df_dict = {'date': kline_data['dates']}
                                for indicator in kline_data['indicators']:
                                    if indicator in kline_data['data']:
                                        df_dict[indicator.lower()] = kline_data['data'][indicator]
                                
                                df = pd.DataFrame(df_dict)
                                if not df.empty:
                                    df = self.standardize_kline_columns(df, 'choice')
                                    result[code] = df
                                    choice_success.append(code)
                                    print(f"[SUCCESS] Choiceè·å– {code} Kçº¿æ•°æ®æˆåŠŸ: {len(df)}å¤©")
                                else:
                                    print(f"[WARN] Choiceè·å– {code} Kçº¿æ•°æ®ä¸ºç©º")
                            else:
                                print(f"[WARN] Choiceè·å– {code} è¿”å›æ•°æ®æ— æ•ˆ")
                            
                            time.sleep(0.1)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡
                        except Exception as e:
                            print(f"[WARN] Choiceè·å– {code} å¤±è´¥: {e}")
                    
                    # å¦‚æœChoiceæˆåŠŸè·å–äº†æ‰€æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›
                    if len(result) == len(codes):
                        print(f"[SUCCESS] ChoiceæˆåŠŸè·å–æ‰€æœ‰ {len(codes)} åªè‚¡ç¥¨çš„Kçº¿æ•°æ®")
                        return result
                    else:
                        # å¤±è´¥çš„è‚¡ç¥¨ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
                        primary_codes = [c for c in codes if c not in choice_success]
                        print(f"[INFO] ChoiceæˆåŠŸ: {len(choice_success)}/{len(codes)} åªï¼Œå‰©ä½™ {len(primary_codes)} åªä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
                        primary_source = None  # éœ€è¦ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
                        
                except Exception as e:
                    print(f"[ERROR] Choiceæ•°æ®æºåˆå§‹åŒ–å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    primary_source = None
            else:
                print(f"[INFO] Choiceæ•°æ®æºæœªå¯ç”¨æˆ–æœªé…ç½®ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
                primary_source = None
        except ImportError as ie:
            print(f"[INFO] Choiceé…ç½®æœªæ‰¾åˆ°: {ie}ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
            primary_source = None
        
        # ä½¿ç”¨å…¶ä»–æ•°æ®æº
        burst_mode = False
        if primary_source is None:
            # æ£€æŸ¥ä¸Šæ¬¡TUSHAREè°ƒç”¨æ—¶é—´ï¼Œå†³å®šä½¿ç”¨å“ªä¸ªæ•°æ®æº
            current_time = time.time()
            time_since_last_tushare = current_time - self.last_tushare_call
            can_use_tushare = time_since_last_tushare >= 60  # 1åˆ†é’Ÿé—´éš”
            
            if can_use_tushare:
                print(f"[INFO] è·ç¦»ä¸Šæ¬¡TUSHAREè°ƒç”¨å·²è¿‡ {time_since_last_tushare:.1f} ç§’ï¼Œä½¿ç”¨TUSHAREè·å–å‰©ä½™ {len(primary_codes)} åª")
                primary_source = 'tushare'
            else:
                # ğŸ”´ ä¿®å¤ï¼šå¦‚æœç­‰å¾…æ—¶é—´<60ç§’ä¸”æ•°æ®é‡ä¸å¤§ï¼Œå°±ç­‰å¾…Tushare
                wait_time = 60 - time_since_last_tushare
                if len(primary_codes) <= 50 and wait_time < 60:  # å°æ‰¹é‡ä¸”ç­‰å¾…æ—¶é—´åˆç†
                    print(f"[INFO] TUSHAREéœ€ç­‰å¾… {wait_time:.1f} ç§’ï¼ˆå°æ‰¹é‡æ•°æ®ï¼Œå€¼å¾—ç­‰å¾…ï¼‰...")
                    time.sleep(wait_time)
                    print(f"[INFO] ç­‰å¾…å®Œæˆï¼Œä½¿ç”¨TUSHAREè·å– {len(primary_codes)} åªè‚¡ç¥¨")
                    primary_source = 'tushare'
                elif len(primary_codes) > 50:
                    # æ‰¹é‡è¾ƒå¤§ï¼Œå¯ç”¨burstæ¨¡å¼ï¼šä¸é˜»å¡ç­‰å¾…60sï¼Œæ”¹ä¸ºåˆ†æ‰¹å¿«é€Ÿè¯·æ±‚å¹¶åšçŸ­æš‚èŠ‚æµ
                    print(f"[INFO] TUSHAREä¸Šæ¬¡è°ƒç”¨{time_since_last_tushare:.1f}ç§’å‰ï¼Œå¯ç”¨ BURST æ¨¡å¼ï¼šåˆ†æ‰¹å¿«é€Ÿè¯·æ±‚ {len(primary_codes)} åªï¼ˆæ³¨æ„é¢‘ç‡é™åˆ¶ï¼‰")
                    primary_source = 'tushare'
                    burst_mode = True
                elif AKSHARE_AVAILABLE and self.akshare_enabled:
                    print(f"[INFO] TUSHAREéœ€ç­‰å¾… {wait_time:.1f} ç§’ï¼Œä½¿ç”¨AKShareè·å–å‰©ä½™ {len(primary_codes)} åª")
                    primary_source = 'akshare'
                else:
                    # å¦‚æœAKShareä¸å¯ç”¨ï¼Œä½¿ç”¨è…¾è®¯API
                    print(f"[INFO] TUSHAREéœ€ç­‰å¾… {wait_time:.1f} ç§’ï¼ŒAKShareä¸å¯ç”¨ï¼Œä½¿ç”¨è…¾è®¯APIè·å–å‰©ä½™ {len(primary_codes)} åª")
                    primary_source = 'tencent'
        
        print(f"[INFO] å¤‡ç”¨æ•°æ®æº: {primary_source.upper()}å¤„ç† {len(primary_codes)} åª")
        
        # 1. ä¸»è¦æ•°æ®æºå¤„ç†
        primary_success = []
        fallback_codes = []  # åˆå§‹åŒ–å¤±è´¥è‚¡ç¥¨åˆ—è¡¨
        if primary_source == 'tushare' and TUSHARE_AVAILABLE and self.tushare_token:
            print(f"[INFO] TUSHARE æ‰¹é‡å¤„ç† {len(primary_codes)} åªè‚¡ç¥¨...")
            print(f"[DEBUG] TUSHARE æ—¥æœŸèŒƒå›´: {start_str} åˆ° {end_str}")
            try:
                pro = ts.pro_api(self.tushare_token)
                
                # æ›´æ–°TUSHAREè°ƒç”¨æ—¶é—´ï¼ˆæŒ‰æ‰¹æ›´æ–°ä»¥ä¾¿èŠ‚æµæ§åˆ¶ï¼‰
                # å¦‚æœå¤„äºburst_modeï¼Œåˆ™å…è®¸å¿«é€Ÿè¿ç»­å¤šæ‰¹è¯·æ±‚ï¼Œä½†ä»åšçŸ­æš‚èŠ‚æµ
                if not burst_mode:
                    self.last_tushare_call = time.time()
                
                # ğŸ”´ ä¼˜åŒ–ï¼šæ ¹æ®æ—¥æœŸèŒƒå›´è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°
                # æ ¹æ®æ˜¯å¦ä» BAT è°ƒç”¨å†³å®šç­–ç•¥ï¼šBAT ä¸‹ä½¿ç”¨æ¿€è¿›ç­–ç•¥ä»¥æœ€å¤§åŒ–ååï¼Œå¸¸è§„è¿è¡Œä½¿ç”¨ä¿å®ˆç­–ç•¥
                bat_mode = os.getenv('TA_RUN_FROM_BAT', '0') == '1'
                days_count = max(1, self.kline_days)
                if bat_mode:
                    # BAT è¿è¡Œï¼šæ›´æ¿€è¿›çš„ä¼°ç®—ç³»æ•°å’Œæ›´é«˜å•æ¬¡è®°å½•ä¸Šé™
                    estimated_records_per_stock = max(1, int(days_count * 0.6))
                    max_records_per_call = 7800
                    computed_batch = max_records_per_call // estimated_records_per_stock
                    safe_batch_size = max(10, min(len(primary_codes), min(1000, computed_batch)))
                else:
                    # GUI/äº¤äº’å¼è¿è¡Œï¼šä¿å®ˆç­–ç•¥ï¼Œé¿å…å¶å‘è¶…é™å¯¼è‡´å¤±è´¥
                    estimated_records_per_stock = max(1, int(days_count * 0.7))
                    max_records_per_call = 7000
                    computed_batch = max_records_per_call // estimated_records_per_stock
                    safe_batch_size = max(10, min(len(primary_codes), min(100, computed_batch)))

                print(f"[INFO] TUSHAREæ™ºèƒ½åˆ†æ‰¹ (bat_mode={bat_mode}): é¢„è®¡æ¯è‚¡{estimated_records_per_stock}æ¡æ•°æ®, æ‰¹æ¬¡å¤§å°={safe_batch_size}åª/æ‰¹ (computed={computed_batch})")
                
                # åˆ†æ‰¹å¤„ç†
                for batch_idx in range(0, len(primary_codes), safe_batch_size):
                    batch_codes = primary_codes[batch_idx:batch_idx + safe_batch_size]
                    print(f"[INFO] TUSHAREå¤„ç†ç¬¬{batch_idx//safe_batch_size + 1}æ‰¹: {len(batch_codes)}åªè‚¡ç¥¨")
                    
                    # ğŸ”´ æ”¹è¿›ï¼šä½¿ç”¨ Tushare æ‰¹é‡æ¥å£ï¼Œæé«˜æ•ˆç‡å’ŒæˆåŠŸç‡
                    ts_code_map = {}
                    for code in batch_codes:
                        # æå–çº¯æ•°å­—éƒ¨åˆ†ï¼Œé˜²æ­¢é‡å¤æ·»åŠ åç¼€
                        pure_code = code.split('.')[0]
                        if pure_code.startswith(('000', '001', '002', '300', '301')):
                            ts_code = f"{pure_code}.SZ"
                        elif pure_code.startswith(('4', '8', '9')):
                            ts_code = f"{pure_code}.BJ"
                        else:
                            ts_code = f"{pure_code}.SH"
                        ts_code_map[ts_code] = code
                    
                    ts_codes_str = ",".join(ts_code_map.keys())
                    
                    try:
                        # æ‰¹é‡è·å–æ•°æ®
                        df = pro.daily(ts_code=ts_codes_str, start_date=start_str, end_date=end_str)
                        
                        if df is not None and not df.empty:
                            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„å¤„ç†
                            for ts_code, group in df.groupby('ts_code'):
                                orig_code = ts_code_map.get(ts_code)
                                if orig_code:
                                    standardized_df = self.standardize_kline_columns(group, 'tushare')
                                    result[orig_code] = standardized_df
                                    primary_success.append(orig_code)
                            
                            # æ£€æŸ¥å“ªäº›è‚¡ç¥¨æ²¡æœ‰è·å–åˆ°æ•°æ®
                            for ts_code, orig_code in ts_code_map.items():
                                if orig_code not in primary_success:
                                    print(f"[WARN] TUSHAREè·å–{orig_code} ({ts_code}) è¿”å›æ•°æ®ä¸ºç©ºï¼Œè½¬å…¥åå¤‡å¤„ç†")
                                    fallback_codes.append(orig_code)
                        else:
                            # æ•´æ‰¹å¤±è´¥ï¼Œå…¨éƒ¨è½¬å…¥åå¤‡å¤„ç†
                            fallback_codes.extend(batch_codes)
                    
                    except Exception as batch_e:
                        print(f"[WARN] TUSHARE ç¬¬{batch_idx//safe_batch_size + 1}æ‰¹è·å–å¤±è´¥: {batch_e}")
                        # æ•´æ‰¹å¤±è´¥ï¼Œè½¬å…¥åå¤‡å¤„ç†
                        fallback_codes.extend(batch_codes)

                    # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰
                    if batch_idx + safe_batch_size < len(primary_codes):
                        # å¦‚æœæ˜¯burstæ¨¡å¼ï¼Œä½¿ç”¨è¾ƒçŸ­çš„èŠ‚æµé—´éš”ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤çŸ­å»¶è¿Ÿ
                        if burst_mode:
                            # æé™æ¨¡å¼ï¼šä¿å®ˆçŸ­å»¶è¿Ÿï¼Œå°½é‡æ¨é«˜åå
                            time.sleep(0.6)
                        else:
                            time.sleep(1.0)

                    # æ¯æ¬¡æˆåŠŸæˆ–å¤±è´¥åæ›´æ–°ä¸Šæ¬¡è°ƒç”¨æ—¶é—´ï¼Œæ–¹ä¾¿ä¸‹ä¸€æ¬¡åˆ¤æ–­
                    self.last_tushare_call = time.time()
                
                print(f"[SUCCESS] TUSHARE æˆåŠŸ: {len(primary_success)}/{len(primary_codes)} åª")
            except Exception as e:
                print(f"[ERROR] TUSHARE æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
                fallback_codes.extend(primary_codes)
        
        elif primary_source == 'akshare' and AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
            print(f"[INFO] AKShare æ‰¹é‡å¤„ç† {len(primary_codes)} åªè‚¡ç¥¨...")
            try:
                # akshare.stock_zh_a_histå·²ç¦ç”¨ - é¿å…py_mini_racerå´©æºƒé—®é¢˜
                # ç›´æ¥è·³è¿‡akshareï¼Œä½¿ç”¨å…¶ä»–ç¨³å®šæ•°æ®æº
                print("[INFO] è·³è¿‡AKShareæ•°æ®æºï¼ˆé¿å…py_mini_racerå´©æºƒï¼‰ï¼Œä½¿ç”¨è…¾è®¯/å…¶ä»–æ•°æ®æº")
                pass  # ä¸ä½¿ç”¨akshare
                
                # åŸä»£ç å·²æ³¨é‡Šï¼š
                # for code in primary_codes:
                #     try:
                #         df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_iso, end_date=end_iso)
                #         if not df.empty:
                #             df = self.standardize_kline_columns(df, 'akshare')
                #             result[code] = df
                #             primary_success.append(code)
                #         time.sleep(0.2)
                #     except Exception as e:
                #         print(f"[WARN] AKShareè·å–{code}å¤±è´¥: {e}")
                #         fallback_codes.append(code)
                #         continue
                
                # print(f"[SUCCESS] AKShare æˆåŠŸ: {len(primary_success)}/{len(primary_codes)} åª")
            except Exception as e:
                print(f"[ERROR] AKShare å·²ç¦ç”¨ï¼Œè·³è¿‡")
                fallback_codes.extend(primary_codes)
        
        elif primary_source == 'tencent' and TENCENT_KLINE_AVAILABLE and self.tencent_kline:
            print(f"[INFO] è…¾è®¯Kçº¿API æ‰¹é‡å¤„ç† {len(primary_codes)} åªè‚¡ç¥¨...")
            try:
                # ä½¿ç”¨è…¾è®¯Kçº¿APIæ‰¹é‡è·å–
                tencent_results = self.tencent_kline.batch_get_klines(primary_codes, start_iso, end_iso)
                
                for code in primary_codes:
                    if code in tencent_results:
                        df = tencent_results[code]
                        if df is not None and not df.empty:
                            df = self.standardize_kline_columns(df, 'tencent')
                            if not df.empty:
                                result[code] = df
                                primary_success.append(code)
                                continue
                    fallback_codes.append(code)
                
                print(f"[SUCCESS] è…¾è®¯Kçº¿API æˆåŠŸ: {len(primary_success)}/{len(primary_codes)} åª")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯Kçº¿API æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
                fallback_codes.extend(primary_codes)
        else:
            print(f"[WARN] {primary_source.upper()} ä¸å¯ç”¨ï¼Œå°†æ‰€æœ‰è‚¡ç¥¨è½¬ä¸ºåå¤‡å¤„ç†")
            fallback_codes.extend(primary_codes)
        
        # 1.5 JoinQuant æ›¿ä»£å¤„ç† (å·²ç¦ç”¨ K çº¿åå¤‡ï¼Œä»…ä¿ç•™åŸºç¡€ä¿¡æ¯åå¤‡)
        # æ ¹æ®ç”¨æˆ·åé¦ˆï¼ŒJoinQuant æ‹¿ä¸åˆ° K çº¿æ—¶ä¸å†ä½œä¸º K çº¿åå¤‡æ•°æ®æº
        joinquant_success = []
        if False and fallback_codes and self.joinquant:
            print(f"[INFO] JoinQuant API æ›¿ä»£å¤„ç† {len(fallback_codes)} åªå¤±è´¥è‚¡ç¥¨...")
            try:
                temp_remaining = []
                for code in fallback_codes:
                    try:
                        df = self.joinquant.get_stock_kline(code, start_iso, end_iso)
                        if df is not None and not df.empty:
                            df = self.standardize_kline_columns(df, 'joinquant')
                            if not df.empty:
                                result[code] = df
                                joinquant_success.append(code)
                                continue
                        temp_remaining.append(code)
                    except Exception as e:
                        print(f"[WARN] JoinQuantè·å–{code}å¤±è´¥: {e}")
                        temp_remaining.append(code)
                
                fallback_codes = temp_remaining
                print(f"[SUCCESS] JoinQuant API æ›¿ä»£æˆåŠŸ: {len(joinquant_success)}/{len(joinquant_success) + len(fallback_codes)} åª")
            except Exception as e:
                print(f"[ERROR] JoinQuant API æ›¿ä»£å¤„ç†å¼‚å¸¸: {e}")
        
        # 2. å¤±è´¥è‚¡ç¥¨çš„å¤šçº§åå¤‡å¤„ç†ï¼šè…¾è®¯Kçº¿ â†’ AlphaVantage â†’ yfinance
        if fallback_codes:
            print(f"[INFO] æœ‰ {len(fallback_codes)} åªè‚¡ç¥¨éœ€è¦åå¤‡æ•°æ®æºå¤„ç†")
            print(f"[INFO] åå¤‡å¤„ç†é¡ºåº: è…¾è®¯Kçº¿ â†’ AlphaVantage â†’ yfinance")
            remaining_codes = fallback_codes.copy()
            
            # ç¬¬ä¸€çº§ï¼šè…¾è®¯Kçº¿æ›¿ä»£å¤„ç†
            tencent_success = []
            if remaining_codes and self.tencent_kline:
                print(f"[INFO] è…¾è®¯Kçº¿API æ›¿ä»£å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                try:
                    # ä½¿ç”¨è…¾è®¯Kçº¿APIæ‰¹é‡è·å–
                    tencent_results = self.tencent_kline.batch_get_klines(remaining_codes, start_iso, end_iso)
                    
                    temp_remaining = []
                    for code in remaining_codes:
                        if code in tencent_results:
                            df = tencent_results[code]
                            if df is not None and not df.empty:
                                df = self.standardize_kline_columns(df, 'tencent')
                                if not df.empty:
                                    result[code] = df
                                    tencent_success.append(code)
                                    continue
                        temp_remaining.append(code)
                    
                    remaining_codes = temp_remaining
                    print(f"[SUCCESS] è…¾è®¯Kçº¿API æ›¿ä»£æˆåŠŸ: {len(tencent_success)}/{len(fallback_codes)} åª")
                except Exception as e:
                    print(f"[ERROR] è…¾è®¯Kçº¿API æ›¿ä»£å¤„ç†å¼‚å¸¸: {e}")
            elif remaining_codes and not self.tencent_kline:
                print(f"[WARN] è…¾è®¯Kçº¿APIæœªåˆå§‹åŒ–ï¼Œè·³è¿‡å¤„ç† {len(remaining_codes)} åªè‚¡ç¥¨")
            
            # ç¬¬ä¸€çº§.5ï¼šæ–°æµªKçº¿æ›¿ä»£å¤„ç† (æ–°å¢)
            sina_success = []
            if remaining_codes and self.sina_kline:
                print(f"[INFO] æ–°æµªKçº¿API æ›¿ä»£å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                try:
                    temp_remaining = []
                    for code in remaining_codes:
                        try:
                            # è®¡ç®—å¤©æ•°
                            days = (datetime.now() - start_date).days + 5
                            df = self.sina_kline.get_stock_kline(code, days=days)
                            if df is not None and not df.empty:
                                df = self.standardize_kline_columns(df, 'sina')
                                if not df.empty:
                                    result[code] = df
                                    sina_success.append(code)
                                    time.sleep(0.2)  # ğŸ”´ å¢åŠ å°é‡å»¶è¿Ÿï¼Œé¿å…è¢«æ–°æµªå°ç¦
                                    continue
                            temp_remaining.append(code)
                        except Exception as e:
                            print(f"[WARN] æ–°æµªKçº¿è·å–{code}å¤±è´¥: {e}")
                            temp_remaining.append(code)
                    
                    remaining_codes = temp_remaining
                    print(f"[SUCCESS] æ–°æµªKçº¿API æ›¿ä»£æˆåŠŸ: {len(sina_success)}/{len(sina_success) + len(remaining_codes)} åª")
                except Exception as e:
                    print(f"[ERROR] æ–°æµªKçº¿API æ›¿ä»£å¤„ç†å¼‚å¸¸: {e}")

            # ç¬¬äºŒçº§ï¼šAPIè½®æ¢æ›¿ä»£å¤„ç† (Alpha Vantage)
            # ğŸ”´ æ”¹è¿›ï¼šæ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œä¸å†ä½¿ç”¨ Polygon è·å– K çº¿ï¼ŒPolygon å°†ç”¨äºè·å–æ–°é—»ç­‰å…¶ä»–æ•°æ®
            api_rotation_success = []
            if remaining_codes and self.alpha_vantage:
                print(f"[INFO] APIè½®æ¢æ›¿ä»£å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                try:
                    temp_remaining = []
                    for code in remaining_codes:
                        try:
                            # ğŸ”´ æ”¹è¿›ï¼šAlpha Vantage å¯¹ A è‚¡æ”¯æŒæå·®ä¸”é¢‘ç‡é™åˆ¶ä¸¥ï¼Œè·³è¿‡ A è‚¡
                            if self._detect_market(code) == 'cn':
                                # print(f"[SKIP] {code}: Aè‚¡è·³è¿‡ Alpha Vantage")
                                temp_remaining.append(code)
                                continue

                            # ğŸ”´ æ”¹è¿›ï¼šç›´æ¥ä½¿ç”¨ Alpha Vantageï¼Œä¸å†è½®æ¢ Polygon
                            api_name = 'alpha_vantage'
                            api_instance = self.alpha_vantage
                            
                            if not api_instance:
                                temp_remaining.append(code)
                                continue
                            
                            df = None
                            
                            # æ ¹æ®APIç±»å‹è°ƒç”¨ç›¸åº”æ–¹æ³•
                            if api_name == 'alpha_vantage':
                                print(f"[INFO] {code}: ä½¿ç”¨ Alpha Vantage")
                                df = api_instance.get_daily_kline(code, outputsize='compact')
                            
                            if df is not None and not df.empty:
                                # å¤„ç†æ•°æ®æ ¼å¼
                                df = df.reset_index()
                                if 'index' in df.columns:
                                    df = df.rename(columns={'index': 'date'})
                                
                                # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
                                if 'date' in df.columns:
                                    df['date'] = pd.to_datetime(df['date'])
                                    mask = (df['date'] >= start_date) & (df['date'] <= end_date)
                                    df = df[mask]
                                
                                if not df.empty:
                                    df = self.standardize_kline_columns(df, api_name)
                                    result[code] = df
                                    api_rotation_success.append(code)
                                    print(f"[SUCCESS] {code}: {api_name}è·å–æˆåŠŸ")
                                    continue
                            
                            temp_remaining.append(code)
                            # Alpha Vantage å…è´¹ç‰ˆæœ‰é¢‘ç‡é™åˆ¶ï¼Œé€‚å½“ç­‰å¾…
                            time.sleep(12) 
                        except Exception as e:
                            print(f"[WARN] APIè½®æ¢è·å–{code}å¤±è´¥: {e}")
                            temp_remaining.append(code)
                    
                    remaining_codes = temp_remaining
                    print(f"[SUCCESS] APIè½®æ¢æ›¿ä»£æˆåŠŸ: {len(api_rotation_success)}/{len(fallback_codes)} åª")
                except Exception as e:
                    print(f"[ERROR] APIè½®æ¢æ›¿ä»£å¤„ç†å¼‚å¸¸: {e}")

            # ç¬¬ä¸‰çº§ï¼šBaoStock æœ€ç»ˆå…œåº• (é’ˆå¯¹ A è‚¡æœ€ç¨³å®šçš„å…è´¹æº)
            baostock_success = []
            if remaining_codes and BAOSTOCK_AVAILABLE:
                print(f"[INFO] BaoStock API æœ€ç»ˆå…œåº•å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                try:
                    # ğŸ”´ æ”¹è¿›ï¼šç¡®ä¿ BaoStockAPI å·²åˆå§‹åŒ–
                    if not hasattr(self, 'baostock_api') or self.baostock_api is None:
                        from baostock_api import BaoStockAPI
                        self.baostock_api = BaoStockAPI()
                    
                    temp_remaining = []
                    for code in remaining_codes:
                        try:
                            # è®¡ç®—å¤©æ•°
                            days = (datetime.now() - start_date).days + 5
                            df = self.baostock_api.get_stock_kline(code, days=days)
                            if df is not None and not df.empty:
                                df = self.standardize_kline_columns(df, 'baostock')
                                if not df.empty:
                                    result[code] = df
                                    baostock_success.append(code)
                                    print(f"[SUCCESS] BaoStock å…œåº•è·å– {code} æˆåŠŸ")
                                    continue
                            temp_remaining.append(code)
                        except Exception as e:
                            print(f"[WARN] BaoStockè·å–{code}å¤±è´¥: {e}")
                            temp_remaining.append(code)
                    
                    remaining_codes = temp_remaining
                    print(f"[SUCCESS] BaoStock æœ€ç»ˆå…œåº•å®Œæˆ: {len(baostock_success)} åªæˆåŠŸ")
                except Exception as e:
                    print(f"[ERROR] BaoStock å…œåº•å¤„ç†å¼‚å¸¸: {e}")
            elif remaining_codes and not (self.alpha_vantage or (self.polygon and self.polygon.is_available)):
                print(f"[WARN] APIè½®æ¢ä¸å¯ç”¨ï¼Œè·³è¿‡å¤„ç† {len(remaining_codes)} åªè‚¡ç¥¨")
            
            # ç¬¬ä¸‰çº§ï¼šyfinanceæœ€ç»ˆå…œåº•å¤„ç†
            yfinance_success = []
            if remaining_codes:
                print(f"[INFO] yfinance æœ€ç»ˆå…œåº•å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                try:
                    # ä½¿ç”¨yfinanceæ‰¹é‡è·å–
                    yf_results = self._collect_batch_basic_info_with_yfinance(remaining_codes)
                    
                    temp_remaining = []
                    for code in remaining_codes:
                        if code in yf_results and 'kline_data' in yf_results[code]:
                            df = yf_results[code]['kline_data']
                            if df is not None and not df.empty:
                                # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
                                if 'date' in df.columns:
                                    df['date'] = pd.to_datetime(df['date'])
                                    mask = (df['date'] >= start_date) & (df['date'] <= end_date)
                                    df = df[mask]
                                
                                if not df.empty:
                                    result[code] = df
                                    yfinance_success.append(code)
                                    continue
                        temp_remaining.append(code)
                    
                    remaining_codes = temp_remaining
                    print(f"[SUCCESS] yfinance å…œåº•æˆåŠŸ: {len(yfinance_success)}/{len(fallback_codes)} åª")
                except Exception as e:
                    print(f"[ERROR] yfinance å…œåº•å¤„ç†å¼‚å¸¸: {e}")
            
            final_failed_codes = remaining_codes
        else:
            baostock_success = []
            alpha_success = []
            yfinance_success = []
            final_failed_codes = []
            
            # å…ˆå°è¯•ç”¨å¦ä¸€ä¸ªæ•°æ®æº
            secondary_source = 'akshare' if primary_source == 'tushare' else 'tushare'
            secondary_success = []
            remaining_codes = fallback_codes.copy()
            
            if False:  # akshareå·²ç¦ç”¨ - é¿å…py_mini_racerå´©æºƒ
                print(f"[INFO] è·³è¿‡AKShareæ›¿ä»£å¤„ç†ï¼ˆé¿å…py_mini_racerå´©æºƒï¼‰")
                # åŸä»£ç å·²å…¨éƒ¨æ³¨é‡Š
                # temp_remaining = []
                # for code in remaining_codes:
                #     try:
                #         df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_iso, end_date=end_iso)
                #         if not df.empty:
                #             df = self.standardize_kline_columns(df, 'akshare')
                #             result[code] = df
                #             secondary_success.append(code)
                #         else:
                #             temp_remaining.append(code)
                #         time.sleep(0.2)
                #     except Exception as e:
                #         print(f"[WARN] AKShareæ›¿ä»£è·å–{code}å¤±è´¥: {e}")
                #         temp_remaining.append(code)
                # remaining_codes = temp_remaining
                # print(f"[SUCCESS] AKShare æ›¿ä»£æˆåŠŸ: {len(secondary_success)}/{len(fallback_codes)} åª")
            
            elif secondary_source == 'tushare' and TUSHARE_AVAILABLE and self.tushare_token:
                # ğŸ”´ ä¿®å¤ï¼šå¦‚æœéœ€è¦ç­‰å¾…ï¼Œå°±ç­‰å¾…ï¼ˆå› ä¸ºyfinanceå·²ç¦ç”¨ï¼‰
                current_time = time.time()
                if current_time - self.last_tushare_call < 60:
                    wait_time = 60 - (current_time - self.last_tushare_call)
                    print(f"[INFO] TUSHAREéœ€ç­‰å¾… {wait_time:.1f} ç§’ï¼Œå¼€å§‹ç­‰å¾…...")
                    time.sleep(wait_time)
                
                print(f"[INFO] TUSHARE æ›¿ä»£å¤„ç† {len(remaining_codes)} åªå¤±è´¥è‚¡ç¥¨...")
                pro = ts.pro_api(self.tushare_token)
                self.last_tushare_call = time.time()
                
                temp_remaining = []
                for code in remaining_codes:
                    try:
                        # ä¼˜åŒ–è‚¡ç¥¨ä»£ç åç¼€é€»è¾‘
                        if code.startswith(('000', '001', '002', '300', '301')):
                            ts_code = f"{code}.SZ"
                        elif code.startswith(('4', '8', '9')):
                            ts_code = f"{code}.BJ"
                        else:
                            ts_code = f"{code}.SH"
                        
                        df = pro.daily(ts_code=ts_code, start_date=start_str, end_date=end_str)
                        if df is not None and not df.empty:
                            df = self.standardize_kline_columns(df, 'tushare')
                            result[code] = df
                            secondary_success.append(code)
                        else:
                            temp_remaining.append(code)
                    except Exception as e:
                        print(f"[WARN] TUSHAREæ›¿ä»£è·å–{code}å¤±è´¥: {e}")
                        temp_remaining.append(code)
                remaining_codes = temp_remaining
                print(f"[SUCCESS] TUSHARE æ›¿ä»£æˆåŠŸ: {len(secondary_success)}/{len(fallback_codes)} åª")
            
            # æœ€åå°è¯•JoinQuant
            final_failed_codes = remaining_codes
        
        # ç°åœ¨æ‰€æœ‰å¤„ç†é€»è¾‘å·²å®Œæˆï¼Œç»Ÿè®¡æœ€ç»ˆç»“æœ
        if not 'baostock_success' in locals():
            baostock_success = []
        if not 'alpha_success' in locals():
            alpha_success = []  
        if not 'yfinance_success' in locals():
            yfinance_success = []
        
        # 3. AKShareå…œåº•å¤„ç† - å·²ç¦ç”¨ï¼ˆé¿å…py_mini_racerå´©æºƒï¼‰
        akshare_fallback_success = []
        if False:  # akshareå·²ç¦ç”¨
            print(f"[INFO] è·³è¿‡AKShareå…œåº•å¤„ç†ï¼ˆé¿å…py_mini_racerå´©æºƒï¼‰")
            try:
                temp_remaining = []
                for code in final_failed_codes:
                    try:
                        df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_iso, end_date=end_iso)
                        if df is not None and not df.empty:
                            df = self.standardize_kline_columns(df, 'akshare')
                            if not df.empty:
                                result[code] = df
                                akshare_fallback_success.append(code)
                        else:
                            temp_remaining.append(code)
                    except Exception as e:
                        print(f"[WARN] AKShareå…œåº• {code} å¤±è´¥: {type(e).__name__}: {e}")
                        temp_remaining.append(code)
                    time.sleep(0.2)
                final_failed_codes = temp_remaining
                print(f"[SUCCESS] AKShare å…œåº•æˆåŠŸ: {len(akshare_fallback_success)}/{len(final_failed_codes) + len(akshare_fallback_success)} åª")
            except Exception as e:
                print(f"[ERROR] AKShare å…œåº•å¤„ç†å¼‚å¸¸: {type(e).__name__}: {e}")
        elif final_failed_codes and not (AKSHARE_AVAILABLE and AKSHARE_CONNECTED):
            print(f"[WARN] AKShare ä¸å¯ç”¨ï¼Œæ— æ³•å…œåº•å¤„ç† {len(final_failed_codes)} åªè‚¡ç¥¨")
            
        # 4. è…¾è®¯Kçº¿å…œåº•å¤„ç†
        tencent_fallback_success = []
        if final_failed_codes and self.tencent_kline:
            print(f"[INFO] è…¾è®¯Kçº¿ å…œåº•å¤„ç† {len(final_failed_codes)} åªå¤±è´¥è‚¡ç¥¨...")
            try:
                temp_remaining = []
                for code in final_failed_codes:
                    try:
                        df = self.tencent_kline.get_stock_kline(code, start_iso, end_iso)
                        if df is not None and not df.empty:
                            df = self.standardize_kline_columns(df, 'tencent')
                            if not df.empty:
                                result[code] = df
                                tencent_fallback_success.append(code)
                        else:
                            temp_remaining.append(code)
                    except Exception as e:
                        print(f"[WARN] è…¾è®¯Kçº¿å…œåº• {code} å¤±è´¥: {e}")
                        temp_remaining.append(code)
                    time.sleep(0.1)
                final_failed_codes = temp_remaining
                print(f"[SUCCESS] è…¾è®¯Kçº¿ å…œåº•æˆåŠŸ: {len(tencent_fallback_success)}/{len(final_failed_codes) + len(tencent_fallback_success)} åª")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯Kçº¿ å…œåº•å¤„ç†å¼‚å¸¸: {e}")
        
        # 5. BaoStockå…œåº•å¤„ç†ï¼ˆç¨³å®šæ€§å¥½ï¼‰
        baostock_success = []
        if final_failed_codes and self.baostock and self.baostock.is_connected:
            print(f"[INFO] BaoStock å…œåº•å¤„ç† {len(final_failed_codes)} åªæœ€ç»ˆå¤±è´¥è‚¡ç¥¨...")
            try:
                # è®¡ç®—è·å–å¤©æ•°
                days = max(30, self.kline_days)
                
                # ä½¿ç”¨BaoStockæ‰¹é‡è·å–
                bs_results = self.baostock.batch_get_klines(final_failed_codes, days)
                
                temp_remaining = []
                for code in final_failed_codes:
                    if code in bs_results and bs_results[code] is not None and not bs_results[code].empty:
                        df = self.standardize_kline_columns(bs_results[code], 'baostock')
                        if not df.empty:
                            result[code] = df
                            baostock_success.append(code)
                    else:
                        temp_remaining.append(code)
                final_failed_codes = temp_remaining
                
                print(f"[SUCCESS] BaoStock å…œåº•æˆåŠŸ: {len(baostock_success)}/{len(final_failed_codes) + len(baostock_success)} åª")
            except Exception as e:
                print(f"[ERROR] BaoStock å…œåº•å¤„ç†å¼‚å¸¸: {e}")
        elif final_failed_codes and not (self.baostock and getattr(self.baostock, 'is_connected', False)):
            print(f"[WARN] BaoStock APIæœªè¿æ¥ï¼Œæ— æ³•å…œåº•å¤„ç† {len(final_failed_codes)} åªè‚¡ç¥¨")
        
        # 6. Alpha Vantageæœ€åå…œåº•å¤„ç†ï¼ˆä»…é™ç¾è‚¡/ADRï¼‰
        still_failed = [code for code in codes if code not in result]
        # è¿‡æ»¤Aè‚¡ä»£ç ï¼ŒAlpha Vantageä¸»è¦æ”¯æŒç¾è‚¡/ADR
        alpha_candidate_codes = [code for code in still_failed 
                               if self._detect_market(code) != 'cn']
        a_stock_codes = [code for code in still_failed if code not in alpha_candidate_codes]
        
        alpha_success = []
        if alpha_candidate_codes and self.alpha_vantage:
            print(f"[INFO] Alpha Vantage æœ€ç»ˆå…œåº•å¤„ç† {len(alpha_candidate_codes)} åªå¯èƒ½çš„ç¾è‚¡/ADRä»£ç ...")
            if a_stock_codes:
                print(f"[SKIP] è·³è¿‡ {len(a_stock_codes)} åªAè‚¡ä»£ç ï¼ˆAlpha Vantageä¸æ”¯æŒï¼‰")
            try:
                for code in alpha_candidate_codes:
                    try:
                        df = self.alpha_vantage.get_daily_kline(code, outputsize='compact')
                        if df is not None and not df.empty:
                            # å¤„ç†Alpha Vantageæ•°æ®æ ¼å¼
                            df = df.reset_index()
                            df = df.rename(columns={'index': 'date'})
                            
                            # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
                            if 'date' in df.columns:
                                df['date'] = pd.to_datetime(df['date'])
                                mask = (df['date'] >= start_date) & (df['date'] <= end_date)
                                df = df[mask]
                            
                            df = self.standardize_kline_columns(df, 'alpha_vantage')
                            if not df.empty:
                                result[code] = df
                                alpha_success.append(code)
                                print(f"[SUCCESS] Alpha Vantageå…œåº• {code}: {len(df)} è¡Œ")
                        
                    except Exception as e:
                        print(f"[WARN] Alpha Vantageå…œåº•{code}å¤±è´¥: {e}")
                        continue
                
                print(f"[SUCCESS] Alpha Vantage å…œåº•æˆåŠŸ: {len(alpha_success)}/{len(still_failed)}")
            except Exception as e:
                print(f"[ERROR] Alpha Vantage å…œåº•å¤„ç†å¼‚å¸¸: {e}")
        elif still_failed and not self.alpha_vantage:
            print(f"[WARN] Alpha Vantage APIæœªåˆå§‹åŒ–ï¼Œæ— æ³•å…œåº•å¤„ç† {len(still_failed)} åªè‚¡ç¥¨")
        
        # 7. Jina API æœ€ç»ˆå°è¯• (æ–°å¢)
        jina_success = []
        still_failed = [code for code in codes if code not in result]
        if still_failed and self.jina_api:
            print(f"[INFO] Jina API æœ€ç»ˆå°è¯•å¤„ç† {len(still_failed)} åªå¤±è´¥è‚¡ç¥¨...")
            try:
                for code in still_failed:
                    try:
                        # å°è¯•é€šè¿‡Jinaæœç´¢è·å–Kçº¿æ•°æ® (å®éªŒæ€§)
                        query = f"è‚¡ç¥¨ {code} æœ€è¿‘30å¤©Kçº¿æ•°æ® OHLC"
                        search_result = self.jina_api.search(query)
                        
                        # è¿™é‡Œéœ€è¦å¤æ‚çš„è§£æé€»è¾‘ï¼Œæš‚æ—¶è®°å½•æ—¥å¿—
                        if search_result and len(search_result) > 100:
                            print(f"[INFO] Jina API æœç´¢åˆ° {code} ç›¸å…³ä¿¡æ¯ï¼Œä½†è§£æé€»è¾‘å°šæœªå®Œå–„")
                        
                    except Exception as e:
                        print(f"[WARN] Jina API å¤„ç†{code}å¤±è´¥: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] Jina API å¤„ç†å¼‚å¸¸: {e}")

        # ç»Ÿè®¡æœ€ç»ˆç»“æœ
        success_count = len(result)
        success_rate = (success_count / total_codes) * 100 if total_codes > 0 else 0
        
        print(f"[SUMMARY] Kçº¿æ•°æ®é‡‡é›†å®Œæˆ: {success_count}/{total_codes} åªæˆåŠŸ ({success_rate:.1f}%)")
        
        # æŒ‰æ•°æ®æºç»Ÿè®¡æˆåŠŸæƒ…å†µ
        print(f"[DETAIL] å„æ•°æ®æºè¡¨ç°:")
        if 'choice_success' in locals() and choice_success:
            print(f"  Choice: {len(choice_success)} åª")
        
        if primary_source == 'tushare':
            print(f"  TUSHARE(ä¸»): {len(primary_success)}/{len(primary_codes)} ({len(primary_success)/len(primary_codes)*100:.1f}%)" if primary_codes else "  TUSHARE(ä¸»): 0/0")
        elif primary_source == 'akshare':
            print(f"  AKShare(ä¸»): {len(primary_success)}/{len(primary_codes)} ({len(primary_success)/len(primary_codes)*100:.1f}%)" if primary_codes else "  AKShare(ä¸»): 0/0")
        
        if 'joinquant_success' in locals() and joinquant_success:
            print(f"  JoinQuant: {len(joinquant_success)} åª")
        if 'tencent_success' in locals() and tencent_success:
            print(f"  Tencent(æ›¿ä»£): {len(tencent_success)} åª")
        if 'sina_success' in locals() and sina_success:
            print(f"  Sina(æ›¿ä»£): {len(sina_success)} åª")
        if 'api_rotation_success' in locals() and api_rotation_success:
            print(f"  API Rotation: {len(api_rotation_success)} åª")
        if 'yfinance_success' in locals() and yfinance_success:
            print(f"  yfinance: {len(yfinance_success)} åª")
        if 'baostock_success' in locals() and baostock_success:
            print(f"  BaoStock: {len(baostock_success)} åª")
        if 'alpha_success' in locals() and alpha_success:
            print(f"  Alpha Vantage: {len(alpha_success)} åª")
        
        return result
        
        if 'final_failed_codes' in locals() and final_failed_codes:
            print(f"  BaoStock(å…œåº•): {len(baostock_success)}/{len(final_failed_codes)}")
        if 'still_failed' in locals() and still_failed:
            print(f"  Alpha Vantage(æœ€ç»ˆ): {len(alpha_success)}/{len(still_failed)}")
        
        return result
    
    def collect_batch_other_data(self, codes: List[str]) -> Dict[str, Dict]:
        """æ‰¹é‡é‡‡é›†å…¶ä»–ä¿¡æ¯ - æ–°ç­–ç•¥: æ•°æ®æºä¸“ä¸šåŒ–åˆ†å·¥ + æ‰¹é‡ä¼˜åŒ– + å…œåº•ä¿éšœ"""
        result = {}
        total_codes = len(codes)
        
        print(f"[INFO] å¼€å§‹é‡‡é›†å…¶ä»–ä¿¡æ¯ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        print(f"[INFO] æ•°æ®åˆ†å·¥ç­–ç•¥: baostock(åŸºç¡€+è´¢åŠ¡) â†’ è…¾è®¯(å®æ—¶+èµ„é‡‘) â†’ yfinance(å›½é™…åŒ–) â†’ akshare(å…œåº•)")
        
        # æ•°æ®åˆ†é…ç­–ç•¥ï¼šæŒ‰æ•°æ®ç±»å‹åˆ†å·¥ï¼Œé¿å…é‡å¤è¯·æ±‚
        baostock_codes = codes.copy()  # baostockå¤„ç†æ‰€æœ‰åŸºç¡€ä¿¡æ¯+è´¢åŠ¡æ•°æ®
        tencent_codes = codes.copy()   # è…¾è®¯å¤„ç†å®æ—¶æ•°æ®+èµ„é‡‘æµå‘
        yfinance_codes = []            # yfinanceä½œä¸ºå›½é™…åŒ–è¡¥å……
        failed_codes = []              # å¤±è´¥è‚¡ç¥¨ç”¨akshareå…œåº•
        
        # 1. Baostockæ‰¹é‡è·å–ï¼šåŸºç¡€ä¿¡æ¯ + è´¢åŠ¡æ•°æ®ï¼ˆä¸“ä¸šå¼ºé¡¹ï¼‰
        baostock_success = []
        if BAOSTOCK_AVAILABLE and self.bs_login:
            print(f"[INFO] Baostockä¸“é¡¹ï¼šåŸºç¡€ä¿¡æ¯+è´¢åŠ¡æ•°æ® {len(baostock_codes)} åª...")
            try:
                for code in baostock_codes:
                    try:
                        bs_code = f"sz.{code}" if code.startswith(('000', '002', '300')) else f"sh.{code}"
                        
                        # åŸºç¡€ä¿¡æ¯
                        basic_info = {'code': code, 'source': 'baostock'}
                        rs_basic = bs.query_stock_basic(code=bs_code)
                        if rs_basic.error_code == '0':
                            while rs_basic.next():
                                row = rs_basic.get_row_data()
                                if len(row) > 6:
                                    basic_info.update({
                                        'name': row[1],
                                        'type': row[2],
                                        'status': row[3],
                                        'industry': row[4],
                                        'listing_date': row[6]
                                    })
                                    break
                        
                        # è´¢åŠ¡æ•°æ®ï¼ˆæœ€æ–°å­£åº¦ï¼‰
                        financial_info = {}
                        rs_profit = bs.query_profit_data(code=bs_code, year="2024", quarter=3)
                        if rs_profit.error_code == '0':
                            while rs_profit.next():
                                row = rs_profit.get_row_data()
                                if len(row) > 7:
                                    financial_info.update({
                                        'revenue': self._safe_float(row[4]),
                                        'net_profit': self._safe_float(row[5]),
                                        'eps': self._safe_float(row[6]),
                                        'roe': self._safe_float(row[7])
                                    })
                                    break
                        
                        # ä¼°å€¼æ•°æ®
                        rs_dupont = bs.query_dupont_data(code=bs_code, year="2024", quarter=3)
                        if rs_dupont.error_code == '0':
                            while rs_dupont.next():
                                row = rs_dupont.get_row_data()
                                if len(row) > 5:
                                    financial_info.update({
                                        'roa': self._safe_float(row[4]),
                                        'gross_profit_rate': self._safe_float(row[5])
                                    })
                                    break
                        
                        result[code] = {**basic_info, **financial_info}
                        baostock_success.append(code)
                        time.sleep(0.05)  # baostockæ§é¢‘
                        
                    except Exception as e:
                        print(f"[WARN] Baostock {code} å¤±è´¥: {e}")
                        continue
                
                print(f"[SUCCESS] Baostockå®Œæˆ: {len(baostock_success)}/{len(baostock_codes)} åª")
            except Exception as e:
                print(f"[ERROR] Baostockæ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
        
        # 2. è…¾è®¯æ‰¹é‡è·å–ï¼šå®æ—¶ä»·æ ¼ + èµ„é‡‘æµå‘ï¼ˆé€Ÿåº¦ä¼˜åŠ¿ï¼‰
        tencent_success = []
        if REQUESTS_AVAILABLE:
            print(f"[INFO] è…¾è®¯ä¸“é¡¹ï¼šå®æ—¶ä»·æ ¼+èµ„é‡‘æµå‘ {len(tencent_codes)} åª...")
            try:
                # æ‰¹é‡è·å–å®æ—¶ä»·æ ¼ï¼ˆè…¾è®¯æ”¯æŒæ‰¹é‡æŸ¥è¯¢ï¼‰
                batch_symbols = ','.join([f's_{code}' for code in tencent_codes])
                url = f'https://qt.gtimg.cn/q={batch_symbols}'
                
                response = requests.get(url, timeout=15)
                if response.status_code == 200:
                    lines = response.text.split('\n')
                    for i, line in enumerate(lines):
                        if i >= len(tencent_codes) or not line.strip():
                            continue
                        
                        code = tencent_codes[i]
                        try:
                            parts = line.split('~')
                            if len(parts) > 10:
                                if code not in result:
                                    result[code] = {'code': code}
                                
                                result[code].update({
                                    'name': parts[1],
                                    'current_price': self._safe_float(parts[3]),
                                    'price_change': self._safe_float(parts[4]),
                                    'price_change_pct': self._safe_float(parts[5]),
                                    'volume': self._safe_float(parts[6]),
                                    'turnover': self._safe_float(parts[7]),
                                    'market_value': self._safe_float(parts[45]) if len(parts) > 45 else None,
                                    'tencent_source': True
                                })
                                tencent_success.append(code)
                        except Exception as e:
                            print(f"[WARN] è…¾è®¯è§£æ {code} å¤±è´¥: {e}")
                            continue
                
                print(f"[SUCCESS] è…¾è®¯å®Œæˆ: {len(tencent_success)}/{len(tencent_codes)} åª")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
        
        # 3. YFinanceè¡¥å……ï¼šå›½é™…åŒ–æ•°æ®ï¼ˆå¯¹æ¸¯è‚¡é€šç­‰æœ‰ä¼˜åŠ¿ï¼‰
        international_codes = [code for code in codes if code.startswith('00') or code in ['000001', '000002']]  # é€‰æ‹©æ€§ä½¿ç”¨
        if international_codes and YFINANCE_AVAILABLE:
            print(f"[INFO] YFinanceè¡¥å……ï¼šå›½é™…åŒ–æ•°æ® {len(international_codes)} åª...")
            try:
                for code in international_codes:
                    try:
                        symbol = f"{code}.SZ" if code.startswith(('000', '002', '300')) else f"{code}.SS"
                        ticker = yf.Ticker(symbol)
                        info = ticker.info
                        
                        if info and code not in result:
                            result[code] = {'code': code}
                        
                        if info:
                            result[code].update({
                                'market_cap': info.get('marketCap'),
                                'pe_ratio': info.get('trailingPE'),
                                'pb_ratio': info.get('priceToBook'),
                                'dividend_yield': info.get('dividendYield'),
                                'beta': info.get('beta'),
                                'yfinance_source': True
                            })
                        
                        time.sleep(0.2) # yfinanceæ§é¢‘
                    except Exception as e:
                        print(f"[WARN] YFinance {code} å¤±è´¥: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] YFinanceå¤„ç†å¼‚å¸¸: {e}")
        
        # 4. AKShareå…œåº•ï¼šå¤„ç†å‰é¢æ•°æ®æºå¤±è´¥çš„è‚¡ç¥¨
        failed_codes = [code for code in codes if code not in result or not result[code].get('name')]
        if failed_codes and AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
            print(f"[INFO] AKShareå…œåº•ï¼šå¤„ç†å¤±è´¥è‚¡ç¥¨ {len(failed_codes)} åª...")
            try:
                for code in failed_codes:
                    try:
                        # åŸºç¡€ä¿¡æ¯
                        df_info = ak.stock_individual_info_em(symbol=code)
                        if df_info is not None and not df_info.empty:
                            info_dict = dict(zip(df_info['item'], df_info['value']))
                            
                            if code not in result:
                                result[code] = {'code': code}
                            
                            result[code].update({
                                'name': info_dict.get('è‚¡ç¥¨ç®€ç§°', f'è‚¡ç¥¨{code}'),
                                'industry': info_dict.get('è¡Œä¸š'),
                                'concept': info_dict.get('æ¦‚å¿µ'),
                                'area': info_dict.get('åœ°åŒº'),
                                'market_cap': self._safe_float(info_dict.get('æ€»å¸‚å€¼')),
                                'pe_ratio': self._safe_float(info_dict.get('å¸‚ç›ˆç‡')),
                                'pb_ratio': self._safe_float(info_dict.get('å¸‚å‡€ç‡')),
                                'akshare_source': True
                            })
                        
                        time.sleep(0.3)  # akshareæ§é¢‘
                    except Exception as e:
                        print(f"[WARN] AKShareå…œåº• {code} å¤±è´¥: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] AKShareå…œåº•å¤„ç†å¼‚å¸¸: {e}")
        
        # 2. å¯¹å¤±è´¥çš„è‚¡ç¥¨ä½¿ç”¨è…¾è®¯API
        failed_codes = [code for code in codes if code not in result]
        if failed_codes:
            print(f"[INFO] ä½¿ç”¨è…¾è®¯APIå¤„ç†å‰©ä½™ {len(failed_codes)} åªè‚¡ç¥¨...")
            tencent_success = []
            try:
                # è…¾è®¯APIæ”¯æŒæ‰¹é‡æŸ¥è¯¢ï¼Œæ¯æ¬¡æœ€å¤š20åª
                for i in range(0, len(failed_codes), 20):
                    batch_codes = failed_codes[i:i+20]
                    try:
                        # æ„é€ è…¾è®¯APIæ‰¹é‡æŸ¥è¯¢URL
                        code_str = ','.join([f"{'sz' if c.startswith(('000', '002', '300')) else 'sh'}{c}" for c in batch_codes])
                        url = f"http://qt.gtimg.cn/q={code_str}"
                        
                        response = requests.get(url, timeout=10)
                        if response.status_code == 200:
                            lines = response.text.strip().split('\n')
                            for j, line in enumerate(lines):
                                if j < len(batch_codes):
                                    code = batch_codes[j]
                                    try:
                                        # è§£æè…¾è®¯è¿”å›æ•°æ®
                                        data_parts = line.split('~')
                                        if len(data_parts) > 10:
                                            result[code] = {
                                                'code': code,
                                                'name': data_parts[1],
                                                'price': data_parts[3],
                                                'change': data_parts[5],
                                                'change_pct': data_parts[6],
                                                'volume': data_parts[36],
                                                'source': 'tencent'
                                            }
                                            tencent_success.append(code)
                                    except Exception as e:
                                        print(f"[WARN] è…¾è®¯æ•°æ®è§£æå¤±è´¥ {code}: {e}")
                        
                        time.sleep(0.5)  # æ‰¹é‡è¯·æ±‚é—´éš”
                        
                    except Exception as e:
                        print(f"[WARN] è…¾è®¯APIæ‰¹é‡è¯·æ±‚å¤±è´¥: {e}")
                        continue
                
                print(f"[SUCCESS] è…¾è®¯API æˆåŠŸè·å– {len(tencent_success)} åªè‚¡ç¥¨ä¿¡æ¯")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯API æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        
        success_count = len(result)
        print(f"[SUMMARY] å…¶ä»–ä¿¡æ¯é‡‡é›†å®Œæˆ: {success_count}/{total_codes} åªæˆåŠŸ")
        return result
    
    def _collect_batch_kline_legacy(self, codes: List[str]) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡é‡‡é›†Kçº¿æ•°æ® - tushare â†’ akshareè½®æµï¼Œyfinanceå…œåº•ï¼ˆé—ç•™æ–¹æ³•ï¼‰"""
        result = {}
        total_codes = len(codes)
        batch_size = 15  # æ¯æ‰¹15åªè‚¡ç¥¨
        
        print(f"[INFO] å¼€å§‹æ‰¹é‡Kçº¿æ•°æ®é‡‡é›†ï¼Œæ€»è®¡ {total_codes} åªè‚¡ç¥¨ï¼Œ{batch_size}åª/æ‰¹")
        
        # å°†è‚¡ç¥¨åˆ†æ‰¹
        batches = [codes[i:i + batch_size] for i in range(0, len(codes), batch_size)]
        failed_codes = []  # è®°å½•å¤±è´¥çš„è‚¡ç¥¨ä»£ç 
        
        for batch_num, batch_codes in enumerate(batches):
            print(f"\n=== ç¬¬ {batch_num + 1} æ‰¹ / å…± {len(batches)} æ‰¹ ===")
            print(f"è‚¡ç¥¨ä»£ç : {', '.join(batch_codes)}")
            
            # è½®æµä½¿ç”¨tushareå’Œakshare
            if batch_num % 2 == 0:  # å¶æ•°æ‰¹ä½¿ç”¨tushare
                batch_result = self._collect_batch_kline_with_tushare(batch_codes)
                print(f"[INFO] ç¬¬{batch_num + 1}æ‰¹ä½¿ç”¨tushareè·å–Kçº¿æ•°æ®: {len(batch_result)}/{len(batch_codes)} æˆåŠŸ")
            else:  # å¥‡æ•°æ‰¹ä½¿ç”¨akshare
                batch_result = self._collect_batch_kline_with_akshare(batch_codes)
                print(f"[INFO] ç¬¬{batch_num + 1}æ‰¹ä½¿ç”¨akshareè·å–Kçº¿æ•°æ®: {len(batch_result)}/{len(batch_codes)} æˆåŠŸ")
            
            # åˆå¹¶æˆåŠŸçš„ç»“æœ
            result.update(batch_result)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„è‚¡ç¥¨
            batch_failed = [code for code in batch_codes if code not in batch_result]
            if batch_failed:
                failed_codes.extend(batch_failed)
                print(f"[WARN] ç¬¬{batch_num + 1}æ‰¹å¤±è´¥è‚¡ç¥¨: {batch_failed}")
        
        # å¦‚æœæœ‰å¤±è´¥çš„è‚¡ç¥¨ï¼Œä½¿ç”¨yfinanceå…œåº•
        if failed_codes:
            print(f"\n[INFO] ä½¿ç”¨yfinanceå…œåº•é‡‡é›† {len(failed_codes)} åªå¤±è´¥è‚¡ç¥¨...")
            fallback_result = self._collect_batch_kline_with_yfinance(failed_codes)
            result.update(fallback_result)
            print(f"[INFO] yfinanceå…œåº•å®Œæˆ: {len(fallback_result)}/{len(failed_codes)} æˆåŠŸ")
            
            # æ£€æŸ¥æœ€ç»ˆä»ç„¶å¤±è´¥çš„è‚¡ç¥¨
            final_failed = [code for code in failed_codes if code not in fallback_result]
            if final_failed:
                print(f"[WARN] æœ€ç»ˆå¤±è´¥çš„è‚¡ç¥¨ ({len(final_failed)}): {final_failed}")
        
        print(f"\n[INFO] Kçº¿æ•°æ®é‡‡é›†å®Œæˆ: {len(result)}/{total_codes} æ€»ä½“æˆåŠŸç‡ {len(result)/total_codes*100:.1f}%")
        return result
    
    def _select_optimal_kline_source(self) -> str:
        """é€‰æ‹©æœ€ä½³Kçº¿æ•°æ®æº"""
        current_time = time.time()
        
        # æ£€æŸ¥tushareæ˜¯å¦å¯ä»¥ä½¿ç”¨
        tushare_ready = (current_time - self.last_tushare_call) >= 60
        
        # æ£€æŸ¥yfinanceæ˜¯å¦å¯ä»¥ä½¿ç”¨
        yfinance_ready = (current_time - self.last_yfinance_call) >= self.yfinance_wait_seconds
        
        # è½®æ¢ç­–ç•¥
        if tushare_ready and yfinance_ready:
            # ä¸¤ä¸ªéƒ½å¯ç”¨ï¼ŒæŒ‰è½®æ¢é¡ºåºé€‰æ‹©
            source = self.kline_sources[self.current_kline_source_index]
            self.current_kline_source_index = (self.current_kline_source_index + 1) % len(self.kline_sources)
            return source
        elif tushare_ready:
            return 'tushare'
        elif yfinance_ready:
            return 'yfinance'
        else:
            # éƒ½ä¸å¯ç”¨ï¼Œé€‰æ‹©ç­‰å¾…æ—¶é—´è¾ƒçŸ­çš„
            tushare_wait = max(0, 60 - (current_time - self.last_tushare_call))
            yfinance_wait = max(0, self.yfinance_wait_seconds - (current_time - self.last_yfinance_call))
            
            if tushare_wait <= yfinance_wait:
                print(f"[INFO] tushareéœ€è¦ç­‰å¾…{tushare_wait:.0f}ç§’")
                return 'tushare'
            else:
                print(f"[INFO] yfinanceéœ€è¦ç­‰å¾…{yfinance_wait:.0f}ç§’")
                return 'yfinance'
    
    def _collect_batch_kline_with_tushare(self, codes: List[str]) -> Dict[str, pd.DataFrame]:
        """ä½¿ç”¨tushareæ‰¹é‡é‡‡é›†Kçº¿æ•°æ®"""
        result = {}
        
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…é¢‘ç‡é™åˆ¶
            current_time = time.time()
            if current_time - self.last_tushare_call < 60:
                wait_time = 60 - (current_time - self.last_tushare_call)
                print(f"[INFO] ç­‰å¾…{wait_time:.1f}ç§’é¿å…tushareé¢‘ç‡é™åˆ¶")
                time.sleep(wait_time)
            
            # è®¾ç½®æ—¶é—´èŒƒå›´ - 50å¤©
            end_date = datetime.now()
            start_date = end_date - timedelta(days=self.kline_days)
            start_str = start_date.strftime('%Y%m%d')
            end_str = end_date.strftime('%Y%m%d')
            
            # å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºtushareæ ¼å¼
            ts_codes = []
            code_mapping = {}  # æ˜ å°„å…³ç³»: ts_code -> original_code
            
            for code in codes:
                # ä¼˜åŒ–è‚¡ç¥¨ä»£ç åç¼€é€»è¾‘
                if code.startswith(('000', '001', '002', '300', '301')):
                    ts_code = f"{code}.SZ"
                elif code.startswith(('4', '8', '9')):
                    ts_code = f"{code}.BJ"
                else:
                    ts_code = f"{code}.SH"
                ts_codes.append(ts_code)
                code_mapping[ts_code] = code
            
            # è‡ªé€‚åº”æ‰¹é‡å¤§å°é€‰æ‹©
            if self.adaptive_batch:
                if len(codes) > 100:
                    actual_batch_size = self.kline_batch_size_max  # å¤§é‡è‚¡ç¥¨ç”¨å¤§æ‰¹é‡
                    print(f"[INFO] å¤§æ‰¹é‡æ¨¡å¼: {actual_batch_size}åª/æ‰¹ (æ€»é‡{len(codes)}åª)")
                else:
                    actual_batch_size = self.kline_batch_size      # å°‘é‡è‚¡ç¥¨ç”¨æ ‡å‡†æ‰¹é‡
                    print(f"[INFO] æ ‡å‡†æ¨¡å¼: {actual_batch_size}åª/æ‰¹ (æ€»é‡{len(codes)}åª)")
            else:
                actual_batch_size = self.kline_batch_size
                
            # æŒ‰æ‰¹é‡å¤§å°åˆ†ç»„é‡‡é›†
            batches = [ts_codes[i:i + actual_batch_size] for i in range(0, len(ts_codes), actual_batch_size)]
            
            print(f"[INFO] å°†{len(codes)}åªè‚¡ç¥¨åˆ†ä¸º{len(batches)}ä¸ªæ‰¹æ¬¡é‡‡é›†Kçº¿æ•°æ®")
            
            for batch_idx, batch_codes in enumerate(batches):
                try:
                    print(f"[INFO] æ­£åœ¨é‡‡é›†ç¬¬{batch_idx + 1}/{len(batches)}æ‰¹ï¼Œ{len(batch_codes)}åªè‚¡ç¥¨")
                    
                    # æ‰¹é‡è·å–
                    codes_str = ','.join(batch_codes)
                    df = self.ts_pro.daily(ts_code=codes_str, start_date=start_str, end_date=end_str)
                    
                    self.last_tushare_call = time.time()
                    
                    if df is not None and not df.empty:
                        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
                        for ts_code in batch_codes:
                            code_data = df[df['ts_code'] == ts_code].copy()
                            if not code_data.empty:
                                # æ•°æ®å¤„ç†
                                code_data['trade_date'] = pd.to_datetime(code_data['trade_date'])
                                code_data = code_data.sort_values('trade_date')
                                code_data = code_data.rename(columns={
                                    'trade_date': 'date', 'open': 'open', 'high': 'high',
                                    'low': 'low', 'close': 'close', 'vol': 'volume', 'amount': 'amount'
                                })
                                
                                original_code = code_mapping[ts_code]
                                result[original_code] = code_data
                                print(f"[SUCCESS] {original_code}: {len(code_data)}å¤©Kçº¿æ•°æ®")
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€æ‰¹ï¼Œç­‰å¾…é¢‘ç‡é™åˆ¶
                    if batch_idx < len(batches) - 1:
                        print(f"[INFO] ç­‰å¾…60ç§’é¿å…é¢‘ç‡é™åˆ¶...")
                        
                        # åœ¨ç­‰å¾…æœŸé—´æ”¶é›†å…¶ä»–æ•°æ®å’ŒKçº¿æ•°æ®
                        if self.enable_wait_period_collection:
                            remaining_codes = []
                            for remaining_batch in batches[batch_idx+1:]:
                                remaining_codes.extend([code_mapping.get(ts_code.replace('.SH', '').replace('.SZ', ''), ts_code.replace('.SH', '').replace('.SZ', '')) 
                                                      for ts_code in remaining_batch])
                            
                            if remaining_codes:
                                print(f"[INFO] ç­‰å¾…æœŸé—´å¹¶è¡Œæ”¶é›†æ•°æ®...")
                                self._collect_parallel_data_during_wait(remaining_codes[:15], codes, 60, result, start_str, end_str)
                        
                        time.sleep(60)
                        
                except Exception as e:
                    print(f"[WARN] ç¬¬{batch_idx + 1}æ‰¹Kçº¿æ•°æ®é‡‡é›†å¤±è´¥: {e}")
                    continue
            
            print(f"[SUCCESS] æ‰¹é‡Kçº¿é‡‡é›†å®Œæˆï¼Œè·å–{len(result)}åªè‚¡ç¥¨æ•°æ®")
            return result
            
        except Exception as e:
            print(f"[ERROR] tushareæ‰¹é‡Kçº¿æ•°æ®é‡‡é›†å¤±è´¥: {e}")
            return result
    
    def _collect_batch_kline_with_yfinance(self, codes: List[str]) -> Dict[str, pd.DataFrame]:
        """ä½¿ç”¨yfinanceæ‰¹é‡é‡‡é›†Kçº¿æ•°æ®"""
        result = {}
        
        try:
            # æ£€æŸ¥yfinanceé¢‘ç‡é™åˆ¶
            current_time = time.time()
            if current_time - self.last_yfinance_call < self.yfinance_wait_seconds:
                wait_time = self.yfinance_wait_seconds - (current_time - self.last_yfinance_call)
                print(f"[INFO] ç­‰å¾…{wait_time:.1f}ç§’é¿å…yfinanceé¢‘ç‡é™åˆ¶")
                time.sleep(wait_time)
            
            print(f"[INFO] ä½¿ç”¨yfinanceæ‰¹é‡è·å–{len(codes)}åªè‚¡ç¥¨Kçº¿æ•°æ®")
            
            # yfinanceæ”¯æŒæ‰¹é‡è·å–ï¼Œä½†éœ€è¦è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼
            yf_symbols = []
            code_mapping = {}
            
            for code in codes:
                # è½¬æ¢ä¸ºyfinanceæ ¼å¼
                if code.startswith(('60', '68')):  # æ²ªå¸‚
                    yf_symbol = f"{code}.SS"
                else:  # æ·±å¸‚
                    yf_symbol = f"{code}.SZ"
                
                yf_symbols.append(yf_symbol)
                code_mapping[yf_symbol] = code
            
            # æ‰¹é‡ä¸‹è½½
            symbols_str = ' '.join(yf_symbols[:self.kline_batch_size])  # é™åˆ¶æ‰¹é‡å¤§å°
            
            import yfinance as yf
            data = yf.download(symbols_str, period="3mo", interval="1d", 
                             group_by='ticker', progress=False)
            
            self.last_yfinance_call = time.time()
            
            if not data.empty:
                # å¤„ç†å•ä¸ªè‚¡ç¥¨çš„æƒ…å†µ
                if len(yf_symbols) == 1:
                    symbol = yf_symbols[0]
                    original_code = code_mapping[symbol]
                    if not data.empty:
                        df = data.reset_index()
                        df = df.rename(columns={
                            'Date': 'date', 'Open': 'open', 'High': 'high',
                            'Low': 'low', 'Close': 'close', 'Volume': 'volume'
                        })
                        # å®‰å…¨è®¡ç®—æˆäº¤é¢
                        if 'close' in df.columns and 'volume' in df.columns:
                            df['amount'] = df['close'] * df['volume']  # ä¼°ç®—æˆäº¤é¢
                        result[original_code] = df
                        print(f"[SUCCESS] {original_code}: {len(df)}å¤©Kçº¿æ•°æ® (yfinance)")
                
                # å¤„ç†å¤šä¸ªè‚¡ç¥¨çš„æƒ…å†µ
                else:
                    for symbol in yf_symbols:
                        original_code = code_mapping[symbol]
                        try:
                            if symbol in data.columns.levels[0]:
                                stock_data = data[symbol].dropna()
                                if not stock_data.empty:
                                    df = stock_data.reset_index()
                                    df = df.rename(columns={
                                        'Date': 'date', 'Open': 'open', 'High': 'high',
                                        'Low': 'low', 'Close': 'close', 'Volume': 'volume'
                                    })
                                    # å®‰å…¨è®¡ç®—æˆäº¤é¢
                                    if 'close' in df.columns and 'volume' in df.columns:
                                        df['amount'] = df['close'] * df['volume']  # ä¼°ç®—æˆäº¤é¢
                                    result[original_code] = df
                                    print(f"[SUCCESS] {original_code}: {len(df)}å¤©Kçº¿æ•°æ® (yfinance)")
                        except Exception as e:
                            print(f"[WARN] {original_code}: yfinanceæ•°æ®å¤„ç†å¤±è´¥ - {e}")
            
            print(f"[INFO] yfinanceæ‰¹é‡é‡‡é›†å®Œæˆï¼Œè·å–{len(result)}åªè‚¡ç¥¨Kçº¿æ•°æ®")
            return result
            
        except Exception as e:
            print(f"[ERROR] yfinanceæ‰¹é‡Kçº¿æ•°æ®é‡‡é›†å¤±è´¥: {e}")
            return result
    
    def _collect_batch_kline_with_akshare(self, codes: List[str]) -> Dict[str, pd.DataFrame]:
        """ä½¿ç”¨akshareæ‰¹é‡é‡‡é›†Kçº¿æ•°æ®"""
        result = {}
        
        if not AKSHARE_AVAILABLE or not AKSHARE_CONNECTED:
            print(f"[WARN] akshareä¸å¯ç”¨æˆ–è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ‰¹é‡Kçº¿é‡‡é›†")
            return result
        
        print(f"[INFO] ä½¿ç”¨akshareè·å–{len(codes)}åªè‚¡ç¥¨Kçº¿æ•°æ®")
        
        try:
            # akshareéœ€è¦å•ç‹¬è‚¡ç¥¨è·å–ï¼Œä½†å¯ä»¥æ§åˆ¶é¢‘ç‡
            for i, code in enumerate(codes):
                try:
                    # è·å–æ—¥Kçº¿æ•°æ®
                    df = ak.stock_zh_a_hist(symbol=code, period="daily", adjust="qfq")
                    
                    if df is not None and not df.empty:
                        # æ ‡å‡†åŒ–åˆ—å
                        df = df.rename(columns={
                            'æ—¥æœŸ': 'date',
                            'å¼€ç›˜': 'open', 
                            'æ”¶ç›˜': 'close',
                            'æœ€é«˜': 'high',
                            'æœ€ä½': 'low', 
                            'æˆäº¤é‡': 'volume',
                            'æˆäº¤é¢': 'amount'
                        })
                        
                        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                        df['date'] = pd.to_datetime(df['date'])
                        for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
                            if col in df.columns:
                                df[col] = pd.to_numeric(df[col], errors='coerce')
                        
                        # åªä¿ç•™æœ€è¿‘50å¤©æ•°æ®
                        df = df.tail(self.kline_days)
                        result[code] = df
                        print(f"[SUCCESS] {code}: {len(df)}å¤©Kçº¿æ•°æ® (akshare)")
                    
                    # akshareé¢‘ç‡æ§åˆ¶ - æ¯åªè‚¡ç¥¨é—´éš”0.5ç§’
                    if i < len(codes) - 1:
                        time.sleep(0.5)
                        
                except Exception as e:
                    print(f"[WARN] {code}: akshare Kçº¿æ•°æ®è·å–å¤±è´¥ - {e}")
                    continue
            
            print(f"[INFO] akshareæ‰¹é‡é‡‡é›†å®Œæˆï¼Œè·å–{len(result)}/{len(codes)}åªè‚¡ç¥¨Kçº¿æ•°æ®")
            return result
            
        except Exception as e:
            print(f"[ERROR] akshareæ‰¹é‡Kçº¿æ•°æ®é‡‡é›†å¤±è´¥: {e}")
            return result
    
    def _collect_kline_individually(self, codes: List[str]) -> Dict[str, pd.DataFrame]:
        """å•ç‹¬é‡‡é›†Kçº¿æ•°æ®ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        result = {}
        print(f"[INFO] ä½¿ç”¨å•ç‹¬é‡‡é›†æ¨¡å¼è·å–{len(codes)}åªè‚¡ç¥¨Kçº¿æ•°æ®")
        
        for code in codes:
            try:
                # å°è¯•ä½¿ç”¨å¯ç”¨çš„æ•°æ®æº
                kline_data = None
                
                if AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
                    kline_data = self.collect_kline_data(code, 'akshare')
                elif YFINANCE_AVAILABLE:
                    kline_data = self.collect_kline_data(code, 'yfinance')
                
                if kline_data is not None and not kline_data.empty:
                    result[code] = kline_data
                    print(f"[SUCCESS] {code}: {len(kline_data)}å¤©Kçº¿æ•°æ® (å•ç‹¬é‡‡é›†)")
                
                time.sleep(1)  # é¿å…é¢‘ç‡é™åˆ¶
                
            except Exception as e:
                print(f"[WARN] {code}: å•ç‹¬Kçº¿é‡‡é›†å¤±è´¥ - {e}")
        
        return result
    
    def get_next_data_source(self) -> str:
        """è½®è¯¢è·å–ä¸‹ä¸€ä¸ªæ•°æ®æº"""
        source = self.data_sources[self.current_source_index]
        self.current_source_index = (self.current_source_index + 1) % len(self.data_sources)
        return source
    
    def collect_basic_info(self, code: str, source: str) -> Dict[str, Any]:
        """é‡‡é›†åŸºç¡€ä¿¡æ¯"""
        basic_info = {
            'code': code,
            'name': f'è‚¡ç¥¨{code}',
            'exchange': 'SZ' if code.startswith(('00', '30')) else 'SH',
            'industry': None,
            'area': None,
            'concept': None,
            'source': source
        }
        
        try:
            if source == 'yfinance' and YFINANCE_AVAILABLE:
                symbol = f"{code}.SS" if code.startswith(('60', '68')) else f"{code}.SZ"
                try:
                    stock = yf.Ticker(symbol)
                    info = stock.info
                    if info:
                        basic_info.update({
                            'name': info.get('shortName', info.get('longName', basic_info['name'])),
                            'industry': info.get('industry'),
                            'sector': info.get('sector')
                        })
                except Exception as e:
                    print(f"[WARN] yfinanceåŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            elif source == 'tencent' and REQUESTS_AVAILABLE:
                try:
                    url = f'https://qt.gtimg.cn/q=s_{code}'
                    response = requests.get(url, timeout=10)
                    if response.status_code == 200:
                        data = response.text.split('~')
                        if len(data) > 1:
                            basic_info['name'] = data[1]
                except Exception as e:
                    print(f"[WARN] è…¾è®¯APIåŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            elif source == 'akshare' and AKSHARE_AVAILABLE and AKSHARE_CONNECTED:
                df = ak.stock_individual_info_em(symbol=code)
                if df is not None and not df.empty:
                    info = dict(zip(df['item'], df['value']))
                    basic_info.update({
                        'name': info.get('è‚¡ç¥¨ç®€ç§°', basic_info['name']),
                        'industry': info.get('è¡Œä¸š'),
                        'area': info.get('åœ°åŒº'),
                        'concept': info.get('æ¦‚å¿µ')
                    })
            
            elif source == 'baostock' and BAOSTOCK_AVAILABLE and self.bs_login:
                # baostockè·å–åŸºç¡€ä¿¡æ¯ï¼ˆæœ€ç»ˆå…œåº•ï¼‰
                bs_code = f"sh.{code}" if code.startswith('6') else f"sz.{code}"
                try:
                    # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                    rs = bs.query_stock_basic(code=bs_code)
                    if rs.error_code == '0' and rs.next():
                        row_data = rs.get_row_data()
                        if len(row_data) >= 3:
                            basic_info.update({
                                'name': row_data[1] if len(row_data) > 1 else basic_info['name'],
                                'industry': row_data[2] if len(row_data) > 2 else None,
                                'type': row_data[3] if len(row_data) > 3 else None
                            })
                except Exception as e:
                    print(f"[DEBUG] baostockåŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            elif source == 'jina' and JINA_AVAILABLE and self.jina_api and self.jina_api.api_key and self.jina_api.api_key != "YOUR_JINA_API_KEY":
                try:
                    info = self.jina_api.get_company_info_fallback(code, basic_info['name'])
                    if info:
                        basic_info.update(info)
                except Exception as e:
                    print(f"[WARN] Jina API åŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {e}")
        
        except Exception as e:
            print(f"[WARN] {code} åŸºç¡€ä¿¡æ¯é‡‡é›†å¤±è´¥ ({source}): {e}")
        
        return basic_info
    
    def collect_batch_basic_info(self, codes: List[str], source: str = 'auto') -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯ - æ–°ç­–ç•¥ï¼šBaostockä¸ºä¸» â†’ JoinQuantä¸ºè¾… â†’ è…¾è®¯è¡¥å…… â†’ AKShareå…œåº•"""
        # é¢„æ£€è‚¡ç¥¨çŠ¶æ€ï¼Œè¿‡æ»¤é€€å¸‚è‚¡ç¥¨
        if STOCK_STATUS_CHECKER_AVAILABLE and self.status_checker:
            print(f"[INFO] åŸºç¡€ä¿¡æ¯é‡‡é›†å‰æ£€æŸ¥è‚¡ç¥¨çŠ¶æ€...")
            try:
                validity_check = self.pre_check_stock_validity(codes)
                original_count = len(codes)
                codes = validity_check['valid_codes']
                
                filtered_count = original_count - len(codes)
                if filtered_count > 0:
                    print(f"[INFO] åŸºç¡€ä¿¡æ¯é‡‡é›†å·²è¿‡æ»¤ {filtered_count} åªé€€å¸‚/æ— æ•ˆè‚¡ç¥¨")
                    
            except Exception as e:
                print(f"[WARN] åŸºç¡€ä¿¡æ¯é‡‡é›†å‰çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {e}ï¼Œç»§ç»­å¤„ç†")
        
        result = {}
        total_codes = len(codes)
        
        print(f"[INFO] æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        print(f"[INFO] åŸºç¡€ä¿¡æ¯ç­–ç•¥: Baostock(ä¸») â†’ JoinQuant(è¾…) â†’ è…¾è®¯(è¡¥å……) â†’ AKShare(å…œåº•)")
        
        # 1. Baostockä¸»åŠ›ï¼šæ ‡å‡†è¡Œä¸šåˆ†ç±»å’ŒåŸºç¡€ä¿¡æ¯
        baostock_success = []
        if BAOSTOCK_AVAILABLE and self.bs_login:
            print(f"[INFO] BaostockåŸºç¡€ä¿¡æ¯é‡‡é›† {total_codes} åª...")
            try:
                # ç¡®ä¿baostockå·²å¯¼å…¥
                import baostock as bs

                # ç¡®ä¿å·²ç™»å½•
                lg = bs.login()
                if lg.error_code != '0':
                    print(f"[WARN] Baostockç™»å½•å¤±è´¥: {lg.error_msg}")
                
                for code in codes:
                    try:
                        bs_code = f"sz.{code}" if code.startswith(('000', '002', '300')) else f"sh.{code}"
                        
                        rs = bs.query_stock_basic(code=bs_code)
                        if rs.error_code == '0':
                            data_found = False
                            while rs.next():
                                row = rs.get_row_data()
                                # Baostock query_stock_basic è¿”å›: code, code_name, ipoDate, outDate, type, status
                                if len(row) >= 6:
                                    result[code] = {
                                        'code': code,
                                        'name': row[1],
                                        'type': row[4],
                                        'status': row[5],
                                        'industry': 'æœªçŸ¥',  # query_stock_basic ä¸åŒ…å«è¡Œä¸šä¿¡æ¯
                                        'listing_date': row[2],
                                        'source': 'baostock'
                                    }
                                    baostock_success.append(code)
                                    data_found = True
                                    break
                            
                            if not data_found:
                                print(f"[WARN] BaoStock {code} æ— æ•°æ®ï¼šå¯èƒ½å·²é€€å¸‚æˆ–ä»£ç æ— æ•ˆ")
                        else:
                            print(f"[WARN] BaoStock {code} æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
                        
                        time.sleep(0.05)
                    except Exception as e:
                        print(f"[DEBUG] Baostock {code}: {e}")
                        continue
                
                # ä¿æŒç™»å½•çŠ¶æ€ä¾›åç»­æ­¥éª¤ä½¿ç”¨
                # bs.logout()
                
                print(f"[SUCCESS] BaostockåŸºç¡€ä¿¡æ¯: {len(baostock_success)}/{total_codes}")
            except Exception as e:
                print(f"[ERROR] BaostockåŸºç¡€ä¿¡æ¯å¼‚å¸¸: {e}")
        
        # 2. JoinQuantä¸ºè¾…ï¼šè·å–å¤±è´¥è‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯
        failed_codes = [code for code in codes if code not in result]
        joinquant_success = []
        if failed_codes and self.joinquant:
            print(f"[INFO] JoinQuantä¸ºè¾…åŸºç¡€ä¿¡æ¯é‡‡é›† {len(failed_codes)} åª...")
            try:
                for code in failed_codes:
                    try:
                        # JoinQuantè·å–åŸºç¡€ä¿¡æ¯
                        stock_info = self._get_joinquant_stock_info(code)
                        if stock_info:
                            result[code] = stock_info
                            joinquant_success.append(code)
                        time.sleep(0.1)
                    except Exception as e:
                        print(f"[DEBUG] JoinQuant {code}: {e}")
                        continue
                
                print(f"[SUCCESS] JoinQuantåŸºç¡€ä¿¡æ¯: {len(joinquant_success)}/{len(failed_codes)} åª")
            except Exception as e:
                print(f"[ERROR] JoinQuantåŸºç¡€ä¿¡æ¯å¼‚å¸¸: {e}")
        elif failed_codes and not self.joinquant:
            print(f"[WARN] JoinQuant APIæœªåˆå§‹åŒ–ï¼Œè·³è¿‡ {len(failed_codes)} åªè‚¡ç¥¨")
        
        # 3. è…¾è®¯è¡¥å……ï¼šå®æ—¶ä»·æ ¼å’Œå¸‚åœºæ•°æ®
        still_failed = [code for code in codes if code not in result]
        tencent_success = []
        if still_failed and REQUESTS_AVAILABLE:
            print(f"[INFO] è…¾è®¯è¡¥å……åŸºç¡€ä¿¡æ¯ {len(still_failed)} åª...")
            try:
                # è…¾è®¯æ”¯æŒæ‰¹é‡æŸ¥è¯¢
                batch_symbols = ','.join([f's_{code}' for code in still_failed])
                url = f'https://qt.gtimg.cn/q={batch_symbols}'
                
                response = requests.get(url, timeout=15)
                if response.status_code == 200:
                    lines = response.text.split('\\n')
                    for i, line in enumerate(lines):
                        if i >= len(still_failed) or not line.strip():
                            continue
                        
                        code = still_failed[i]
                        try:
                            parts = line.split('~')
                            if len(parts) > 5:
                                result[code] = {
                                    'code': code,
                                    'name': parts[1],
                                    'current_price': self._safe_float(parts[3]),
                                    'change_pct': self._safe_float(parts[5]),
                                    'volume': self._safe_float(parts[6]),
                                    'source': 'tencent'
                                }
                                tencent_success.append(code)
                        except Exception as e:
                            print(f"[DEBUG] è…¾è®¯è§£æ {code}: {e}")
                            continue
                            
                print(f"[SUCCESS] è…¾è®¯è¡¥å……åŸºç¡€ä¿¡æ¯: {len(tencent_success)}/{len(still_failed)} åª")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯æ‰¹é‡è¡¥å……å¼‚å¸¸: {e}")
        
        # 4. AKShareå…œåº•ï¼šå®Œæ•´ä¿¡æ¯è·å–
        final_failed = [code for code in codes if code not in result]
        akshare_success = []
        if final_failed and AKSHARE_AVAILABLE:
            print(f"[INFO] AKShareå…œåº•åŸºç¡€ä¿¡æ¯ {len(final_failed)} åª...")
            try:
                for code in final_failed:
                    try:
                        df = ak.stock_individual_info_em(symbol=code)
                        if df is not None and not df.empty:
                            info_dict = dict(zip(df['item'], df['value']))
                            result[code] = {
                                'code': code,
                                'name': info_dict.get('è‚¡ç¥¨ç®€ç§°', f'è‚¡ç¥¨{code}'),
                                'industry': info_dict.get('è¡Œä¸š'),
                                'concept': info_dict.get('æ¦‚å¿µ'),
                                'area': info_dict.get('åœ°åŒº'),
                                'source': 'akshare'
                            }
                            akshare_success.append(code)
                        time.sleep(0.3)
                    except Exception as e:
                        print(f"[DEBUG] AKShare {code}: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] AKShareå…œåº•å¼‚å¸¸: {e}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = len(result)
        success_rate = success_count / total_codes * 100 if total_codes > 0 else 0
        
        print(f"[SUMMARY] åŸºç¡€ä¿¡æ¯é‡‡é›†å®Œæˆ: {success_count}/{total_codes} åª ({success_rate:.1f}%)")
        print(f"[DETAIL] Baostock: {len(baostock_success)}, JoinQuant: {len(joinquant_success)}, è…¾è®¯: {len(tencent_success)}, AKShare: {len(akshare_success)}")
        
        return result
    
    def _collect_batch_basic_info_legacy(self, codes: List[str], source: str = 'auto') -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯ï¼Œä¼˜åŒ–é¢‘æ¬¡é™åˆ¶é—®é¢˜ï¼ˆé—ç•™æ–¹æ³•ï¼‰"""
        result = {}
        
        if source == 'tencent' and REQUESTS_AVAILABLE:
            try:
                # è…¾è®¯APIæ”¯æŒæ‰¹é‡æŸ¥è¯¢ï¼Œä¸€æ¬¡æœ€å¤š15åªè‚¡ç¥¨
                batch_size = min(15, len(codes))
                for i in range(0, len(codes), batch_size):
                    batch_codes = codes[i:i+batch_size]
                    
                    # æ„é€ æ‰¹é‡æŸ¥è¯¢URL
                    query_params = ','.join([f's_{code}' for code in batch_codes])
                    url = f'https://qt.gtimg.cn/q={query_params}'
                    
                    response = requests.get(url, timeout=15)
                    if response.status_code == 200:
                        lines = response.text.strip().split('\n')
                        for line, code in zip(lines, batch_codes):
                            try:
                                data = line.split('~')
                                if len(data) > 1 and data[1].strip():  # ç¡®ä¿æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨åç§°
                                    result[code] = {
                                        'code': code,
                                        'name': data[1] if len(data) > 1 else f'è‚¡ç¥¨{code}',
                                        'exchange': 'SZ' if code.startswith(('00', '30')) else 'SH',
                                        'current_price': float(data[3]) if len(data) > 3 and data[3] else None,
                                        'change_pct': float(data[32]) if len(data) > 32 and data[32] else None,
                                        'volume': float(data[36]) if len(data) > 36 and data[36] else None,
                                        'source': 'tencent'
                                    }
                                    print(f"[SUCCESS] {code}: è…¾è®¯åŸºç¡€ä¿¡æ¯è·å–æˆåŠŸ")
                                else:
                                    print(f"[WARN] {code}: è…¾è®¯è¿”å›ç©ºæ•°æ®ï¼Œè·³è¿‡")
                            except (ValueError, IndexError) as e:
                                print(f"[WARN] è§£æè‚¡ç¥¨{code}æ•°æ®å¤±è´¥: {e}")
                                # å¤±è´¥æ—¶ä¸æ·»åŠ åˆ°resultä¸­ï¼Œè®©åç»­å…œåº•æœºåˆ¶å¤„ç†
                    
                    print(f"[INFO] è…¾è®¯æ‰¹é‡åŸºç¡€ä¿¡æ¯: {len([c for c in batch_codes if c in result])}/{len(batch_codes)} æˆåŠŸ")
                    
                    # é¿å…é¢‘ç‡é™åˆ¶
                    if i + batch_size < len(codes):
                        time.sleep(1)
                        
            except Exception as e:
                print(f"[WARN] è…¾è®¯æ‰¹é‡åŸºç¡€ä¿¡æ¯é‡‡é›†å¤±è´¥: {e}")
        
        # å¦‚æœè…¾è®¯APIå¤±è´¥ï¼Œä½¿ç”¨yfinanceå…œåº•ï¼ˆæ›´å¯é çš„åŸºç¡€ä¿¡æ¯ï¼‰
        if len(result) < len(codes) * 0.8:  # å¦‚æœæˆåŠŸç‡ä½äº80%ï¼Œä½¿ç”¨yfinanceå…œåº•
            print(f"[INFO] è…¾è®¯æ‰¹é‡é‡‡é›†æˆåŠŸç‡è¾ƒä½ï¼Œä½¿ç”¨yfinanceå…œåº•è¡¥å……")
            missing_codes = [code for code in codes if code not in result]
            
            # ä½¿ç”¨yfinanceæ‰¹é‡è·å–åŸºç¡€ä¿¡æ¯
            yfinance_result = self._collect_batch_basic_info_with_yfinance(missing_codes)
            result.update(yfinance_result)
            
            # å¦‚æœyfinanceä¹Ÿå¤±è´¥è¾ƒå¤šï¼Œæœ€åä½¿ç”¨baostockå…œåº•
            still_missing = [code for code in missing_codes if code not in yfinance_result]
            if still_missing:
                print(f"[INFO] yfinanceé‡‡é›†ä¸å®Œæ•´ï¼Œä½¿ç”¨baostockæœ€ç»ˆå…œåº• {len(still_missing)} åªè‚¡ç¥¨")
                for code in still_missing:
                    try:
                        result[code] = self.collect_basic_info(code, 'baostock')
                        time.sleep(0.3)  # baostocké¢‘ç‡æ§åˆ¶
                    except Exception as e:
                        print(f"[WARN] baostockæœ€ç»ˆå…œåº•å¤±è´¥ {code}: {e}")
                        result[code] = {
                            'code': code,
                            'name': f'è‚¡ç¥¨{code}',
                            'exchange': 'SZ' if code.startswith(('00', '30')) else 'SH',
                            'source': 'fallback'
                        }
        
        return result
    
    def _get_joinquant_stock_info(self, code: str) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨JoinQuantè·å–å•åªè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '000001'
            
        Returns:
            è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.joinquant:
            return None
        
        try:
            # JoinQuantå¯èƒ½çš„åŸºç¡€ä¿¡æ¯è·å–ç«¯ç‚¹
            endpoints = [
                "/data/stock/info",
                "/data/stock/basic",
                "/stock/info",
                "/stock/basic_info"
            ]
            
            for endpoint in endpoints:
                try:
                    url = f"{self.joinquant.base_url}{endpoint}"
                    params = {
                        'code': code,
                        'symbol': code
                    }
                    
                    response = self.joinquant.session.get(url, params=params, timeout=10)
                    
                    if response.status_code == 200 and len(response.text) > 50:
                        # å°è¯•è§£æå“åº”
                        stock_info = self._parse_joinquant_basic_info(response.text, code)
                        if stock_info:
                            return stock_info
                            
                except Exception as e:
                    print(f"[DEBUG] JoinQuantç«¯ç‚¹{endpoint}å¤±è´¥{code}: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
            return {
                'code': code,
                'name': f'è‚¡ç¥¨{code}',
                'source': 'joinquant_fallback'
            }
            
        except Exception as e:
            print(f"[ERROR] JoinQuantè·å–{code}åŸºç¡€ä¿¡æ¯å¼‚å¸¸: {e}")
            return None
    
    def _parse_joinquant_basic_info(self, content: str, code: str) -> Optional[Dict[str, Any]]:
        """
        è§£æJoinQuantåŸºç¡€ä¿¡æ¯å“åº”
        
        Args:
            content: APIå“åº”å†…å®¹
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è§£æåçš„åŸºç¡€ä¿¡æ¯å­—å…¸
        """
        try:
            import json

            # å°è¯•JSONè§£æ
            if content.strip().startswith('{') or content.strip().startswith('['):
                try:
                    data = json.loads(content)
                    
                    # å¤„ç†ä¸åŒçš„JSONç»“æ„
                    if isinstance(data, dict):
                        if 'data' in data:
                            stock_data = data['data']
                        elif 'result' in data:
                            stock_data = data['result']
                        else:
                            stock_data = data
                        
                        # æå–åŸºç¡€ä¿¡æ¯
                        if isinstance(stock_data, dict):
                            return {
                                'code': code,
                                'name': stock_data.get('name', stock_data.get('display_name', f'è‚¡ç¥¨{code}')),
                                'industry': stock_data.get('industry'),
                                'sector': stock_data.get('sector'),
                                'exchange': stock_data.get('exchange'),
                                'listing_date': stock_data.get('start_date', stock_data.get('listing_date')),
                                'source': 'joinquant'
                            }
                        
                except json.JSONDecodeError:
                    pass
            
            # å°è¯•ä»HTMLä¸­æå–ä¿¡æ¯
            if 'è‚¡ç¥¨' in content or 'stock' in content.lower():
                # ç®€å•çš„æ–‡æœ¬è§£æ
                return {
                    'code': code,
                    'name': f'è‚¡ç¥¨{code}',
                    'source': 'joinquant_html'
                }
            
            return None
            
        except Exception as e:
            print(f"[DEBUG] JoinQuantå“åº”è§£æå¤±è´¥{code}: {e}")
            return None
    
    def _get_joinquant_financial_info(self, code: str) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨JoinQuantè·å–å•åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '000001'
            
        Returns:
            è‚¡ç¥¨è´¢åŠ¡æ•°æ®å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.joinquant:
            return None
        
        try:
            # JoinQuantå¯èƒ½çš„è´¢åŠ¡æ•°æ®è·å–ç«¯ç‚¹
            endpoints = [
                "/data/stock/fundamental",
                "/data/stock/financial",
                "/stock/fundamental",
                "/stock/finance"
            ]
            
            for endpoint in endpoints:
                try:
                    url = f"{self.joinquant.base_url}{endpoint}"
                    params = {
                        'code': code,
                        'symbol': code,
                        'period': 'quarter'  # å­£æŠ¥
                    }
                    
                    response = self.joinquant.session.get(url, params=params, timeout=10)
                    
                    if response.status_code == 200 and len(response.text) > 50:
                        # å°è¯•è§£æå“åº”
                        financial_info = self._parse_joinquant_financial_info(response.text, code)
                        if financial_info:
                            return financial_info
                            
                except Exception as e:
                    print(f"[DEBUG] JoinQuantè´¢åŠ¡ç«¯ç‚¹{endpoint}å¤±è´¥{code}: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥ï¼Œè¿”å›åŸºæœ¬è´¢åŠ¡ä¿¡æ¯
            return {
                'code': code,
                'source': 'joinquant_fallback'
            }
            
        except Exception as e:
            print(f"[ERROR] JoinQuantè·å–{code}è´¢åŠ¡æ•°æ®å¼‚å¸¸: {e}")
            return None
    
    def _parse_joinquant_financial_info(self, content: str, code: str) -> Optional[Dict[str, Any]]:
        """
        è§£æJoinQuantè´¢åŠ¡æ•°æ®å“åº”
        
        Args:
            content: APIå“åº”å†…å®¹
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è§£æåçš„è´¢åŠ¡æ•°æ®å­—å…¸
        """
        try:
            import json

            # å°è¯•JSONè§£æ
            if content.strip().startswith('{') or content.strip().startswith('['):
                try:
                    data = json.loads(content)
                    
                    # å¤„ç†ä¸åŒçš„JSONç»“æ„
                    if isinstance(data, dict):
                        if 'data' in data:
                            financial_data = data['data']
                        elif 'result' in data:
                            financial_data = data['result']
                        else:
                            financial_data = data
                        
                        # æå–è´¢åŠ¡ä¿¡æ¯
                        if isinstance(financial_data, dict):
                            return {
                                'code': code,
                                'revenue': financial_data.get('total_operating_revenue'),
                                'net_income': financial_data.get('net_profit'),
                                'total_assets': financial_data.get('total_assets'),
                                'total_equity': financial_data.get('total_owner_equities'),
                                'market_cap': financial_data.get('market_cap'),
                                'pe_ratio': financial_data.get('pe_ratio'),
                                'pb_ratio': financial_data.get('pb_ratio'),
                                'roe': financial_data.get('roe'),
                                'source': 'joinquant'
                            }
                        
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœåŒ…å«è´¢åŠ¡å…³é”®è¯ï¼Œè¿”å›åŸºç¡€ä¿¡æ¯
            financial_keywords = ['revenue', 'profit', 'asset', 'equity', 'è¥æ”¶', 'åˆ©æ¶¦', 'èµ„äº§']
            if any(keyword in content.lower() for keyword in financial_keywords):
                return {
                    'code': code,
                    'source': 'joinquant_partial'
                }
            
            return None
            
        except Exception as e:
            print(f"[DEBUG] JoinQuantè´¢åŠ¡å“åº”è§£æå¤±è´¥{code}: {e}")
            return None
    
    def _collect_batch_basic_info_with_yfinance(self, codes: List[str]) -> Dict[str, Dict[str, Any]]:
        """ä½¿ç”¨yfinanceæ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯"""
        result = {}
        
        if not YFINANCE_AVAILABLE:
            print(f"[WARN] yfinanceä¸å¯ç”¨ï¼Œè·³è¿‡åŸºç¡€ä¿¡æ¯é‡‡é›†")
            return result
        
        print(f"[INFO] ä½¿ç”¨yfinanceæ‰¹é‡è·å–{len(codes)}åªè‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
        
        # yfinanceé¢‘ç‡æ§åˆ¶ - åˆå§‹ç­‰å¾…ï¼ˆé¿å…Rate Limitï¼‰
        print(f"[INFO] yfinanceé¢‘ç‡æ§åˆ¶ï¼Œç­‰å¾…5ç§’...")
        time.sleep(5)
        
        try:
            # yfinanceæ‰¹é‡è·å– (10åª/æ‰¹ï¼Œå‡å°‘é¢‘ç‡é™åˆ¶é£é™©)
            batch_size = min(10, len(codes))
            for i in range(0, len(codes), batch_size):
                batch_codes = codes[i:i+batch_size]
                
                # è½¬æ¢ä¸ºyfinanceæ ¼å¼
                yf_symbols = []
                code_mapping = {}
                
                for code in batch_codes:
                    if code.startswith(('60', '68')):  # æ²ªå¸‚
                        yf_symbol = f"{code}.SS"
                    else:  # æ·±å¸‚
                        yf_symbol = f"{code}.SZ"
                    yf_symbols.append(yf_symbol)
                    code_mapping[yf_symbol] = code
                
                # æ‰¹é‡è·å–åŸºç¡€ä¿¡æ¯
                try:
                    symbols_str = ' '.join(yf_symbols)
                    tickers = yf.Tickers(symbols_str)
                    
                    for yf_symbol in yf_symbols:
                        code = code_mapping[yf_symbol]
                        try:
                            ticker = tickers.tickers[yf_symbol]
                            info = ticker.info
                            
                            if info and info.get('symbol'):
                                result[code] = {
                                    'code': code,
                                    'name': info.get('shortName', info.get('longName', f'è‚¡ç¥¨{code}')),
                                    'exchange': 'SZ' if code.startswith(('00', '30')) else 'SH',
                                    'industry': info.get('industry'),
                                    'sector': info.get('sector'),
                                    'market_cap': info.get('marketCap'),
                                    'employee_count': info.get('fullTimeEmployees'),
                                    'source': 'yfinance'
                                }
                                print(f"[SUCCESS] {code}: yfinanceåŸºç¡€ä¿¡æ¯è·å–æˆåŠŸ")
                            else:
                                result[code] = {
                                    'code': code,
                                    'name': f'è‚¡ç¥¨{code}',
                                    'exchange': 'SZ' if code.startswith(('00', '30')) else 'SH',
                                    'source': 'yfinance'
                                }
                        except Exception as e:
                            print(f"[WARN] {code}: yfinanceåŸºç¡€ä¿¡æ¯è·å–å¤±è´¥ - {e}")
                            # å¤±è´¥æ—¶ä¸æ·»åŠ åˆ°resultä¸­ï¼Œè®©baostockæ¥å…œåº•
                
                except Exception as e:
                    print(f"[WARN] yfinanceæ‰¹é‡è·å–ç¬¬{i//batch_size + 1}æ‰¹å¤±è´¥: {e}")
                
                actual_success = len([c for c in batch_codes if c in result])
                print(f"[INFO] yfinanceæ‰¹é‡åŸºç¡€ä¿¡æ¯: ç¬¬{i//batch_size + 1}æ‰¹å®Œæˆ ({actual_success}/{len(batch_codes)} æˆåŠŸ)")
                
                # yfinanceé¢‘ç‡é™åˆ¶è¾ƒä¸¥æ ¼ï¼Œå¿…é¡»ç­‰å¾…è¶³å¤Ÿé•¿æ—¶é—´
                if i + batch_size < len(codes):
                    print(f"[INFO] yfinanceé¢‘ç‡æ§åˆ¶ï¼Œç­‰å¾…8ç§’åç»§ç»­ä¸‹ä¸€æ‰¹...")
                    time.sleep(8)  # å¢åŠ åˆ°8ç§’é¿å…Rate Limit
                    
        except Exception as e:
            print(f"[WARN] yfinanceæ‰¹é‡åŸºç¡€ä¿¡æ¯é‡‡é›†å¤±è´¥: {e}")
        
        # ç»Ÿè®¡æœ‰æ•ˆæˆåŠŸæ•°ï¼ˆåªè®¡ç®—æœ‰æœ‰æ•ˆæ•°æ®çš„ï¼‰
        valid_results = {code: data for code, data in result.items() 
                        if data.get('name') and data.get('name') != f'è‚¡ç¥¨{code}'}
        print(f"[INFO] yfinanceåŸºç¡€ä¿¡æ¯é‡‡é›†å®Œæˆ: {len(valid_results)}/{len(codes)} æœ‰æ•ˆæˆåŠŸ")
        return result
    
    def _has_valid_financial_data(self, data: Dict[str, Any]) -> bool:
        """æ£€æŸ¥è´¢åŠ¡æ•°æ®æ˜¯å¦æœ‰æ•ˆ"""
        if not data:
            return False
        
        # è‡³å°‘åŒ…å«ä¸€äº›å…³é”®æŒ‡æ ‡
        key_metrics = ['revenue', 'net_profit', 'pe_ratio', 'pb_ratio', 'roe', 'market_cap']
        valid_count = 0
        for metric in key_metrics:
            if metric in data and data[metric] is not None:
                valid_count += 1
        
        return valid_count >= 1

    def collect_batch_financial_data(self, codes: List[str], source: str = 'auto') -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡é‡‡é›†è´¢åŠ¡æ•°æ® - æ–°ç­–ç•¥ï¼šBaostockä¸“ä¸šè´¢åŠ¡ä¸ºä¸» â†’ JoinQuantä¸ºè¾… â†’ YFinanceè¡¥å…… â†’ è…¾è®¯ä¼°å€¼"""
        result = {}
        total_codes = len(codes)
        
        print(f"[INFO] æ‰¹é‡é‡‡é›†è´¢åŠ¡æ•°æ®ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        print(f"[INFO] è´¢åŠ¡æ•°æ®ç­–ç•¥: Baostock(ä¸») â†’ JoinQuant(è¾…) â†’ YFinance(è¡¥å……) â†’ è…¾è®¯(ä¼°å€¼) â†’ AKShare(å…œåº•)")
        
        # 1. Baostockä¸»åŠ›ï¼šä¸“ä¸šçš„ä¸­å›½Aè‚¡è´¢åŠ¡æ•°æ®
        baostock_success = []
        if BAOSTOCK_AVAILABLE and self.bs_login:
            print(f"[INFO] Baostockä¸“ä¸šè´¢åŠ¡æ•°æ® {total_codes} åª...")
            try:
                import baostock as bs
                for code in codes:
                    try:
                        bs_code = f"sz.{code}" if code.startswith(('000', '002', '300')) else f"sh.{code}"
                        financial_data = {'code': code, 'source': 'baostock'}
                        
                        # åˆ©æ¶¦è¡¨æ•°æ®
                        rs_profit = bs.query_profit_data(code=bs_code, year="2024", quarter=3)
                        if rs_profit.error_code == '0':
                            while rs_profit.next():
                                row = rs_profit.get_row_data()
                                if len(row) > 10:
                                    financial_data.update({
                                        'revenue': self._safe_float(row[4]),          # è¥ä¸šæ”¶å…¥
                                        'net_profit': self._safe_float(row[5]),       # å‡€åˆ©æ¶¦
                                        'eps': self._safe_float(row[6]),              # æ¯è‚¡æ”¶ç›Š
                                        'roe': self._safe_float(row[7]),              # å‡€èµ„äº§æ”¶ç›Šç‡
                                        'total_profit': self._safe_float(row[8])      # åˆ©æ¶¦æ€»é¢
                                    })
                                    break
                        
                        # æœé‚¦æ•°æ®ï¼ˆè´¢åŠ¡æ¯”ç‡ï¼‰
                        rs_dupont = bs.query_dupont_data(code=bs_code, year="2024", quarter=3)
                        if rs_dupont.error_code == '0':
                            while rs_dupont.next():
                                row = rs_dupont.get_row_data()
                                if len(row) > 8:
                                    financial_data.update({
                                        'roa': self._safe_float(row[4]),              # æ€»èµ„äº§æ”¶ç›Šç‡
                                        'gross_profit_rate': self._safe_float(row[5]), # æ¯›åˆ©ç‡
                                        'net_profit_rate': self._safe_float(row[6]),   # å‡€åˆ©ç‡
                                        'debt_ratio': self._safe_float(row[7])         # èµ„äº§è´Ÿå€ºç‡
                                    })
                                    break
                        
                        if self._has_valid_financial_data(financial_data):
                            result[code] = financial_data
                            baostock_success.append(code)
                        
                        time.sleep(0.08)  # Baostocké€‚åº¦æ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] Baostock {code}: {e}")
                        continue
                
                print(f"[SUCCESS] Baostockè´¢åŠ¡æ•°æ®: {len(baostock_success)}/{total_codes} åª")
            except Exception as e:
                print(f"[ERROR] Baostockè´¢åŠ¡æ•°æ®å¼‚å¸¸: {e}")
        else:
            print(f"[WARN] Baostockä¸å¯ç”¨ï¼Œè·³è¿‡è´¢åŠ¡æ•°æ®é‡‡é›†")
        
        # 2. JoinQuantä¸ºè¾…ï¼šè·å–å¤±è´¥è‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®
        failed_codes = [code for code in codes if code not in result]
        joinquant_success = []
        if failed_codes and self.joinquant:
            print(f"[INFO] JoinQuantä¸ºè¾…è´¢åŠ¡æ•°æ®é‡‡é›† {len(failed_codes)} åª...")
            try:
                for code in failed_codes:
                    try:
                        # JoinQuantè·å–è´¢åŠ¡æ•°æ®
                        financial_info = self._get_joinquant_financial_info(code)
                        if financial_info and self._has_valid_financial_data(financial_info):
                            result[code] = financial_info
                            joinquant_success.append(code)
                        time.sleep(0.1)
                    except Exception as e:
                        print(f"[DEBUG] JoinQuantè´¢åŠ¡ {code}: {e}")
                        continue
                
                print(f"[SUCCESS] JoinQuantè´¢åŠ¡æ•°æ®: {len(joinquant_success)}/{len(failed_codes)} åª")
            except Exception as e:
                print(f"[ERROR] JoinQuantè´¢åŠ¡æ•°æ®å¼‚å¸¸: {e}")
        elif failed_codes and not self.joinquant:
            print(f"[WARN] JoinQuant APIæœªåˆå§‹åŒ–ï¼Œè·³è¿‡è´¢åŠ¡æ•°æ®é‡‡é›† {len(failed_codes)} åªè‚¡ç¥¨")
        
        # 3. YFinanceè¡¥å……ï¼šå›½é™…åŒ–ä¼°å€¼æŒ‡æ ‡
        still_failed = [code for code in codes if code not in result]
        yfinance_success = []
        if still_failed and YFINANCE_AVAILABLE:
            print(f"[INFO] YFinanceä¼°å€¼è¡¥å…… {len(still_failed)} åª...")
            try:
                for code in still_failed:
                    try:
                        symbol = f"{code}.SZ" if code.startswith(('000', '002', '300')) else f"{code}.SS"
                        ticker = yf.Ticker(symbol)
                        info = ticker.info
                        
                        if info:
                            financial_data = {
                                'code': code,
                                'source': 'yfinance',
                                'market_cap': info.get('marketCap'),
                                'pe_ratio': info.get('trailingPE'),
                                'pb_ratio': info.get('priceToBook'),
                                'ps_ratio': info.get('priceToSalesTrailing12Months'),
                                'dividend_yield': info.get('dividendYield'),
                                'beta': info.get('beta'),
                                'profit_margins': info.get('profitMargins'),
                                'revenue_growth': info.get('revenueGrowth')
                            }
                            
                            if self._has_valid_financial_data(financial_data):
                                result[code] = financial_data
                        
                        time.sleep(0.25)  # YFinanceæ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] YFinance {code}: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] YFinanceè¡¥å……å¼‚å¸¸: {e}")
        
        # 3. è…¾è®¯å®æ—¶ï¼šå¸‚åœºå®æ—¶ä¼°å€¼æ•°æ®
        still_failed = [code for code in codes if code not in result]
        if still_failed and REQUESTS_AVAILABLE:
            print(f"[INFO] è…¾è®¯å®æ—¶ä¼°å€¼ {len(still_failed)} åª...")
            try:
                # è…¾è®¯æ‰¹é‡è·å–å®æ—¶æ•°æ®
                batch_symbols = ','.join([f's_{code}' for code in still_failed])
                url = f'https://qt.gtimg.cn/q={batch_symbols}'
                
                response = requests.get(url, timeout=15)
                if response.status_code == 200:
                    lines = response.text.split('\\n')
                    for i, line in enumerate(lines):
                        if i >= len(still_failed) or not line.strip():
                            continue
                        
                        code = still_failed[i]
                        try:
                            parts = line.split('~')
                            if len(parts) > 40:
                                financial_data = {
                                    'code': code,
                                    'source': 'tencent',
                                    'current_price': self._safe_float(parts[3]),
                                    'pe_ratio': self._safe_float(parts[39]) if len(parts) > 39 else None,
                                    'pb_ratio': self._safe_float(parts[46]) if len(parts) > 46 else None,
                                    'market_cap': self._safe_float(parts[45]) if len(parts) > 45 else None,
                                    'turnover_rate': self._safe_float(parts[38]) if len(parts) > 38 else None
                                }
                                
                                if self._has_valid_financial_data(financial_data):
                                    result[code] = financial_data
                        except Exception as e:
                            print(f"[DEBUG] è…¾è®¯è§£æ {code}: {e}")
                            continue
            except Exception as e:
                print(f"[ERROR] è…¾è®¯å®æ—¶æ•°æ®å¼‚å¸¸: {e}")
        
        # 4. AKShareæœ€ç»ˆå…œåº•ï¼šå°‘é‡å¤±è´¥è‚¡ç¥¨
        final_failed = [code for code in codes if code not in result]
        if final_failed and AKSHARE_AVAILABLE and len(final_failed) <= 5:
            print(f"[INFO] AKShareæœ€ç»ˆå…œåº• {len(final_failed)} åª...")
            try:
                for code in final_failed:
                    try:
                        df = ak.stock_individual_info_em(symbol=code)
                        if df is not None and not df.empty:
                            info_dict = dict(zip(df['item'], df['value']))
                            
                            financial_data = {
                                'code': code,
                                'source': 'akshare',
                                'pe_ratio': self._safe_float(info_dict.get('å¸‚ç›ˆç‡')),
                                'pb_ratio': self._safe_float(info_dict.get('å¸‚å‡€ç‡')),
                                'market_cap': self._safe_float(info_dict.get('æ€»å¸‚å€¼')),
                                'revenue': self._safe_float(info_dict.get('è¥ä¸šæ”¶å…¥')),
                                'net_profit': self._safe_float(info_dict.get('å‡€åˆ©æ¶¦'))
                            }
                            
                            if self._has_valid_financial_data(financial_data):
                                result[code] = financial_data
                        
                        time.sleep(0.5)  # AKShareä¸¥æ ¼æ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] AKShare {code}: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] AKShareå…œåº•å¼‚å¸¸: {e}")
        
        success_count = len(result)
        success_rate = success_count / total_codes * 100 if total_codes > 0 else 0
        print(f"[SUMMARY] è´¢åŠ¡æ•°æ®é‡‡é›†å®Œæˆ: {success_count}/{total_codes} ({success_rate:.1f}%)")
        
        return result
    
    def collect_batch_industry_concept(self, codes: List[str], source: str = 'auto') -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡é‡‡é›†è¡Œä¸šæ¦‚å¿µæ•°æ® - æ–°ç­–ç•¥ï¼šBaostockè¡Œä¸šåˆ†ç±»ä¸ºä¸»ï¼ŒAKShareæ¦‚å¿µè¡¥å……"""
        result = {}
        total_codes = len(codes)
        
        print(f"[INFO] æ‰¹é‡é‡‡é›†è¡Œä¸šæ¦‚å¿µæ•°æ®ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        print(f"[INFO] è¡Œä¸šæ¦‚å¿µç­–ç•¥: Baostock(æ ‡å‡†è¡Œä¸š) â†’ AKShare(çƒ­é—¨æ¦‚å¿µ) â†’ é»˜è®¤åˆ†ç±»")
        
        # 1. Baostockä¸»åŠ›ï¼šæ ‡å‡†è¡Œä¸šåˆ†ç±»ï¼ˆä¸€æ¬¡æ€§è·å–å…¨é‡æ˜ å°„ï¼‰
        baostock_success = []
        if BAOSTOCK_AVAILABLE and self.bs_login:
            print(f"[INFO] Baostockæ ‡å‡†è¡Œä¸šåˆ†ç±»æ˜ å°„...")
            try:
                import baostock as bs

                # è·å–å®Œæ•´è¡Œä¸šåˆ†ç±»æ˜ å°„è¡¨ï¼ˆæ•ˆç‡æ›´é«˜ï¼‰
                rs = bs.query_stock_industry()
                industry_mapping = {}
                
                if rs.error_code == '0':
                    while rs.next():
                        row = rs.get_row_data()
                        if len(row) >= 3:
                            stock_code = row[0].split('.')[-1]  # ç§»é™¤sh./sz.å‰ç¼€
                            industry_mapping[stock_code] = {
                                'industry': row[1],
                                'industry_name': row[2] if len(row) > 2 else row[1],
                                'update_date': row[3] if len(row) > 3 else None
                            }
                
                print(f"[INFO] Baostockè¡Œä¸šæ˜ å°„è·å–å®Œæˆ: {len(industry_mapping)} åªè‚¡ç¥¨")
                
                # æ‰¹é‡åŒ¹é…ç›®æ ‡è‚¡ç¥¨
                for code in codes:
                    if code in industry_mapping:
                        industry_info = industry_mapping[code]
                        result[code] = {
                            'code': code,
                            'source': 'baostock',
                            'industry': industry_info['industry'],
                            'industry_name': industry_info['industry_name'],
                            'sector': self._classify_sector(industry_info['industry']),
                            'concepts': [],  # åç»­è¡¥å……
                            'industry_update_date': industry_info['update_date']
                        }
                        baostock_success.append(code)
                    else:
                        # æ— æ˜ å°„çš„è‚¡ç¥¨è®¾ç½®é»˜è®¤å€¼
                        result[code] = {
                            'code': code,
                            'source': 'baostock_default',
                            'industry': self._guess_industry_by_code(code),
                            'industry_name': None,
                            'sector': None,
                            'concepts': []
                        }
                
                print(f"[SUCCESS] Baostockè¡Œä¸šåˆ†ç±»: {len(baostock_success)}/{total_codes}")
            except Exception as e:
                print(f"[ERROR] Baostockè¡Œä¸šåˆ†ç±»å¼‚å¸¸: {e}")
        
        # 2. AKShareè¡¥å……ï¼šçƒ­é—¨æ¦‚å¿µå’Œè¯¦ç»†åˆ†ç±»
        # ğŸ”´ ä¼˜åŒ–ï¼šåœ¨Kçº¿æ›´æ–°åœºæ™¯ä¸‹ï¼Œè·³è¿‡AKShareæ¦‚å¿µæŸ¥è¯¢ï¼ˆé¿å…å¤§é‡APIè°ƒç”¨ï¼‰
        # åªæœ‰åœ¨å°æ‰¹é‡æ—¶æ‰æŸ¥è¯¢æ¦‚å¿µï¼ˆ<=10åªï¼‰
        concept_codes = codes.copy()
        skip_concepts = len(concept_codes) > 10  # è¶…è¿‡10åªè‚¡ç¥¨åˆ™è·³è¿‡æ¦‚å¿µæŸ¥è¯¢
        
        if not skip_concepts and concept_codes and AKSHARE_AVAILABLE:
            print(f"[INFO] AKShareçƒ­é—¨æ¦‚å¿µè¡¥å…… {len(concept_codes)} åª...")
            try:
                for code in concept_codes:
                    try:
                        # è·å–ä¸ªè‚¡æ¦‚å¿µä¿¡æ¯
                        df_concept = ak.stock_board_concept_cons_em(symbol=code)
                        if df_concept is not None and not df_concept.empty:
                            concepts = df_concept['æ¿å—åç§°'].tolist()[:5]  # æœ€å¤š5ä¸ªæ¦‚å¿µ
                            
                            if code not in result:
                                result[code] = {'code': code}
                            
                            result[code].update({
                                'concepts': concepts,
                                'hot_concepts': [c for c in concepts if 'æ–°' in c or 'çƒ­' in c or 'é¾™å¤´' in c],
                                'concept_source': 'akshare'
                            })
                        
                        time.sleep(0.8)  # AKShareæ¦‚å¿µæŸ¥è¯¢æ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] AKShareæ¦‚å¿µ {code}: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] AKShareæ¦‚å¿µè¡¥å……å¼‚å¸¸: {e}")
        elif skip_concepts:
            print(f"[INFO] æ‰¹é‡æ›´æ–°æ¨¡å¼ï¼šè·³è¿‡AKShareæ¦‚å¿µæŸ¥è¯¢ï¼ˆ{len(concept_codes)}åªè‚¡ç¥¨ï¼‰ï¼Œä»…æ›´æ–°è¡Œä¸šä¿¡æ¯")
        
        # 3. é»˜è®¤åˆ†ç±»ï¼šä¸ºæ— æ•°æ®è‚¡ç¥¨æä¾›åŸºç¡€åˆ†ç±»
        unclassified_codes = [code for code in codes if code not in result or not result[code].get('industry')]
        for code in unclassified_codes:
            default_industry = self._guess_industry_by_code(code)
            default_sector = self._classify_sector(default_industry)
            
            result[code] = {
                'code': code,
                'source': 'default',
                'industry': default_industry,
                'industry_name': default_industry,
                'sector': default_sector,
                'concepts': [],
                'message': 'ä½¿ç”¨é»˜è®¤è¡Œä¸šåˆ†ç±»'
            }
        
        success_count = len([r for r in result.values() if r.get('source') not in ['default', 'baostock_default']])
        success_rate = success_count / total_codes * 100 if total_codes > 0 else 0
        print(f"[SUMMARY] è¡Œä¸šæ¦‚å¿µé‡‡é›†å®Œæˆ: {success_count}/{total_codes} ({success_rate:.1f}%)")
        
        return result
    
    def _classify_sector(self, industry: str) -> str:
        """æ ¹æ®è¡Œä¸šåˆ†ç±»æ¨æ–­æ¿å—"""
        if not industry:
            return None
        
        sector_mapping = {
            'é“¶è¡Œ': 'é‡‘èä¸š', 'ä¿é™©': 'é‡‘èä¸š', 'è¯åˆ¸': 'é‡‘èä¸š',
            'æˆ¿åœ°äº§': 'æˆ¿åœ°äº§ä¸š', 'å»ºç­‘': 'å»ºç­‘ä¸š', 'å·¥ç¨‹': 'å»ºç­‘ä¸š',
            'ç”µåŠ›': 'ç”µåŠ›ã€çƒ­åŠ›ã€ç‡ƒæ°”', 'ç…¤ç‚­': 'é‡‡çŸ¿ä¸š', 'çŸ³æ²¹': 'é‡‡çŸ¿ä¸š',
            'é’¢é“': 'åˆ¶é€ ä¸š', 'æœ‰è‰²': 'åˆ¶é€ ä¸š', 'åŒ–å·¥': 'åˆ¶é€ ä¸š',
            'åŒ»è¯': 'åˆ¶é€ ä¸š', 'é£Ÿå“': 'åˆ¶é€ ä¸š', 'çººç»‡': 'åˆ¶é€ ä¸š',
            'æ±½è½¦': 'åˆ¶é€ ä¸š', 'ç”µå­': 'åˆ¶é€ ä¸š', 'æœºæ¢°': 'åˆ¶é€ ä¸š',
            'è®¡ç®—æœº': 'ä¿¡æ¯æŠ€æœ¯ä¸š', 'é€šä¿¡': 'ä¿¡æ¯æŠ€æœ¯ä¸š', 'è½¯ä»¶': 'ä¿¡æ¯æŠ€æœ¯ä¸š',
            'ä¼ åª’': 'æ–‡åŒ–ã€ä½“è‚²å’Œå¨±ä¹ä¸š', 'æ•™è‚²': 'æ•™è‚²ä¸š',
            'äº¤é€š': 'äº¤é€šè¿è¾“ä¸š', 'ç‰©æµ': 'äº¤é€šè¿è¾“ä¸š',
            'å•†è´¸': 'æ‰¹å‘å’Œé›¶å”®ä¸š', 'é›¶å”®': 'æ‰¹å‘å’Œé›¶å”®ä¸š'
        }
        
        for key, sector in sector_mapping.items():
            if key in industry:
                return sector
        
        return 'å…¶ä»–'
    
    def _guess_industry_by_code(self, code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç æ¨æµ‹è¡Œä¸šï¼ˆç®€å•è§„åˆ™ï¼‰"""
        if code.startswith('60'):
            if code.startswith('600'):
                return 'ä¼ ç»Ÿåˆ¶é€ ä¸š'
            elif code.startswith('601'):
                return 'å¤§å‹å›½ä¼'
            elif code.startswith('603'):
                return 'æ–°ä¸Šå¸‚ä¼ä¸š'
        elif code.startswith('000'):
            return 'æ·±åœ³ä¸»æ¿'
        elif code.startswith('002'):
            return 'ä¸­å°æ¿ä¼ä¸š'
        elif code.startswith('300'):
            return 'åˆ›ä¸šæ¿/ç§‘æŠ€'
        
        return 'æœªåˆ†ç±»è¡Œä¸š'
    
    def collect_batch_fund_flow(self, codes: List[str], source: str = 'auto') -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡é‡‡é›†èµ„é‡‘æµå‘æ•°æ® - æ–°ç­–ç•¥ï¼šè…¾è®¯ä¸ºä¸»(å®æ—¶å‡†ç¡®)ï¼ŒAKShareè¡¥å……"""
        result = {}
        total_codes = len(codes)
        
        print(f"[INFO] æ‰¹é‡é‡‡é›†èµ„é‡‘æµå‘æ•°æ®ï¼Œå…± {total_codes} åªè‚¡ç¥¨")
        print(f"[INFO] èµ„é‡‘æµå‘ç­–ç•¥: è…¾è®¯(å®æ—¶ä¸»åŠ›+è¶…å¤§å•) â†’ AKShare(ä¸ªè‚¡èµ„é‡‘æµ)")
        
        # 1. è…¾è®¯ä¸»åŠ›ï¼šå®æ—¶èµ„é‡‘æµå‘æ•°æ®ï¼ˆä¼˜åŠ¿æ˜æ˜¾ï¼‰
        tencent_success = []
        if REQUESTS_AVAILABLE:
            print(f"[INFO] è…¾è®¯å®æ—¶èµ„é‡‘æµå‘ {total_codes} åª...")
            try:
                # è…¾è®¯æ”¯æŒå•ç‹¬æŸ¥è¯¢ï¼Œä½†æ‰¹é‡æ•ˆæœæ›´å¥½
                for code in codes:
                    try:
                        # ä¸»åŠ›èµ„é‡‘æµå‘API
                        url = f'https://qt.gtimg.cn/q=ff_{code}'
                        response = requests.get(url, timeout=10)
                        
                        if response.status_code == 200:
                            parts = response.text.split('~')
                            if len(parts) > 8:
                                fund_flow_data = {
                                    'code': code,
                                    'source': 'tencent',
                                    'main_fund_inflow': self._safe_float(parts[1]),      # ä¸»åŠ›å‡€æµå…¥
                                    'super_fund_inflow': self._safe_float(parts[2]),     # è¶…å¤§å•å‡€æµå…¥
                                    'large_fund_inflow': self._safe_float(parts[3]),     # å¤§å•å‡€æµå…¥
                                    'medium_fund_inflow': self._safe_float(parts[4]),    # ä¸­å•å‡€æµå…¥
                                    'small_fund_inflow': self._safe_float(parts[5]),     # å°å•å‡€æµå…¥
                                    'main_fund_inflow_pct': self._safe_float(parts[6]),  # ä¸»åŠ›å‡€æµå…¥å æ¯”
                                    'fund_flow_score': self._safe_float(parts[7])        # èµ„é‡‘æµå‘è¯„åˆ†
                                }
                                
                                # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                                if any(fund_flow_data[key] is not None for key in ['main_fund_inflow', 'super_fund_inflow', 'large_fund_inflow']):
                                    result[code] = fund_flow_data
                                    tencent_success.append(code)
                        
                        time.sleep(0.1)  # è…¾è®¯é€‚åº¦æ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] è…¾è®¯èµ„é‡‘æµå‘ {code}: {e}")
                        continue
                
                print(f"[SUCCESS] è…¾è®¯èµ„é‡‘æµå‘: {len(tencent_success)}/{total_codes}")
            except Exception as e:
                print(f"[ERROR] è…¾è®¯èµ„é‡‘æµå‘å¼‚å¸¸: {e}")
        
        # 2. AKShareè¡¥å……ï¼šä¸ªè‚¡è¯¦ç»†èµ„é‡‘æµå‘
        failed_codes = [code for code in codes if code not in result]
        if failed_codes and AKSHARE_AVAILABLE and AKSHARE_CONNECTED and len(failed_codes) <= 8: # é™åˆ¶æ•°é‡é¿å…é¢‘ç‡é—®é¢˜
            print(f"[INFO] AKShareèµ„é‡‘æµå‘è¡¥å…… {len(failed_codes)} åª...")
            try:
                for code in failed_codes:
                    try:
                        # AKShareä¸ªè‚¡èµ„é‡‘æµå‘
                        market = "sh" if code.startswith('6') else "sz"
                        df_fund = ak.stock_individual_fund_flow(stock=code, market=market)
                        
                        if df_fund is not None and not df_fund.empty:
                            latest_data = df_fund.iloc[-1]
                            fund_flow_data = {
                                'code': code,
                                'source': 'akshare',
                                'main_fund_inflow': self._safe_float(latest_data.get('ä¸»åŠ›å‡€æµå…¥-å‡€æµå…¥')),
                                'super_fund_inflow': self._safe_float(latest_data.get('è¶…å¤§å•å‡€æµå…¥-å‡€æµå…¥')),
                                'large_fund_inflow': self._safe_float(latest_data.get('å¤§å•å‡€æµå…¥-å‡€æµå…¥')),
                                'medium_fund_inflow': self._safe_float(latest_data.get('ä¸­å•å‡€æµå…¥-å‡€æµå…¥')),
                                'small_fund_inflow': self._safe_float(latest_data.get('å°å•å‡€æµå…¥-å‡€æµå…¥')),
                                'main_fund_inflow_pct': self._safe_float(latest_data.get('ä¸»åŠ›å‡€æµå…¥-å‡€æµå…¥å æ¯”')),
                                'date': str(latest_data.get('æ—¥æœŸ', ''))
                            }
                            
                            if any(fund_flow_data[key] is not None for key in ['main_fund_inflow', 'super_fund_inflow']):
                                result[code] = fund_flow_data
                        
                        time.sleep(0.6)  # AKShareä¸¥æ ¼æ§é¢‘
                    except Exception as e:
                        print(f"[DEBUG] AKShareèµ„é‡‘æµå‘ {code}: {e}")
                        continue
            except Exception as e:
                print(f"[ERROR] AKShareèµ„é‡‘æµå‘å¼‚å¸¸: {e}")
        
        # 3. ä¸ºæ— æ•°æ®è‚¡ç¥¨æä¾›é»˜è®¤ç»“æ„
        final_failed = [code for code in codes if code not in result]
        for code in final_failed:
            result[code] = {
                'code': code,
                'source': 'default',
                'main_fund_inflow': None,
                'super_fund_inflow': None,
                'large_fund_inflow': None,
                'medium_fund_inflow': None,
                'small_fund_inflow': None,
                'main_fund_inflow_pct': None,
                'message': 'èµ„é‡‘æµå‘æ•°æ®æš‚æ— '
            }
        
        success_count = len([r for r in result.values() if r.get('source') != 'default'])
        success_rate = success_count / total_codes * 100 if total_codes > 0 else 0
        print(f"[SUMMARY] èµ„é‡‘æµå‘é‡‡é›†å®Œæˆ: {success_count}/{total_codes} ({success_rate:.1f}%)")
        
        return result
    
    def collect_news_announcements(self, code: str, source: str) -> Dict[str, Any]:
        """é‡‡é›†æ–°é—»å…¬å‘Šæ•°æ®"""
        news_data = {
            'recent_announcements': [],
            'news_sentiment': None,
            'important_events': [],
            'source': source
        }
        
        try:
            # ä¼˜å…ˆä½¿ç”¨ Jina API è·å–æ–°é—»
            if JINA_AVAILABLE and self.jina_api and self.jina_api.api_key and self.jina_api.api_key != "YOUR_JINA_API_KEY":
                try:
                    # è·å–è‚¡ç¥¨åç§°
                    name = f"è‚¡ç¥¨{code}"
                    # å°è¯•ä»å·²æ”¶é›†çš„æ•°æ®ä¸­è·å–åç§°
                    if code in self.collected_data and 'name' in self.collected_data[code]:
                        name = self.collected_data[code]['name']
                    elif code in self.wait_period_data and 'basic_info' in self.wait_period_data[code]:
                        name = self.wait_period_data[code]['basic_info'].get('name', name)
                        
                    jina_news = self.jina_api.get_stock_news(code, name)
                    if jina_news:
                        news_data['recent_announcements'] = jina_news
                        news_data['source'] = 'jina_search'
                        # ç®€å•çš„å…³é”®è¯æƒ…æ„Ÿåˆ†æ
                        sentiment_score = 0
                        for item in jina_news:
                            title = item.get('title', '')
                            if 'åˆ©å¥½' in title or 'ä¸Šæ¶¨' in title or 'å¢é•¿' in title:
                                sentiment_score += 1
                            if 'åˆ©ç©º' in title or 'ä¸‹è·Œ' in title or 'äºæŸ' in title:
                                sentiment_score -= 1
                        
                        if sentiment_score > 0:
                            news_data['news_sentiment'] = 'positive'
                        elif sentiment_score < 0:
                            news_data['news_sentiment'] = 'negative'
                        else:
                            news_data['news_sentiment'] = 'neutral'
                            
                        return news_data
                except Exception as e:
                    print(f"[WARN] Jina API æ–°é—»é‡‡é›†å¤±è´¥: {e}")

            if source == 'akshare' and AKSHARE_AVAILABLE:
                # è·å–å…¬å¸å…¬å‘Š
                try:
                    announcement_df = ak.stock_notice_report(symbol=code)
                    if announcement_df is not None and not announcement_df.empty:
                        recent = announcement_df.head(10)  # æœ€è¿‘10æ¡å…¬å‘Š
                        news_data['recent_announcements'] = [
                            {
                                'date': row.get('å…¬å‘Šæ—¥æœŸ', ''),
                                'title': row.get('å…¬å‘Šæ ‡é¢˜', ''),
                                'type': row.get('å…¬å‘Šç±»å‹', '')
                            }
                            for _, row in recent.iterrows()
                        ]
                except:
                    pass
        
        except Exception as e:
            print(f"[WARN] {code} æ–°é—»å…¬å‘Šæ•°æ®é‡‡é›†å¤±è´¥ ({source}): {e}")
        
        return news_data
    
    def _collect_non_kline_data_during_wait(self, codes: List[str], wait_seconds: int) -> None:
        """åœ¨ç­‰å¾…æœŸé—´æ”¶é›†éKçº¿æ•°æ®ä»¥æé«˜æ•ˆç‡ - ä½¿ç”¨åˆ†å±‚æ•°æ®æºç­–ç•¥"""
        print(f"[INFO] ç­‰å¾…æœŸé—´ä½¿ç”¨åˆ†å±‚æ•°æ®æºç­–ç•¥æ”¶é›†{len(codes)}åªè‚¡ç¥¨çš„å…¶ä»–æ•°æ®...")
        
        start_time = time.time()
        collected_count = 0
        
        for code in codes:
            if time.time() - start_time >= wait_seconds - 5:  # é¢„ç•™5ç§’ç¼“å†²
                break
                
            try:
                if code not in self.wait_period_data:
                    self.wait_period_data[code] = {}
                
                # 1. åŸºç¡€ä¿¡æ¯ - ä¼˜å…ˆyfinance, tencent, å…œåº•akshare
                if 'basic_info' not in self.wait_period_data[code]:
                    for source in self.wait_period_strategy['basic_info']:
                        if time.time() - start_time >= wait_seconds - 10:
                            break
                        
                        basic_info = self.collect_basic_info(code, source)
                        if basic_info and basic_info.get('name') and basic_info['name'] != f'è‚¡ç¥¨{code}':
                            self.wait_period_data[code]['basic_info'] = basic_info
                            print(f"    âœ“ {code}: åŸºç¡€ä¿¡æ¯ ({source})")
                            break
                
                # 2. è¡Œä¸šæ¦‚å¿µ - ä¼˜å…ˆbaostock, å…œåº•akshare
                if time.time() - start_time < wait_seconds - 15 and 'industry_concept' not in self.wait_period_data[code]:
                    for source in self.wait_period_strategy['industry_concept']:
                        if time.time() - start_time >= wait_seconds - 20:
                            break
                        
                        industry_concept = self.collect_industry_concept_info(code, source)
                        if industry_concept and (industry_concept.get('industry') or industry_concept.get('concepts')):
                            self.wait_period_data[code]['industry_concept'] = industry_concept
                            print(f"    âœ“ {code}: è¡Œä¸šæ¦‚å¿µ ({source})")
                            break
                
                # 3. è´¢åŠ¡æ•°æ® - ä¼˜å…ˆbaostock, å…œåº•akshare
                if time.time() - start_time < wait_seconds - 25 and 'financial_data' not in self.wait_period_data[code]:
                    for source in self.wait_period_strategy['financial_data']:
                        if time.time() - start_time >= wait_seconds - 30:
                            break
                        
                        financial_data = self.collect_financial_data(code, source)
                        if financial_data and any(v is not None for v in financial_data.values() if v != source):
                            self.wait_period_data[code]['financial_data'] = financial_data
                            print(f"    âœ“ {code}: è´¢åŠ¡æ•°æ® ({source})")
                            break
                
                # 4. èµ„é‡‘æµå‘ - ä¼˜å…ˆtencent, å…œåº•akshare
                if time.time() - start_time < wait_seconds - 35 and 'fund_flow' not in self.wait_period_data[code]:
                    for source in self.wait_period_strategy['fund_flow']:
                        if time.time() - start_time >= wait_seconds - 40:
                            break
                        
                        fund_flow = self.collect_fund_flow_data(code, source)
                        if fund_flow and any(v is not None for v in fund_flow.values() if v != source):
                            self.wait_period_data[code]['fund_flow'] = fund_flow
                            print(f"    âœ“ {code}: èµ„é‡‘æµå‘ ({source})")
                            break
                
                collected_count += 1
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"    âš ï¸ {code}: ç­‰å¾…æœŸé—´æ•°æ®æ”¶é›†å¤±è´¥ - {e}")
                continue
        
        elapsed = time.time() - start_time
        print(f"[INFO] ç­‰å¾…æœŸé—´å·²æ”¶é›†{collected_count}åªè‚¡ç¥¨çš„å…¶ä»–æ•°æ®ï¼Œç”¨æ—¶{elapsed:.1f}ç§’")
        print(f"[INFO] æ•°æ®æºä½¿ç”¨ç­–ç•¥: åŸºç¡€ä¿¡æ¯({self.wait_period_strategy['basic_info']})")
        print(f"[INFO]                è¡Œä¸šæ¦‚å¿µ({self.wait_period_strategy['industry_concept']})")
        print(f"[INFO]                è´¢åŠ¡æ•°æ®({self.wait_period_strategy['financial_data']})")
        print(f"[INFO]                èµ„é‡‘æµå‘({self.wait_period_strategy['fund_flow']})")
    
    def _collect_parallel_data_during_wait(self, remaining_codes: List[str], all_codes: List[str], 
                                         wait_seconds: int, result: Dict, start_str: str, end_str: str) -> None:
        """åœ¨ç­‰å¾…æœŸé—´å¹¶è¡Œæ”¶é›†Kçº¿æ•°æ®å’Œå…¶ä»–æ•°æ®"""
        print(f"[INFO] ç­‰å¾…æœŸé—´å¹¶è¡Œæ”¶é›†ç­–ç•¥: Kçº¿æ•°æ®(akshare) + å…¶ä»–æ•°æ®(åˆ†å±‚æº)")
        
        start_time = time.time()
        akshare_kline_count = 0
        other_data_count = 0
        
        # è·å–è¿˜æ²¡æœ‰Kçº¿æ•°æ®çš„è‚¡ç¥¨
        missing_kline_codes = [code for code in all_codes if code not in result][:10]  # æœ€å¤š10åª
        
        for i, code in enumerate(remaining_codes):
            if time.time() - start_time >= wait_seconds - 5:  # é¢„ç•™5ç§’ç¼“å†²
                break
            
            try:
                # 1. å¦‚æœè¿˜æœ‰è‚¡ç¥¨æ²¡æœ‰Kçº¿æ•°æ®ï¼Œä¼˜å…ˆç”¨akshareè·å–Kçº¿
                if i < len(missing_kline_codes) and time.time() - start_time < wait_seconds - 15:
                    kline_code = missing_kline_codes[i]
                    print(f"    [Kçº¿] ä½¿ç”¨akshareè·å– {kline_code} Kçº¿æ•°æ®...")
                    
                    kline_data = self._collect_kline_with_akshare(kline_code, start_str, end_str)
                    if kline_data is not None and not kline_data.empty:
                        result[kline_code] = kline_data
                        akshare_kline_count += 1
                        print(f"    âœ“ [Kçº¿] {kline_code}: {len(kline_data)}å¤©Kçº¿æ•°æ® (akshare)")
                    else:
                        print(f"    âœ— [Kçº¿] {kline_code}: akshareè·å–å¤±è´¥")
                
                # 2. å¹¶è¡Œæ”¶é›†å…¶ä»–æ•°æ®
                if code not in self.wait_period_data:
                    self.wait_period_data[code] = {}
                
                # å¿«é€Ÿæ”¶é›†åŸºç¡€ä¿¡æ¯
                if 'basic_info' not in self.wait_period_data[code] and time.time() - start_time < wait_seconds - 20:
                    for source in self.wait_period_strategy['basic_info']:
                        if time.time() - start_time >= wait_seconds - 25:
                            break
                        basic_info = self.collect_basic_info(code, source)
                        if basic_info and basic_info.get('name') and basic_info['name'] != f'è‚¡ç¥¨{code}':
                            self.wait_period_data[code]['basic_info'] = basic_info
                            other_data_count += 1
                            print(f"    âœ“ [å…¶ä»–] {code}: åŸºç¡€ä¿¡æ¯ ({source})")
                            break
                
                # æ”¶é›†è´¢åŠ¡æ•°æ®ï¼ˆå¦‚æœæ—¶é—´å……è¶³ï¼‰
                if ('financial_data' not in self.wait_period_data[code] and 
                    time.time() - start_time < wait_seconds - 30):
                    for source in self.wait_period_strategy['financial_data']:
                        if time.time() - start_time >= wait_seconds - 35:
                            break
                        financial_data = self.collect_financial_data(code, source)
                        if financial_data and any(v is not None for v in financial_data.values() if v != source):
                            self.wait_period_data[code]['financial_data'] = financial_data
                            print(f"    âœ“ [å…¶ä»–] {code}: è´¢åŠ¡æ•°æ® ({source})")
                            break
                
                time.sleep(0.5)  # çŸ­æš‚å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"    âš ï¸ {code}: å¹¶è¡Œæ•°æ®æ”¶é›†å¤±è´¥ - {e}")
                continue
        
        elapsed = time.time() - start_time
        print(f"[INFO] ç­‰å¾…æœŸé—´å¹¶è¡Œæ”¶é›†å®Œæˆï¼Œç”¨æ—¶{elapsed:.1f}ç§’")
        print(f"[INFO]   - akshare Kçº¿æ•°æ®: {akshare_kline_count}åªè‚¡ç¥¨")
        print(f"[INFO]   - å…¶ä»–æ•°æ®: {other_data_count}é¡¹")
    
    def _collect_kline_with_akshare(self, code: str, start_str: str, end_str: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨akshareè·å–Kçº¿æ•°æ®"""
        try:
            if not AKSHARE_AVAILABLE or not AKSHARE_CONNECTED:
                return None
            
            import akshare as ak
            df = ak.stock_zh_a_hist(symbol=code, period="daily", 
                                   start_date=start_str, end_date=end_str, adjust="qfq")
            if df is not None and not df.empty:
                # æ•°æ®æ ¼å¼æ ‡å‡†åŒ–ï¼Œä¸tushareä¿æŒä¸€è‡´
                df['trade_date'] = pd.to_datetime(df['æ—¥æœŸ'])
                df = df.sort_values('trade_date')
                df = df.rename(columns={
                    'trade_date': 'date', 'å¼€ç›˜': 'open', 'æœ€é«˜': 'high',
                    'æœ€ä½': 'low', 'æ”¶ç›˜': 'close', 'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount'
                })
                # åªä¿ç•™éœ€è¦çš„åˆ—
                return df[['date', 'open', 'high', 'low', 'close', 'volume', 'amount']]
            
        except Exception as e:
            print(f"[DEBUG] akshare Kçº¿è·å–å¤±è´¥ {code}: {e}")
        
        return None

    def collect_kline_data(self, code: str, source: str = 'auto', days: int = None) -> Optional[pd.DataFrame]:
        """æ”¶é›†å•ä¸ªè‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        # æ£€æŸ¥è‚¡ç¥¨çŠ¶æ€ï¼Œå¦‚æœå·²é€€å¸‚åˆ™è·³è¿‡
        if STOCK_STATUS_CHECKER_AVAILABLE and self.status_checker:
            try:
                status_info = self.status_checker.check_single_stock(code)
                if status_info['status'] in ['delisted', 'invalid']:
                    print(f"[SKIP] {code} å·²{status_info['status']}ï¼Œè·³è¿‡Kçº¿æ•°æ®æ”¶é›†")
                    return None
            except Exception as e:
                print(f"[DEBUG] {code} çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {e}ï¼Œç»§ç»­æ”¶é›†")
        
        if days is None:
            days = self.kline_days
            
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # å‡†å¤‡ä¸åŒæ ¼å¼çš„æ—¥æœŸ
        start_compact = start_date.strftime('%Y%m%d')
        end_compact = end_date.strftime('%Y%m%d')
        start_iso = start_date.strftime('%Y-%m-%d')
        end_iso = end_date.strftime('%Y-%m-%d')
        
        # 1. AKShare
        if source == 'akshare' or (source == 'auto' and AKSHARE_AVAILABLE):
            return self._collect_kline_with_akshare(code, start_compact, end_compact)
            
        # 2. Tushare
        if source == 'tushare' or (source == 'auto' and TUSHARE_AVAILABLE and self.tushare_token):
            try:
                pro = ts.pro_api(self.tushare_token)
                # ä¼˜åŒ–è‚¡ç¥¨ä»£ç åç¼€é€»è¾‘
                if code.startswith(('000', '001', '002', '300', '301')):
                    ts_code = f"{code}.SZ"
                elif code.startswith(('4', '8', '9')):
                    ts_code = f"{code}.BJ"
                else:
                    ts_code = f"{code}.SH"
                    
                df = pro.daily(ts_code=ts_code, start_date=start_compact, end_date=end_compact)
                if df is not None and not df.empty:
                    return self.standardize_kline_columns(df, 'tushare')
            except Exception as e:
                print(f"[WARN] Tushareè·å–å•è‚¡Kçº¿å¤±è´¥ {code}: {e}")
        
        # 3. Tencent (ä½œä¸ºå…œåº•)
        if self.tencent_kline:
            return self.tencent_kline.get_stock_kline(code, start_iso, end_iso)
            
        return None

    def pre_check_stock_validity(self, codes: List[str], filter_invalid: bool = True) -> Dict[str, List[str]]:
        """
        é¢„æ£€è‚¡ç¥¨æœ‰æ•ˆæ€§ï¼Œè¿‡æ»¤é€€å¸‚å’Œæ— æ•ˆè‚¡ç¥¨
        
        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            filter_invalid: æ˜¯å¦è¿‡æ»¤æ— æ•ˆè‚¡ç¥¨
            
        Returns:
            {
                'valid_codes': æœ‰æ•ˆä¸”æ´»è·ƒçš„è‚¡ç¥¨ä»£ç ,
                'delisted': å·²é€€å¸‚çš„è‚¡ç¥¨,
                'invalid': æ— æ•ˆçš„è‚¡ç¥¨ä»£ç ,
                'suspended': åœç‰Œçš„è‚¡ç¥¨
            }
        """
        print(f"[INFO] å¼€å§‹è‚¡ç¥¨æœ‰æ•ˆæ€§é¢„æ£€: {len(codes)} åªè‚¡ç¥¨...")
        
        try:
            # æ‰¹é‡æ£€æµ‹è‚¡ç¥¨çŠ¶æ€
            status_results = self.status_checker.batch_check_stocks(codes)
            
            # åˆ†ç±»ç»“æœ
            categorized = {
                'valid_codes': [],
                'delisted': [],
                'invalid': [],
                'suspended': [],
                'st': []
            }
            
            for code, info in status_results.items():
                if info['status'] == 'active':
                    categorized['valid_codes'].append(code)
                elif info['status'] == 'delisted':
                    categorized['delisted'].append(code)
                elif info['status'] == 'invalid':
                    categorized['invalid'].append(code)
                elif info['status'] == 'suspended':
                    categorized['suspended'].append(code)
                elif info['status'] == 'st':
                    categorized['st'].append(code)
            
            # æŠ¥å‘Šç»“æœ
            print(f"[SUCCESS] è‚¡ç¥¨é¢„æ£€å®Œæˆ:")
            print(f"  OK æœ‰æ•ˆæ´»è·ƒ: {len(categorized['valid_codes'])} åª")
            print(f"  DELISTED å·²é€€å¸‚: {len(categorized['delisted'])} åª")
            print(f"  INVALID æ— æ•ˆä»£ç : {len(categorized['invalid'])} åª")
            print(f"  SUSPENDED åœç‰Œ: {len(categorized['suspended'])} åª")
            print(f"  ST é£é™©è­¦ç¤º: {len(categorized['st'])} åª")
            
            return categorized
            
        except Exception as e:
            print(f"[ERROR] è‚¡ç¥¨é¢„æ£€å¼‚å¸¸: {e}")
            # å¦‚æœé¢„æ£€å¤±è´¥ï¼Œè¿”å›åŸå§‹ä»£ç åˆ—è¡¨
            return {
                'valid_codes': codes,
                'delisted': [],
                'invalid': [],
                'suspended': []
            }
    
    def clean_delisted_stocks_from_data(self, data_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¸…ç†æ•°æ®ä¸­çš„é€€å¸‚è‚¡ç¥¨
        
        Args:
            data_dict: åŒ…å«è‚¡ç¥¨æ•°æ®çš„å­—å…¸
            
        Returns:
            æ¸…ç†åçš„æ•°æ®å­—å…¸
        """
        if not STOCK_STATUS_CHECKER_AVAILABLE or not self.status_checker:
            return data_dict
        
        print(f"[INFO] å¼€å§‹æ¸…ç†æ•°æ®ä¸­çš„é€€å¸‚è‚¡ç¥¨...")
        
        try:
            # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
            all_codes = list(data_dict.keys())
            if not all_codes:
                return data_dict
            
            # æ£€æŸ¥è‚¡ç¥¨çŠ¶æ€
            validity_check = self.pre_check_stock_validity(all_codes)
            
            # éœ€è¦ç§»é™¤çš„è‚¡ç¥¨ï¼ˆé€€å¸‚å’Œæ— æ•ˆï¼‰
            codes_to_remove = validity_check['delisted'] + validity_check['invalid']
            
            if codes_to_remove:
                print(f"[INFO] å‘ç° {len(codes_to_remove)} åªé€€å¸‚/æ— æ•ˆè‚¡ç¥¨ï¼Œæ­£åœ¨æ¸…ç†...")
                
                cleaned_data = {}
                removed_count = 0
                
                for code, data in data_dict.items():
                    if code not in codes_to_remove:
                        cleaned_data[code] = data
                    else:
                        removed_count += 1
                        print(f"[CLEAN] ç§»é™¤é€€å¸‚è‚¡ç¥¨æ•°æ®: {code}")
                
                print(f"[SUCCESS] æ•°æ®æ¸…ç†å®Œæˆï¼Œç§»é™¤ {removed_count} åªé€€å¸‚è‚¡ç¥¨")
                print(f"[INFO] æ¸…ç†åæ•°æ®: {len(cleaned_data)}/{len(data_dict)} åªè‚¡ç¥¨")
                
                return cleaned_data
            else:
                print(f"[INFO] æ•°æ®ä¸­æ— é€€å¸‚è‚¡ç¥¨ï¼Œæ— éœ€æ¸…ç†")
                return data_dict
                
        except Exception as e:
            print(f"[ERROR] æ¸…ç†é€€å¸‚è‚¡ç¥¨æ•°æ®æ—¶å¼‚å¸¸: {e}")
            return data_dict
    
    def auto_clean_all_data(self):
        """
        è‡ªåŠ¨æ¸…ç†æ‰€æœ‰å·²æ”¶é›†æ•°æ®ä¸­çš„é€€å¸‚è‚¡ç¥¨
        """
        print(f"[INFO] å¼€å§‹è‡ªåŠ¨æ¸…ç†æ‰€æœ‰æ•°æ®ä¸­çš„é€€å¸‚è‚¡ç¥¨...")
        
        # æ¸…ç†ä¸»è¦æ•°æ®
        if hasattr(self, 'collected_data') and self.collected_data:
            print(f"[INFO] æ¸…ç†ä¸»è¦æ”¶é›†æ•°æ®...")
            self.collected_data = self.clean_delisted_stocks_from_data(self.collected_data)
        
        # æ¸…ç†ç­‰å¾…æœŸæ•°æ®
        if hasattr(self, 'wait_period_data') and self.wait_period_data:
            print(f"[INFO] æ¸…ç†ç­‰å¾…æœŸæ•°æ®...")
            self.wait_period_data = self.clean_delisted_stocks_from_data(self.wait_period_data)
        
        # æ¸…ç†å…¶ä»–å¯èƒ½çš„æ•°æ®å­—å…¸
        for attr_name in ['kline_data_cache', 'financial_data_cache', 'basic_info_cache']:
            if hasattr(self, attr_name):
                attr_data = getattr(self, attr_name)
                if isinstance(attr_data, dict) and attr_data:
                    print(f"[INFO] æ¸…ç†{attr_name}...")
                    cleaned = self.clean_delisted_stocks_from_data(attr_data)
                    setattr(self, attr_name, cleaned)
        
        print(f"[SUCCESS] è‡ªåŠ¨æ¸…ç†å®Œæˆ")

    def _safe_float(self, value) -> Optional[float]:
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        if value in (None, "", "--", "-", "NaN"):
            return None
        try:
            if isinstance(value, str):
                value = value.replace(',', '').replace('%', '').strip()
            return float(value)
        except:
            return None
    
    def collect_technical_indicators(self, kline_df: pd.DataFrame) -> Dict[str, Any]:
        """æ ¹æ®Kçº¿æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        try:
            if kline_df is None or kline_df.empty:
                return {'status': 'no_data'}
            
            # ç¡®ä¿æŒ‰æ—¥æœŸæ’åº
            if 'date' in kline_df.columns:
                df = kline_df.sort_values('date')
            else:
                df = kline_df
            
            # è·å–æ”¶ç›˜ä»·åºåˆ—
            # å…¼å®¹ä¸åŒçš„åˆ—å
            close_col = next((col for col in ['close', 'æ”¶ç›˜', 'Close'] if col in df.columns), None)
            volume_col = next((col for col in ['volume', 'æˆäº¤é‡', 'Volume'] if col in df.columns), None)
            
            if not close_col:
                return {'status': 'missing_close_price'}
                
            closes = df[close_col]
            current_price = float(closes.iloc[-1])
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            ma5 = float(closes.rolling(window=5).mean().iloc[-1]) if len(closes) >= 5 else current_price
            ma10 = float(closes.rolling(window=10).mean().iloc[-1]) if len(closes) >= 10 else current_price
            ma20 = float(closes.rolling(window=20).mean().iloc[-1]) if len(closes) >= 20 else current_price
            ma60 = float(closes.rolling(window=60).mean().iloc[-1]) if len(closes) >= 60 else current_price
            
            # è®¡ç®—RSI
            delta = closes.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            rsi_val = float(rsi.iloc[-1]) if not pd.isna(rsi.iloc[-1]) else 50.0
            
            # è®¡ç®—MACD
            exp12 = closes.ewm(span=12, adjust=False).mean()
            exp26 = closes.ewm(span=26, adjust=False).mean()
            macd_line = exp12 - exp26
            signal_line = macd_line.ewm(span=9, adjust=False).mean()
            macd_val = float(macd_line.iloc[-1])
            signal_val = float(signal_line.iloc[-1])
            
            # è®¡ç®—é‡æ¯”
            volume_ratio = 1.0
            if volume_col and len(df) >= 6:
                volumes = df[volume_col]
                current_vol = float(volumes.iloc[-1])
                avg_vol = float(volumes.iloc[-6:-1].mean())
                if avg_vol > 0:
                    volume_ratio = current_vol / avg_vol
            
            return {
                'current_price': current_price,
                'ma5': ma5,
                'ma10': ma10,
                'ma20': ma20,
                'ma60': ma60,
                'rsi': rsi_val,
                'macd': macd_val,
                'signal': signal_val,
                'volume_ratio': volume_ratio,
                'status': 'calculated'
            }
            
        except Exception as e:
            print(f"[ERROR] è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return {'status': 'calculation_error', 'error': str(e)}

    def collect_comprehensive_data(self, codes: List[str], batch_size: int = 15, exclude_st: bool = True) -> Dict[str, Any]:
        """é‡‡é›†ç»¼åˆæ•°æ® - ä¸“é—¨åŒ–æ•°æ®æºåˆ†é…ç­–ç•¥"""
        results = {}
        
        print(f"[INFO] å¼€å§‹é‡‡é›† {len(codes)} åªè‚¡ç¥¨çš„ç»¼åˆæ•°æ® (ä¸“é—¨åŒ–APIåˆ†é…ç­–ç•¥)")
        
        # é¢„æ£€è‚¡ç¥¨æœ‰æ•ˆæ€§ï¼ˆè¿‡æ»¤é€€å¸‚å’Œæ— æ•ˆè‚¡ç¥¨ï¼‰
        if STOCK_STATUS_CHECKER_AVAILABLE and self.status_checker:
            print(f"[INFO] æ­¥éª¤0: è‚¡ç¥¨æœ‰æ•ˆæ€§é¢„æ£€...")
            try:
                validity_check = self.pre_check_stock_validity(codes)
                original_count = len(codes)
                
                # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦åŒ…å« ST è‚¡ç¥¨
                if exclude_st:
                    codes = validity_check['valid_codes']  # åªä½¿ç”¨æœ‰æ•ˆçš„è‚¡ç¥¨
                else:
                    codes = validity_check['valid_codes'] + validity_check.get('st', [])
                
                # è®°å½•è¢«è¿‡æ»¤çš„è‚¡ç¥¨
                filtered_count = original_count - len(codes)
                if filtered_count > 0:
                    print(f"[INFO] å·²è¿‡æ»¤ {filtered_count} åªé—®é¢˜è‚¡ç¥¨:")
                    if validity_check['delisted']:
                        print(f"  - é€€å¸‚è‚¡ç¥¨: {len(validity_check['delisted'])} åª")
                    if validity_check['invalid']:
                        print(f"  - æ— æ•ˆä»£ç : {len(validity_check['invalid'])} åª")
                    if validity_check['suspended']:
                        print(f"  - åœç‰Œè‚¡ç¥¨: {len(validity_check['suspended'])} åª")
                    if validity_check.get('st'):
                        print(f"  - ST è‚¡ç¥¨: {len(validity_check['st'])} åª")
                        
                print(f"[INFO] é¢„æ£€åæœ‰æ•ˆè‚¡ç¥¨: {len(codes)} åª")
            except Exception as e:
                print(f"[WARN] è‚¡ç¥¨é¢„æ£€å¼‚å¸¸: {e}ï¼Œå°†ç»§ç»­ä½¿ç”¨åŸå§‹åˆ—è¡¨")
        else:
            print(f"[INFO] è‚¡ç¥¨çŠ¶æ€æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„æ£€")
        
        print(f"[INFO] æ•°æ®æºç­–ç•¥: BaostockåŸºæœ¬é¢ | Tencentå®æ—¶èµ„é‡‘ | YFinanceä¼°å€¼ | AKShareå…œåº•")
        
        # 1. æ‰¹é‡é‡‡é›†Kçº¿æ•°æ® (ä¿æŒåŸæœ‰è½®æ¢ç­–ç•¥: tushare â†” akshare â†’ JoinQuant â†’ Alpha Vantage)
        print(f"[INFO] æ­¥éª¤1: æ‰¹é‡é‡‡é›†Kçº¿æ•°æ® (è½®æ¢ç­–ç•¥)...")
        try:
            batch_kline_data = self.collect_batch_kline_data(codes, 'auto')
            print(f"[INFO] Kçº¿æ•°æ®é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_kline_data)} åªè‚¡ç¥¨ (å¤šæºè½®æ¢)")
        except Exception as e:
            print(f"[ERROR] æ‰¹é‡é‡‡é›†Kçº¿æ•°æ®å¤±è´¥: {e}")
            batch_kline_data = {}
        
        # 2. æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯ - ä¸“é—¨åŒ–åˆ†é…ï¼šBaostock â†’ Tencent â†’ AKShare
        print(f"[INFO] æ­¥éª¤2: æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯ (Baostockä¸“ä¸š â†’ Tencentå®æ—¶ â†’ AKShareå…œåº•)...")
        try:
            batch_basic_info = self.collect_batch_basic_info(codes, 'baostock')
            print(f"[INFO] åŸºç¡€ä¿¡æ¯é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_basic_info)} åªè‚¡ç¥¨ (ä¸“ä¸šæ•°æ®æº)")
        except Exception as e:
            print(f"[ERROR] æ‰¹é‡é‡‡é›†åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
            batch_basic_info = {}
        
        # 3. æ‰¹é‡é‡‡é›†è´¢åŠ¡æ•°æ® - ä¸“é—¨åŒ–åˆ†é…ï¼šBaostock â†’ YFinance â†’ Tencent â†’ AKShare
        print(f"[INFO] æ­¥éª¤3: æ‰¹é‡é‡‡é›†è´¢åŠ¡æ•°æ® (BaostockåŸºæœ¬é¢ â†’ YFinanceä¼°å€¼ â†’ Tencent â†’ AKShare)...")
        try:
            batch_financial_data = self.collect_batch_financial_data(codes, 'baostock')
            print(f"[INFO] è´¢åŠ¡æ•°æ®é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_financial_data)} åªè‚¡ç¥¨ (å¤šå±‚ä¸“ä¸šæº)")
        except Exception as e:
            print(f"[ERROR] æ‰¹é‡é‡‡é›†è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            batch_financial_data = {}
        
        # 4. æ‰¹é‡é‡‡é›†è¡Œä¸šæ¦‚å¿µæ•°æ® - ä¸“é—¨åŒ–åˆ†é…ï¼šBaostockæ˜ å°„ â†’ AKShareçƒ­ç‚¹æ¦‚å¿µ
        print(f"[INFO] æ­¥éª¤4: æ‰¹é‡é‡‡é›†è¡Œä¸šæ¦‚å¿µ (Baostockæ ‡å‡†åˆ†ç±» â†’ AKShareæ¦‚å¿µçƒ­ç‚¹)...")
        try:
            batch_industry_data = self.collect_batch_industry_concept(codes, 'baostock')
            print(f"[INFO] è¡Œä¸šæ¦‚å¿µé‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_industry_data)} åªè‚¡ç¥¨ (æ ‡å‡†+çƒ­ç‚¹)")
        except Exception as e:
            print(f"[ERROR] æ‰¹é‡é‡‡é›†è¡Œä¸šæ¦‚å¿µå¤±è´¥: {e}")
            batch_industry_data = {}
        
        # 5. æ‰¹é‡é‡‡é›†èµ„é‡‘æµå‘æ•°æ® - ä¸“é—¨åŒ–åˆ†é…ï¼šTencent â†’ AKShare
        print(f"[INFO] æ­¥éª¤5: æ‰¹é‡é‡‡é›†èµ„é‡‘æµå‘ (Tencentå®æ—¶æµå‘ â†’ AKShareä¸ªè‚¡èµ„é‡‘)...")
        try:
            batch_fund_flow_data = self.collect_batch_fund_flow(codes, 'tencent')
            print(f"[INFO] èµ„é‡‘æµå‘é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_fund_flow_data)} åªè‚¡ç¥¨ (å®æ—¶ä¸“ä¸š)")
        except Exception as e:
            print(f"[ERROR] æ‰¹é‡é‡‡é›†èµ„é‡‘æµå‘å¤±è´¥: {e}")
            batch_fund_flow_data = {}
        
        # 6. æ•´åˆæ•°æ®å¹¶è¡¥å……å…¶ä»–ä¿¡æ¯
        print(f"[INFO] æ­¥éª¤6: æ•´åˆä¸“é—¨åŒ–æ•°æ®å¹¶è¡¥å……å®æ—¶ä¿¡æ¯...")
        for i, code in enumerate(codes[:batch_size]):
            print(f"\n[{i+1}/{min(batch_size, len(codes))}] æ­£åœ¨æ•´åˆ {code} çš„ä¸“é—¨åŒ–æ•°æ®...")
            
            stock_data = {
                'code': code,
                'timestamp': datetime.now().isoformat(),
                'collection_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_source': 'specialized_distribution_v2',
                'api_strategy': {
                    'kline': 'tushare_akshare_rotation',
                    'basic_info': 'baostock_tencent_akshare',
                    'financial': 'baostock_yfinance_tencent_akshare', 
                    'industry': 'baostock_akshare_mapping',
                    'fund_flow': 'tencent_akshare_realtime',
                    'news': 'akshare_realtime'
                },
                'basic_info': batch_basic_info.get(code, {'code': code, 'name': f'è‚¡ç¥¨{code}', 'source': 'fallback'}),
                'kline_data': None,
                'financial_data': batch_financial_data.get(code, {'code': code, 'source': 'fallback'}),
                'technical_indicators': {},
                'industry_concept': batch_industry_data.get(code, {'industry': 'å…¶ä»–åˆ¶é€ ä¸š', 'source': 'fallback'}),
                'fund_flow': batch_fund_flow_data.get(code, {'source': 'fallback'}),
                'news_announcements': {}
            }
            
            # å¤„ç†Kçº¿æ•°æ® - ä»æ‰¹é‡é‡‡é›†ç»“æœè·å– (å¤šæºè½®æ¢ç­–ç•¥)
            if code in batch_kline_data:
                kline_df = batch_kline_data[code]
                if kline_df is not None and not kline_df.empty:
                    # å®‰å…¨è·å–æœ€æ–°ä»·æ ¼
                    latest_price = None
                    for col in ['close', 'æ”¶ç›˜', 'Close']:
                        if col in kline_df.columns:
                            try:
                                latest_price = float(kline_df[col].iloc[-1])
                                break
                            except (IndexError, ValueError, TypeError):
                                continue
                    
                    stock_data['kline_data'] = {
                        'daily': kline_df.to_dict('records'),
                        'latest_price': latest_price,
                        'data_points': len(kline_df),
                        'source': 'batch_rotation'
                    }
                    print(f"    âœ“ Kçº¿æ•°æ®: {len(kline_df)}å¤© (è½®æ¢ç­–ç•¥)")
                else:
                    kline_df = None
            else:
                print(f"    âš ï¸ æœªåœ¨æ‰¹é‡Kçº¿æ•°æ®ä¸­ï¼Œå°è¯•AKShareå…œåº•")
                kline_df = self.collect_kline_data(code, 'akshare')
                if kline_df is not None and not kline_df.empty:
                    # å®‰å…¨è·å–æœ€æ–°ä»·æ ¼
                    latest_price = None
                    for col in ['close', 'æ”¶ç›˜', 'Close']:
                        if col in kline_df.columns:
                            try:
                                latest_price = float(kline_df[col].iloc[-1])
                                break
                            except (IndexError, ValueError, TypeError):
                                continue
                    
                    stock_data['kline_data'] = {
                        'daily': kline_df.to_dict('records'),
                        'latest_price': latest_price,
                        'data_points': len(kline_df),
                        'source': 'akshare_fallback'
                    }
            
            # æŠ€æœ¯æŒ‡æ ‡è®¡ç®— - åŸºäºKçº¿æ•°æ®
            if kline_df is not None and not kline_df.empty:
                stock_data['technical_indicators'] = self.collect_technical_indicators(kline_df)
                print(f"    âœ“ æŠ€æœ¯æŒ‡æ ‡: åŸºäºKçº¿æ•°æ®è®¡ç®—å®Œæˆ")
            else:
                stock_data['technical_indicators'] = {'status': 'no_kline_data'}
                print(f"    âš ï¸ æŠ€æœ¯æŒ‡æ ‡: æ— Kçº¿æ•°æ®ï¼Œè·³è¿‡")
            
            # æ•°æ®æºè¿½è¸ª - è®°å½•å®é™…ä½¿ç”¨çš„æ•°æ®æº
            data_sources_used = {
                'basic_info': stock_data['basic_info'].get('source', 'unknown'),
                'financial_data': stock_data['financial_data'].get('source', 'unknown'),
                'industry_concept': stock_data['industry_concept'].get('source', 'unknown'),
                'fund_flow': stock_data['fund_flow'].get('source', 'unknown'),
                'kline_data': stock_data['kline_data'].get('source', 'unknown') if stock_data['kline_data'] else 'none'
            }
            
            # è¾“å‡ºæ‰¹é‡é‡‡é›†ç»“æœæ±‡æ€»
            print(f"    âœ“ åŸºç¡€ä¿¡æ¯: {data_sources_used['basic_info']}")
            print(f"    âœ“ è´¢åŠ¡æ•°æ®: {data_sources_used['financial_data']}")
            print(f"    âœ“ è¡Œä¸šæ¦‚å¿µ: {data_sources_used['industry_concept']}")
            print(f"    âœ“ èµ„é‡‘æµå‘: {data_sources_used['fund_flow']}")
            
            # æ–°é—»å…¬å‘Š - å®æ—¶æ”¶é›†ï¼ˆæ—¶æ•ˆæ€§é‡è¦ï¼Œä½¿ç”¨AKShareï¼‰
            try:
                stock_data['news_announcements'] = self.collect_news_announcements(code, 'akshare')
                print(f"    âœ“ æ–°é—»å…¬å‘Š: AKShareå®æ—¶æ”¶é›†")
            except Exception as e:
                stock_data['news_announcements'] = {'status': 'failed', 'error': str(e)}
                print(f"    âš ï¸ æ–°é—»å…¬å‘Š: æ”¶é›†å¤±è´¥ - {e}")
            
            # è®°å½•å®Œæ•´æ•°æ®æºä¿¡æ¯
            stock_data['data_sources_used'] = data_sources_used
            stock_data['collection_summary'] = {
                'strategy': 'specialized_api_distribution',
                'timestamp': datetime.now().isoformat(),
                'success_rate': len([v for v in data_sources_used.values() if v not in ('unknown', 'none', 'fallback')]) / len(data_sources_used)
            }
            
            results[code] = stock_data
            
            # çŸ­æš‚å»¶æ—¶é¿å…è¯·æ±‚è¿‡é¢‘
            time.sleep(0.3)
        
        # è¾“å‡ºæ‰¹é‡é‡‡é›†ç»Ÿè®¡
        total_stocks = len(results)
        successful_collections = {
            'kline': len([r for r in results.values() if r['kline_data'] is not None]),
            'basic_info': len([r for r in results.values() if r['basic_info'].get('source') != 'fallback']),
            'financial': len([r for r in results.values() if r['financial_data'].get('source') != 'fallback']),
            'industry': len([r for r in results.values() if r['industry_concept'].get('source') != 'fallback']),
            'fund_flow': len([r for r in results.values() if r['fund_flow'].get('source') != 'fallback'])
        }
        
        print(f"\n[INFO] ä¸“é—¨åŒ–æ•°æ®é‡‡é›†å®Œæˆç»Ÿè®¡:")
        print(f"  æ€»è‚¡ç¥¨æ•°: {total_stocks}")
        print(f"  Kçº¿æ•°æ®: {successful_collections['kline']}/{total_stocks} ({successful_collections['kline']/total_stocks*100:.1f}%)")
        print(f"  åŸºç¡€ä¿¡æ¯: {successful_collections['basic_info']}/{total_stocks} ({successful_collections['basic_info']/total_stocks*100:.1f}%)")
        print(f"  è´¢åŠ¡æ•°æ®: {successful_collections['financial']}/{total_stocks} ({successful_collections['financial']/total_stocks*100:.1f}%)")
        print(f"  è¡Œä¸šæ¦‚å¿µ: {successful_collections['industry']}/{total_stocks} ({successful_collections['industry']/total_stocks*100:.1f}%)")
        print(f"  èµ„é‡‘æµå‘: {successful_collections['fund_flow']}/{total_stocks} ({successful_collections['fund_flow']/total_stocks*100:.1f}%)")
        
        # ç¡®ä¿Baostockç™»å‡ºï¼Œé‡Šæ”¾èµ„æº
        if BAOSTOCK_AVAILABLE and self.bs_login:
            try:
                import baostock as bs
                bs.logout()
            except:
                pass
        
        return results
    
    def save_data(self, data: Dict[str, Any], filename: Optional[str] = None) -> None:
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶ - åˆ†å·å­˜å‚¨æ¨¡å¼ (æ¯å·æœ€å¤š200åªè‚¡ç¥¨)"""
        # å¿½ç•¥ä¼ å…¥çš„ filenameï¼Œä½¿ç”¨åˆ†å·é€»è¾‘
        base_filename = self.output_file # data/comprehensive_stock_data.json
        base_dir = os.path.dirname(base_filename)
        base_name = os.path.basename(base_filename).replace('.json', '')
        index_file = os.path.join(base_dir, 'stock_file_index.json')
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(base_dir, exist_ok=True)
        
        # åŠ è½½ç´¢å¼•
        stock_index = {}
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    stock_index = json.load(f)
            except:
                pass
        
        # æ¸…ç†å¾…ä¿å­˜æ•°æ®
        cleaned_data = DateTimeEncoder.clean_data_for_json(data)
        
        # æŒ‰ç›®æ ‡æ–‡ä»¶åˆ†ç»„å¾…ä¿å­˜çš„æ•°æ®
        files_to_update = {} # filename -> {code: data}
        
        # æŸ¥æ‰¾ç°æœ‰çš„åˆ†å·æ–‡ä»¶
        import glob
        part_files = glob.glob(os.path.join(base_dir, f"{base_name}_part_*.json"))
        part_files.sort(key=lambda x: int(x.split('_part_')[-1].replace('.json', '')))
        
        # ç¡®å®šå½“å‰æœ€æ–°çš„åˆ†å·æ–‡ä»¶
        current_file = None
        current_file_count = 0
        
        if part_files:
            current_file = part_files[-1]
            # ç®€å•è¯»å–ä¸€ä¸‹æ•°é‡ï¼Œæˆ–è€…æˆ‘ä»¬ä¿¡ä»»ç´¢å¼•ï¼Ÿ
            # ä¸ºäº†å‡†ç¡®ï¼Œè¯»å–ä¸€ä¸‹æœ€åè¿™ä¸ªæ–‡ä»¶
            try:
                with open(current_file, 'r', encoding='utf-8') as f:
                    content = json.load(f)
                    if 'stocks' in content:
                        current_file_count = len(content['stocks'])
            except:
                current_file_count = 0
        else:
            # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ–‡ä»¶
            current_file = os.path.join(base_dir, f"{base_name}_part_1.json")
            current_file_count = 0
            
        # åˆ†é…æ•°æ®åˆ°æ–‡ä»¶
        for code, stock_info in cleaned_data.items():
            # è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„Kçº¿æ•°æ®ï¼šä¿ç•™æ€»è®¡60å¤©çš„æ•°æ®ï¼Œåˆ é™¤è¶…è¿‡80å¤©ä»¥å¤–çš„æ•°æ®
            if isinstance(stock_info, dict) and 'kline_data' in stock_info:
                kline_obj = stock_info['kline_data']
                if isinstance(kline_obj, dict) and 'daily' in kline_obj:
                    daily_list = kline_obj['daily']
                    if isinstance(daily_list, list) and len(daily_list) > 80:
                        # æˆªæ–­åˆ°æœ€è¿‘çš„80å¤©ï¼ˆç¡¬ä¸Šé™ï¼‰
                        kline_obj['daily'] = daily_list[-80:]
                        kline_obj['data_points'] = len(kline_obj['daily'])
                        kline_obj['update_time'] = datetime.now().isoformat()
            
            target_file = None
            
            # 1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨äºæŸä¸ªæ–‡ä»¶ä¸­ (æ›´æ–°)
            if code in stock_index:
                # ç´¢å¼•ä¸­å­˜å‚¨çš„æ˜¯ç›¸å¯¹è·¯å¾„æˆ–æ–‡ä»¶åï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å®ƒæ˜¯å®Œæ•´çš„è·¯å¾„
                indexed_file = stock_index[code]
                # å¦‚æœç´¢å¼•åªå­˜äº†æ–‡ä»¶å
                if os.path.dirname(indexed_file) == '':
                    target_file = os.path.join(base_dir, indexed_file)
                else:
                    target_file = indexed_file
            else:
                # 2. æ–°å¢æ•°æ®
                # æ£€æŸ¥å½“å‰æ–‡ä»¶æ˜¯å¦å·²æ»¡
                if current_file_count >= 200:
                    # åˆ›å»ºæ–°åˆ†å·
                    next_part = 1
                    if part_files:
                        try:
                            last_part_num = int(part_files[-1].split('_part_')[-1].replace('.json', ''))
                            next_part = last_part_num + 1
                        except:
                            pass
                    elif current_file:
                         try:
                            last_part_num = int(current_file.split('_part_')[-1].replace('.json', ''))
                            next_part = last_part_num + 1
                         except:
                            pass

                    new_file = os.path.join(base_dir, f"{base_name}_part_{next_part}.json")
                    part_files.append(new_file) # æ›´æ–°åˆ—è¡¨
                    current_file = new_file
                    current_file_count = 0
                
                target_file = current_file
                current_file_count += 1
                # æ›´æ–°ç´¢å¼• (å­˜æ–‡ä»¶åå³å¯ï¼Œæ–¹ä¾¿ç§»æ¤)
                stock_index[code] = os.path.basename(target_file)
            
            if target_file not in files_to_update:
                files_to_update[target_file] = {}
            files_to_update[target_file][code] = stock_info
            
        # æ‰§è¡Œä¿å­˜
        for filepath, stocks_data in files_to_update.items():
            file_content = {'stocks': {}}
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        file_content = json.load(f)
                except:
                    pass
            
            if 'stocks' not in file_content:
                file_content['stocks'] = {}
                
            file_content['stocks'].update(stocks_data)
            file_content['last_updated'] = datetime.now().isoformat()
            file_content['total_stocks'] = len(file_content['stocks'])
            
            # åŸå­å†™å…¥
            temp_filename = filepath + '.tmp'
            try:
                with open(temp_filename, 'w', encoding='utf-8') as f:
                    json.dump(file_content, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)
                
                if os.path.exists(filepath):
                    os.replace(temp_filename, filepath)
                else:
                    os.rename(temp_filename, filepath)
                print(f"[SUCCESS] æ•°æ®å·²ä¿å­˜åˆ° {os.path.basename(filepath)}")
            except Exception as e:
                print(f"[ERROR] ä¿å­˜åˆ†å· {os.path.basename(filepath)} å¤±è´¥: {e}")
                if os.path.exists(temp_filename):
                    try: os.remove(temp_filename) 
                    except: pass

        # ä¿å­˜ç´¢å¼•
        try:
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(stock_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[WARN] ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
        
        # æ›´æ–°Kçº¿çŠ¶æ€æ–‡ä»¶ï¼ˆå› ä¸ºå…¨éƒ¨æ•°æ®åŒ…å«Kçº¿ï¼‰
        self._update_kline_status_file(base_dir, cleaned_data)
    
    def update_kline_data_only(self, batch_size: int = 20, total_batches: int = None, stock_type: str = "ä¸»æ¿", progress_callback=None, exclude_st: bool = True):
        """åªæ›´æ–°Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼ˆé«˜æ•ˆæ¨¡å¼ï¼‰"""
        
        # é¦–å…ˆåŠ è½½æœ¬åœ°å·²æœ‰æ•°æ®ï¼Œåªæ›´æ–°æœ¬åœ°å­˜åœ¨çš„è‚¡ç¥¨
        existing_data = self.load_existing_data()
        
        if not existing_data:
            msg = "é”™è¯¯ï¼šæœ¬åœ°æ²¡æœ‰æ•°æ®ï¼è¯·å…ˆä½¿ç”¨'è·å–å…¨éƒ¨æ•°æ®'åŠŸèƒ½é‡‡é›†æ•°æ®ã€‚"
            print(f"[ERROR] {msg}")
            if progress_callback:
                progress_callback("é”™è¯¯", 0, msg)
            return
        
        # ä»æœ¬åœ°æ•°æ®ä¸­ç­›é€‰ç¬¦åˆç±»å‹çš„è‚¡ç¥¨
        all_codes = []
        for code in existing_data.keys():
            # æ ¹æ®è‚¡ç¥¨ç±»å‹è¿‡æ»¤
            if stock_type == "å…¨éƒ¨":
                all_codes.append(code)
            elif stock_type == "ä¸»æ¿":
                if code.startswith(('600', '601', '603', '000', '001', '002')):
                    all_codes.append(code)
            elif stock_type == "ç§‘åˆ›æ¿":
                if code.startswith('688'):
                    all_codes.append(code)
            elif stock_type == "åˆ›ä¸šæ¿":
                if code.startswith('300'):
                    all_codes.append(code)
        
        # ğŸ”´ é¢„è¿‡æ»¤ï¼šæ’é™¤ ST å’Œ åœç‰Œè‚¡ç¥¨
        if self.status_checker:
            print(f"[INFO] æ­£åœ¨æ£€æŸ¥ {len(all_codes)} åªè‚¡ç¥¨çš„çŠ¶æ€ (ST/åœç‰Œ)...")
            if progress_callback:
                progress_callback("æ£€æŸ¥è‚¡ç¥¨çŠ¶æ€...", 1, "æ­£åœ¨è·å–å…¨å¸‚åœº ST å’Œåœç‰Œä¿¡æ¯...")
            
            if self.status_checker.update_status():
                # è¿‡æ»¤ä»£ç åˆ—è¡¨
                all_codes = self.status_checker.filter_codes(all_codes, exclude_st=exclude_st, exclude_suspended=True)
        
        actual_total = len(all_codes)
        
        # æ ¹æ®å®é™…è‚¡ç¥¨æ•°é‡åŠ¨æ€è®¡ç®—æ‰¹æ¬¡
        if total_batches is None:
            total_batches = (actual_total + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
        
        print(f"[INFO] å¼€å§‹Kçº¿æ•°æ®æ›´æ–° (æ¯æ‰¹ {batch_size} åªè‚¡ç¥¨ï¼Œå…± {total_batches} æ‰¹)")
        print(f"[INFO] è‚¡ç¥¨ç±»å‹: {stock_type}")
        print(f"[INFO] å®é™…è‚¡ç¥¨æ•°é‡: {actual_total} åª")
        print(f"[INFO] æ›´æ–°ç­–ç•¥: åªæ›´æ–°Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œä¿ç•™å…¶ä»–æ•°æ®ä¸å˜")
        
        if progress_callback:
            progress_callback("è·å–è‚¡ç¥¨åˆ—è¡¨...", 1, f"è·å¾— {actual_total} åª{stock_type}è‚¡ç¥¨ï¼Œå°†åˆ† {total_batches} æ‰¹å¤„ç†")
        
        if actual_total == 0:
            msg = f"é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°{stock_type}ç±»å‹çš„è‚¡ç¥¨ï¼"
            print(f"[ERROR] {msg}")
            if progress_callback:
                progress_callback("é”™è¯¯", 0, msg)
                return
        
        if progress_callback:
            progress_callback("å¼€å§‹Kçº¿æ›´æ–°...", 2, f"è·å¾— {actual_total} åªè‚¡ç¥¨ï¼Œå¼€å§‹Kçº¿æ•°æ®æ›´æ–°...")
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = start_idx + batch_size
            batch_codes = all_codes[start_idx:end_idx]
            
            if not batch_codes:
                break
            
            # è®¡ç®—è¿›åº¦
            progress_pct = ((batch_num + 1) / total_batches) * 100
            completed_count = min((batch_num + 1) * batch_size, actual_total)
            current_batch_info = f"ç¬¬ {batch_num + 1}/{total_batches} æ‰¹"
            stock_info = f"å¤„ç†è‚¡ç¥¨: {', '.join(batch_codes[:3])}{'...' if len(batch_codes) > 3 else ''}"
            progress_text = f"{completed_count}/{actual_total}"
            
            if progress_callback:
                progress_callback(f"Kçº¿æ›´æ–°ä¸­ ({progress_text})", progress_pct, f"{current_batch_info} - {stock_info}")
            
            print(f"\n{'='*50}")
            print(f"ç¬¬ {batch_num + 1} æ‰¹ / å…± {total_batches} æ‰¹ (Kçº¿æ›´æ–°)")
            print(f"è‚¡ç¥¨ä»£ç : {', '.join(batch_codes)}")
            print(f"{'='*50}")
            
            # æ‰¹é‡é‡‡é›†Kçº¿æ•°æ®ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰
            try:
                # ä¸ºæ¯åªè‚¡ç¥¨ç¡®å®šéœ€è¦è·å–çš„æ—¥æœŸèŒƒå›´ï¼Œå¹¶æ‰¾åˆ°æœ¬æ‰¹æ¬¡çš„æœ€æ—©å¼€å§‹æ—¥æœŸ
                codes_with_date_range = {}
                min_start_date = None
                
                for code in batch_codes:
                    try:
                        if code in existing_data and 'kline_data' in existing_data[code]:
                            # è·å–å†å²Kçº¿æ•°æ®çš„æœ€åæ—¥æœŸ
                            kline_data_obj = existing_data[code].get('kline_data')
                            if kline_data_obj is None:
                                codes_with_date_range[code] = None
                                continue
                            
                            daily_data = kline_data_obj.get('daily', []) if isinstance(kline_data_obj, dict) else []
                            if daily_data and isinstance(daily_data, list) and len(daily_data) > 0:
                                # æ‰¾åˆ°æœ€åä¸€å¤©çš„æ—¥æœŸ
                                last_item = daily_data[-1]
                                if last_item and isinstance(last_item, dict):
                                    last_date_str = last_item.get('date', last_item.get('trade_date', ''))
                                else:
                                    last_date_str = ''
                                
                                if last_date_str:
                                    try:
                                        # è§£ææ—¥æœŸ
                                        if len(last_date_str) == 8:  # YYYYMMDDæ ¼å¼
                                            last_date = datetime.strptime(last_date_str, '%Y%m%d')
                                        else:  # YYYY-MM-DDæ ¼å¼
                                            last_date = datetime.strptime(last_date_str, '%Y-%m-%d')
                                        
                                        # ä»ä¸‹ä¸€å¤©å¼€å§‹è·å–
                                        start_date = last_date + timedelta(days=1)
                                        
                                        # é™åˆ¶è·å–èŒƒå›´ï¼šåªè¦ç»Ÿè®¡ä»è·å–å½“å¤©å¼€å§‹å¾€å‰æ¨60å¤©çš„æ•°æ®å³å¯
                                        limit_date = datetime.now() - timedelta(days=self.kline_days)
                                        if start_date < limit_date:
                                            start_date = limit_date
                                            print(f"    {code}: å†å²æ•°æ®å¤ªæ—§({last_date_str})ï¼Œè°ƒæ•´ä»{start_date.strftime('%Y-%m-%d')}å¼€å§‹è¡¥å…¨")
                                        
                                        codes_with_date_range[code] = start_date
                                        
                                        # æ›´æ–°æœ¬æ‰¹æ¬¡çš„æœ€æ—©å¼€å§‹æ—¥æœŸ
                                        if min_start_date is None or start_date < min_start_date:
                                            min_start_date = start_date
                                            
                                        if start_date > last_date:
                                            print(f"    {code}: å†å²æ•°æ®åˆ°{last_date_str}ï¼Œå»ºè®®ä»{start_date.strftime('%Y-%m-%d')}è¡¥å…¨")
                                    except Exception as date_parse_err:
                                        print(f"    {code}: æ—¥æœŸè§£æå¤±è´¥ ({date_parse_err})ï¼Œå°†è·å–å…¨éƒ¨æ•°æ®")
                                        codes_with_date_range[code] = None
                                        min_start_date = datetime.now() - timedelta(days=self.kline_days)
                                else:
                                    codes_with_date_range[code] = None
                                    min_start_date = datetime.now() - timedelta(days=self.kline_days)
                            else:
                                codes_with_date_range[code] = None
                                min_start_date = datetime.now() - timedelta(days=self.kline_days)
                        else:
                            codes_with_date_range[code] = None
                            min_start_date = datetime.now() - timedelta(days=self.kline_days)
                    except Exception as code_err:
                        print(f"    [WARNING] {code}: å¤„ç†å¤±è´¥ ({code_err})ï¼Œè·³è¿‡")
                        codes_with_date_range[code] = None
                
                # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„å¼€å§‹æ—¥æœŸ
                final_start_str = None
                if min_start_date:
                    # ğŸ”´ ä¿®å¤ï¼šç¡®ä¿ min_start_date ä¹Ÿè°ƒæ•´åˆ°äº¤æ˜“æ—¥
                    weekday = min_start_date.weekday()
                    if weekday == 5:  # å‘¨å…­
                        min_start_date = min_start_date - timedelta(days=1)
                    elif weekday == 6:  # å‘¨æ—¥
                        min_start_date = min_start_date - timedelta(days=2)
                    
                    # å¦‚æœæœ€æ—©å¼€å§‹æ—¥æœŸæ™šäºä»Šå¤©ï¼Œè¯´æ˜æ•°æ®å·²æ˜¯æœ€æ–°
                    now = datetime.now()
                    # åŒæ ·è°ƒæ•´ now åˆ°äº¤æ˜“æ—¥
                    now_weekday = now.weekday()
                    if now_weekday == 5:
                        now = now - timedelta(days=1)
                    elif now_weekday == 6:
                        now = now - timedelta(days=2)
                    
                    if min_start_date > now:
                        print(f"[INFO] æœ¬æ‰¹æ¬¡è‚¡ç¥¨æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œä»…è¿›è¡Œå¸¸è§„æ£€æŸ¥")
                        final_start_str = (now - timedelta(days=3)).strftime('%Y%m%d')
                    else:
                        final_start_str = min_start_date.strftime('%Y%m%d')
                        print(f"[INFO] æœ¬æ‰¹æ¬¡å°†ä» {min_start_date.strftime('%Y-%m-%d')} å¼€å§‹å¢é‡è·å–")
                
                # æ‰¹é‡é‡‡é›†æ–°æ•°æ®
                batch_kline_data = self.collect_batch_kline_data(batch_codes, 'auto', start_date_override=final_start_str)
                print(f"[INFO] æœ¬æ‰¹Kçº¿æ•°æ®é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_kline_data)} åªè‚¡ç¥¨")
                
                # ğŸ”´ æ™ºèƒ½é‡‡é›†æ¿å—ä¿¡æ¯ï¼šåªæ›´æ–°ç¼ºå¤±æˆ–éœ€è¦æ›´æ–°çš„è‚¡ç¥¨
                print(f"[INFO] æ£€æŸ¥æ¿å—ä¿¡æ¯æ›´æ–°éœ€æ±‚...")
                codes_need_industry = []
                for code in batch_codes:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ¿å—ä¿¡æ¯
                    needs_update = False
                    if code not in existing_data:
                        needs_update = True  # æ–°è‚¡ç¥¨
                    elif 'industry_concept' not in existing_data[code]:
                        needs_update = True  # ç¼ºå¤±æ¿å—ä¿¡æ¯
                    elif not existing_data[code]['industry_concept'].get('industry'):
                        needs_update = True  # è¡Œä¸šä¿¡æ¯ä¸ºç©º
                    elif existing_data[code]['industry_concept'].get('source') in ['default', 'baostock_default']:
                        needs_update = True  # ä½¿ç”¨çš„æ˜¯é»˜è®¤å€¼ï¼Œå°è¯•è·å–çœŸå®æ•°æ®
                    
                    if needs_update:
                        codes_need_industry.append(code)
                
                batch_industry_data = {}
                if codes_need_industry:
                    print(f"[INFO] éœ€è¦æ›´æ–°æ¿å—ä¿¡æ¯çš„è‚¡ç¥¨: {len(codes_need_industry)}/{len(batch_codes)} åª")
                    try:
                        batch_industry_data = self.collect_batch_industry_concept(codes_need_industry, 'auto')
                        print(f"[INFO] æ¿å—ä¿¡æ¯é‡‡é›†å®Œæˆï¼Œè·å¾— {len(batch_industry_data)} åªè‚¡ç¥¨")
                    except Exception as industry_err:
                        print(f"[WARN] æ¿å—ä¿¡æ¯é‡‡é›†å¤±è´¥: {industry_err}ï¼Œå°†ä½¿ç”¨ç°æœ‰æ•°æ®æˆ–é»˜è®¤å€¼")
                else:
                    print(f"[INFO] æ‰€æœ‰è‚¡ç¥¨æ¿å—ä¿¡æ¯å‡å·²å­˜åœ¨ï¼Œè·³è¿‡é‡‡é›†")
                
                # æ›´æ–°æ¯åªè‚¡ç¥¨çš„Kçº¿æ•°æ®ï¼ˆåˆå¹¶å†å²æ•°æ®ï¼‰
                for code in batch_codes:
                    if code in batch_kline_data:
                        new_kline_df = batch_kline_data[code]
                        if new_kline_df is not None and not new_kline_df.empty:
                            # åˆå¹¶å†å²æ•°æ®
                            if code in existing_data and 'kline_data' in existing_data[code] and existing_data[code]['kline_data'] is not None:
                                old_daily = existing_data[code]['kline_data'].get('daily', [])
                                if old_daily:
                                    # å°†å†å²æ•°æ®è½¬æ¢ä¸ºDataFrame
                                    old_df = pd.DataFrame(old_daily)
                                    
                                    # ğŸ”´ æ”¹è¿›ï¼šç»Ÿä¸€æ–°æ—§æ•°æ®çš„åˆ—åï¼Œç¡®ä¿åˆå¹¶æ­£ç¡®
                                    # æ˜ç¡®æŒ‡å®š source ä¸º 'auto' æˆ–æ ¹æ®æ•°æ®ç‰¹å¾è¯†åˆ«
                                    old_df = self.standardize_kline_columns(old_df, 'auto')
                                    new_kline_df = self.standardize_kline_columns(new_kline_df, 'auto')
                                    
                                    date_col = 'date'
                                    
                                    if date_col in old_df.columns:
                                        # è®°å½•åˆå¹¶å‰çš„æ—¥æœŸ
                                        old_dates = set(old_df[date_col].astype(str).tolist())
                                        
                                        # åˆå¹¶æ–°æ—§æ•°æ®ï¼Œå»é‡å¹¶æ’åº
                                        combined_df = pd.concat([old_df, new_kline_df], ignore_index=True)
                                        
                                        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸º YYYY-MM-DDï¼Œé¿å…æ··åˆæ ¼å¼å¯¼è‡´æ’åºé”™è¯¯
                                        def normalize_date_func(d):
                                            d_str = str(d).split(' ')[0].replace('-', '').replace('/', '')
                                            if len(d_str) >= 8:
                                                return f"{d_str[:4]}-{d_str[4:6]}-{d_str[6:8]}"
                                            return str(d)
                                            
                                        combined_df[date_col] = combined_df[date_col].apply(normalize_date_func)
                                        combined_df = combined_df.drop_duplicates(subset=[date_col], keep='last')
                                        combined_df = combined_df.sort_values(by=date_col)
                                        
                                        # é™åˆ¶æ•°æ®é‡ï¼šä¿ç•™æ€»è®¡60å¤©çš„æ•°æ®ï¼Œåˆ é™¤è¶…è¿‡80å¤©ä»¥å¤–çš„æ•°æ®
                                        if len(combined_df) > 80:
                                            combined_df = combined_df.tail(80)
                                            print(f"    ! {code}: æ•°æ®è¶…è¿‡80å¤©ï¼Œå·²æˆªæ–­ä¿ç•™æœ€è¿‘80å¤©")
                                        elif len(combined_df) > 60:
                                            # å¦‚æœè¶…è¿‡60å¤©ä½†æ²¡åˆ°80å¤©ï¼Œä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦æˆªæ–­åˆ°60å¤©
                                            # è¿™é‡Œæˆ‘ä»¬ä¿ç•™åˆ°80å¤©ä½œä¸ºç¼“å†²ï¼Œä½†ç¡®ä¿ä¸æ— é™å¢é•¿
                                            pass
                                            
                                        kline_df = combined_df
                                        
                                        # è®¡ç®—çœŸæ­£æ–°å¢çš„å¤©æ•°
                                        new_dates = set(kline_df[date_col].astype(str).tolist())
                                        truly_added = len(new_dates - old_dates)
                                        
                                        total_count = len(kline_df)
                                        print(f"    âœ“ {code}: æ¥å£è¿”å›{len(new_kline_df)}å¤©ï¼Œå®é™…æ–°å¢{truly_added}å¤©ï¼Œæ€»è®¡{total_count}å¤©Kçº¿")
                                    else:
                                        # æ— æ³•åˆå¹¶ï¼Œä½¿ç”¨æ–°æ•°æ®
                                        kline_df = new_kline_df
                                        print(f"    âœ“ {code}: æ›´æ–°Kçº¿ {len(kline_df)}å¤©ï¼ˆæ— æ³•åˆå¹¶ï¼‰")
                                else:
                                    kline_df = new_kline_df
                                    print(f"    âœ“ {code}: æ›´æ–°Kçº¿ {len(kline_df)}å¤©")
                            else:
                                kline_df = new_kline_df
                                print(f"    + {code}: æ–°å¢Kçº¿ {len(kline_df)}å¤©")
                            
                            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                            tech_indicators = self.collect_technical_indicators(kline_df)
                            
                            # è·å–æœ€æ–°ä»·æ ¼
                            latest_price = None
                            for col in ['close', 'æ”¶ç›˜', 'Close']:
                                if col in kline_df.columns:
                                    try:
                                        latest_price = float(kline_df[col].iloc[-1])
                                        break
                                    except:
                                        continue
                            
                            # ä¿å­˜åˆå¹¶åçš„æ•°æ®
                            if code in existing_data:
                                # ä¿ç•™åŸæœ‰æ•°æ®ï¼Œåªæ›´æ–°Kçº¿å’ŒæŠ€æœ¯æŒ‡æ ‡
                                existing_data[code]['kline_data'] = {
                                    'daily': kline_df.to_dict('records'),
                                    'latest_price': latest_price,
                                    'data_points': len(kline_df),
                                    'source': 'incremental_update',
                                    'update_time': datetime.now().isoformat()
                                }
                                existing_data[code]['technical_indicators'] = tech_indicators
                                existing_data[code]['last_kline_update'] = datetime.now().isoformat()
                                
                                # ğŸ”´ æ›´æ–°æ¿å—ä¿¡æ¯ï¼ˆå¦‚æœæœ‰æ–°é‡‡é›†çš„æ•°æ®ï¼‰
                                if code in batch_industry_data:
                                    existing_data[code]['industry_concept'] = batch_industry_data[code]
                                    print(f"    + {code}: æ›´æ–°æ¿å—ä¿¡æ¯ - {batch_industry_data[code].get('industry', 'æœªçŸ¥')}")
                                
                                # åŒæ­¥æ›´æ–°é¡¶å±‚æ—¶é—´æˆ³ï¼Œç¡®ä¿ GUI åˆå¹¶é€»è¾‘èƒ½è¯†åˆ«è¿™æ˜¯æœ€æ–°æ•°æ®
                                existing_data[code]['timestamp'] = datetime.now().isoformat()
                            else:
                                # å¦‚æœæ˜¯æ–°è‚¡ç¥¨ï¼Œåˆ›å»ºåŸºæœ¬ç»“æ„
                                existing_data[code] = {
                                    'code': code,
                                    'name': f'è‚¡ç¥¨{code}',
                                    'kline_data': {
                                        'daily': kline_df.to_dict('records'),
                                        'latest_price': latest_price,
                                        'data_points': len(kline_df),
                                        'source': 'new',
                                        'update_time': datetime.now().isoformat()
                                    },
                                    'technical_indicators': tech_indicators,
                                    'last_kline_update': datetime.now().isoformat(),
                                    'timestamp': datetime.now().isoformat()
                                }
                                
                                # ğŸ”´ æ·»åŠ æ¿å—ä¿¡æ¯ï¼ˆå¦‚æœæœ‰æ–°é‡‡é›†çš„æ•°æ®ï¼‰
                                if code in batch_industry_data:
                                    existing_data[code]['industry_concept'] = batch_industry_data[code]
                
                # æ‰¹æ¬¡ä¿å­˜
                self.save_data(existing_data)
                
                if progress_callback:
                    detail_info = f"{current_batch_info} å®Œæˆ - å·²ä¿å­˜ {len(batch_kline_data)} åªKçº¿æ•°æ®"
                    progress_callback(f"Kçº¿æ›´æ–°ä¸­ ({progress_text})", progress_pct, detail_info)
                
            except Exception as e:
                import traceback
                error_msg = f"{current_batch_info} å¤±è´¥: {str(e)}"
                print(f"[ERROR] {error_msg}")
                print(f"[ERROR] è¯¦ç»†é”™è¯¯è¿½è¸ª:")
                traceback.print_exc()
                if progress_callback:
                    progress_callback("Kçº¿æ›´æ–°å‡ºé”™", progress_pct, error_msg)
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if batch_num < total_batches - 1:
                if progress_callback:
                    progress_callback("æ‰¹æ¬¡é—´ä¼‘æ¯...", progress_pct, f"{current_batch_info} å®Œæˆï¼Œä¼‘æ¯3ç§’åç»§ç»­...")
                print(f"\n[INFO] æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯ 3 ç§’åç»§ç»­...")
                time.sleep(3)
        
        if progress_callback:
            progress_callback("Kçº¿æ›´æ–°å®Œæˆ", 100, f"æ‰€æœ‰ {total_batches} æ‰¹æ¬¡Kçº¿æ•°æ®æ›´æ–°å®Œæˆï¼")
        
        print(f"\n[SUCCESS] æ‰€æœ‰æ‰¹æ¬¡Kçº¿æ•°æ®æ›´æ–°å®Œæˆï¼")
    
    def load_existing_data(self):
        """åŠ è½½ç°æœ‰æ•°æ® - æ”¯æŒåˆ†å·åŠ è½½"""
        import glob
        import json
        import os

        # ç¡®å®šæ•°æ®ç›®å½•
        data_dir = os.path.dirname(os.path.abspath(self.output_file))
        base_name = os.path.basename(self.output_file).replace('.json', '')
        all_data = {}
        
        print(f"[INFO] æ­£åœ¨ä»ç›®å½•åŠ è½½æ•°æ®: {data_dir}")
        
        if os.path.exists(data_dir):
            # ä½¿ç”¨ glob æŸ¥æ‰¾æ‰€æœ‰åˆ†å·æ–‡ä»¶
            part_pattern = os.path.join(data_dir, f"{base_name}_part_*.json")
            part_files = glob.glob(part_pattern)
            
            if part_files:
                # æŒ‰åˆ†å·ç¼–å·æ’åº
                try:
                    part_files.sort(key=lambda x: int(x.split('_part_')[-1].replace('.json', '')))
                except:
                    part_files.sort()
                
                for part_file in part_files:
                    try:
                        with open(part_file, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                            if 'stocks' in content:
                                all_data.update(content['stocks'])
                                print(f"[INFO] åŠ è½½åˆ†å· {os.path.basename(part_file)}: {len(content['stocks'])} åªè‚¡ç¥¨")
                    except Exception as e:
                        print(f"[WARN] åŠ è½½ {part_file} å¤±è´¥: {e}")
            else:
                # å°è¯•åŠ è½½å•æ–‡ä»¶
                if os.path.exists(self.output_file):
                    try:
                        with open(self.output_file, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                            if 'stocks' in content:
                                all_data = content['stocks']
                            else:
                                all_data = content
                        print(f"[INFO] åŠ è½½å•æ–‡ä»¶æ•°æ®: {len(all_data)} åªè‚¡ç¥¨")
                    except Exception as e:
                        print(f"[WARN] åŠ è½½ {self.output_file} å¤±è´¥: {e}")
        
        print(f"[INFO] åŠ è½½ç°æœ‰æ•°æ®å®Œæˆ: å…± {len(all_data)} åªè‚¡ç¥¨")
        return all_data
    
    def run_batch_collection_with_progress(self, batch_size: int = 15, total_batches: int = None, stock_type: str = "ä¸»æ¿", progress_callback=None, exclude_st: bool = True):
        """è¿è¡Œä¸“é—¨åŒ–æ•°æ®æºåˆ†é…æ‰¹é‡é‡‡é›†ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        
        # é¦–å…ˆè·å–è‚¡ç¥¨åˆ—è¡¨æ¥ç¡®å®šå®é™…æ•°é‡
        if stock_type == "å…¨éƒ¨":
            # å…¨éƒ¨è‚¡ç¥¨ï¼šå…ˆè·å–å…¨é‡è‚¡ç¥¨åˆ—è¡¨
            all_codes = self.get_stock_list_by_type(stock_type, limit=6000)  # è·å–æ›´å¤šè‚¡ç¥¨
        else:
            # å…¶ä»–ç±»å‹ï¼šæ ¹æ®é¢„ä¼°æ•°é‡è·å–
            estimated_limit = (total_batches * batch_size) if total_batches else 5000
            all_codes = self.get_stock_list_by_type(stock_type, limit=estimated_limit)
        
        # ğŸ”´ é¢„è¿‡æ»¤ï¼šæ’é™¤ ST å’Œ åœç‰Œè‚¡ç¥¨
        if self.status_checker:
            print(f"[INFO] æ­£åœ¨æ£€æŸ¥ {len(all_codes)} åªè‚¡ç¥¨çš„çŠ¶æ€ (ST/åœç‰Œ)...")
            if progress_callback:
                progress_callback("æ£€æŸ¥è‚¡ç¥¨çŠ¶æ€...", 1, "æ­£åœ¨è·å–å…¨å¸‚åœº ST å’Œåœç‰Œä¿¡æ¯...")
            
            if self.status_checker.update_status():
                # è¿‡æ»¤ä»£ç åˆ—è¡¨
                all_codes = self.status_checker.filter_codes(all_codes, exclude_st=exclude_st, exclude_suspended=True)
        
        actual_total = len(all_codes)
        
        # æ ¹æ®å®é™…è‚¡ç¥¨æ•°é‡åŠ¨æ€è®¡ç®—æ‰¹æ¬¡
        if total_batches is None:
            total_batches = (actual_total + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
        
        print(f"[INFO] å¼€å§‹ä¸“é—¨åŒ–æ•°æ®æºåˆ†é…æ‰¹é‡é‡‡é›† (æ¯æ‰¹ {batch_size} åªè‚¡ç¥¨ï¼Œå…± {total_batches} æ‰¹)")
        print(f"[INFO] è‚¡ç¥¨ç±»å‹: {stock_type}")
        print(f"[INFO] å®é™…è‚¡ç¥¨æ•°é‡: {actual_total} åª")
        print(f"[INFO] æ•°æ®æºç­–ç•¥: BaostockåŸºæœ¬é¢ | Tencentå®æ—¶èµ„é‡‘ | YFinanceä¼°å€¼ | AKShareå…œåº•")
        
        if progress_callback:
            progress_callback("è·å–è‚¡ç¥¨åˆ—è¡¨...", 1, f"è·å¾— {actual_total} åª{stock_type}è‚¡ç¥¨ï¼Œå°†åˆ† {total_batches} æ‰¹å¤„ç†")
        
        if actual_total == 0:
            msg = f"é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°{stock_type}ç±»å‹çš„è‚¡ç¥¨ï¼"
            print(f"[ERROR] {msg}")
            if progress_callback:
                progress_callback("é”™è¯¯", 0, msg)
                return
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = start_idx + batch_size
            batch_codes = all_codes[start_idx:end_idx]
            
            if not batch_codes:
                break
            
            # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”å’Œå·²å®Œæˆæ•°é‡
            progress_pct = ((batch_num + 1) / total_batches) * 100
            completed_count = min((batch_num + 1) * batch_size, actual_total)
            current_batch_info = f"ç¬¬ {batch_num + 1}/{total_batches} æ‰¹"
            stock_info = f"å¤„ç†è‚¡ç¥¨: {', '.join(batch_codes[:3])}{'...' if len(batch_codes) > 3 else ''}"
            progress_text = f"{completed_count}/{actual_total}"
            
            if progress_callback:
                progress_callback(f"é‡‡é›†ä¸­ ({progress_text})", progress_pct, f"{current_batch_info} - {stock_info}")
            
            print(f"\n{'='*50}")
            print(f"ç¬¬ {batch_num + 1} æ‰¹ / å…± {total_batches} æ‰¹ (ä¸“é—¨åŒ–APIåˆ†é…)")
            print(f"è‚¡ç¥¨ä»£ç : {', '.join(batch_codes)}")
            print(f"{'='*50}")
            
            # é‡‡é›†æ•°æ®
            try:
                batch_data = self.collect_comprehensive_data(batch_codes, batch_size, exclude_st=exclude_st)
                
                # ä¿å­˜æ•°æ®
                self.save_data(batch_data)
                
                if progress_callback:
                    detail_info = f"{current_batch_info} å®Œæˆ - å·²ä¿å­˜ {len(batch_data)} åªè‚¡ç¥¨ä¸“é—¨åŒ–æ•°æ®"
                    progress_callback("ä¸“é—¨åŒ–é‡‡é›†ä¸­...", progress_pct, detail_info)
                
            except Exception as e:
                error_msg = f"{current_batch_info} å¤±è´¥: {str(e)}"
                print(f"[ERROR] {error_msg}")
                if progress_callback:
                    progress_callback("é‡‡é›†å‡ºç°é”™è¯¯", progress_pct, error_msg)
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if batch_num < total_batches - 1:
                if progress_callback:
                    progress_callback("æ‰¹æ¬¡é—´ä¼‘æ¯...", progress_pct, f"{current_batch_info} å®Œæˆï¼Œä¼‘æ¯5ç§’åç»§ç»­...")
                print(f"\n[INFO] æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯ 5 ç§’åç»§ç»­...")
                time.sleep(5)
        
        if progress_callback:
            progress_callback("ä¸“é—¨åŒ–é‡‡é›†å®Œæˆ", 100, f"æ‰€æœ‰ {total_batches} æ‰¹æ¬¡ä¸“é—¨åŒ–æ•°æ®é‡‡é›†å®Œæˆï¼")
        
        print(f"\n[SUCCESS] æ‰€æœ‰æ‰¹æ¬¡ä¸“é—¨åŒ–æ•°æ®é‡‡é›†å®Œæˆï¼")
    
    def run_batch_collection(self, batch_size: int = 15, total_batches: int = 166, exclude_st: bool = True):
        """è¿è¡Œä¸“é—¨åŒ–æ•°æ®æºåˆ†é…æ‰¹é‡é‡‡é›†"""
        print(f"[INFO] å¼€å§‹ä¸“é—¨åŒ–æ•°æ®æºåˆ†é…æ‰¹é‡é‡‡é›† (æ¯æ‰¹ {batch_size} åªè‚¡ç¥¨ï¼Œå…± {total_batches} æ‰¹)")
        print(f"[INFO] ä¼˜åŒ–ç­–ç•¥: æ¯ä¸ªAPIä¸“æ³¨å…¶ä¸“é•¿é¢†åŸŸï¼Œæ™ºèƒ½æ‰¹é‡ï¼Œé¢‘æ¬¡æ§åˆ¶")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆåªåŒ…å«ä¸»æ¿è‚¡ç¥¨ï¼‰
        all_codes = self.get_stock_list_excluding_cyb(limit=batch_size * total_batches)
        
        # ğŸ”´ é¢„è¿‡æ»¤ï¼šæ’é™¤ ST å’Œ åœç‰Œè‚¡ç¥¨
        if self.status_checker:
            print(f"[INFO] æ­£åœ¨æ£€æŸ¥ {len(all_codes)} åªè‚¡ç¥¨çš„çŠ¶æ€ (ST/åœç‰Œ)...")
            if self.status_checker.update_status():
                # è¿‡æ»¤ä»£ç åˆ—è¡¨
                all_codes = self.status_checker.filter_codes(all_codes, exclude_st=exclude_st, exclude_suspended=True)
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = start_idx + batch_size
            batch_codes = all_codes[start_idx:end_idx]
            
            if not batch_codes:
                break
            
            print(f"\n{'='*50}")
            print(f"ç¬¬ {batch_num + 1} æ‰¹ / å…± {total_batches} æ‰¹ (ä¸“é—¨åŒ–ç­–ç•¥)")
            print(f"è‚¡ç¥¨ä»£ç : {', '.join(batch_codes)}")
            print(f"{'='*50}")
            
            # é‡‡é›†æ•°æ®
            batch_data = self.collect_comprehensive_data(batch_codes, batch_size, exclude_st=exclude_st)
            
            # ä¿å­˜æ•°æ®
            self.save_data(batch_data)
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if batch_num < total_batches - 1:
                print(f"\n[INFO] æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯ 5 ç§’åç»§ç»­...")
                time.sleep(5)
        
        print(f"\n[SUCCESS] æ‰€æœ‰æ‰¹æ¬¡ä¸“é—¨åŒ–æ•°æ®é‡‡é›†å®Œæˆï¼")
    
    def _update_kline_status_file(self, data_dir: str, stock_data: Dict[str, Any]) -> None:
        """æ›´æ–°Kçº¿çŠ¶æ€æ–‡ä»¶ï¼Œè®°å½•å®é™…Kçº¿æ•°æ®çš„æœ€æ–°æ—¥æœŸ"""
        try:
            from datetime import datetime

            # ä»è‚¡ç¥¨æ•°æ®ä¸­æå–æœ€æ–°Kçº¿æ—¥æœŸ
            latest_kline_date = None
            
            for code, info in stock_data.items():
                try:
                    kline = info.get('kline_data', {})
                    daily = kline.get('daily', []) if isinstance(kline, dict) else []
                    
                    if daily and len(daily) > 0:
                        # éå†æ‰€æœ‰Kçº¿ï¼Œæ‰¾åˆ°çœŸæ­£çš„æœ€æ–°æ—¥æœŸï¼ˆé˜²æ­¢æ’åºé”™è¯¯ï¼‰
                        for item in daily:
                            date_str = item.get('date', item.get('trade_date', ''))
                            if not date_str:
                                continue
                                
                            # ç»Ÿä¸€æ ¼å¼ï¼š20251218 æˆ– 2025-12-18 00:00:00 -> 2025-12-18
                            temp_date = str(date_str).split(' ')[0].replace('-', '').replace('/', '')
                            if len(temp_date) >= 8:
                                formatted_date = f"{temp_date[:4]}-{temp_date[4:6]}-{temp_date[6:8]}"
                                
                                # æ¯”è¾ƒæ‰¾åˆ°æœ€æ–°çš„
                                if latest_kline_date is None or formatted_date > latest_kline_date:
                                    latest_kline_date = formatted_date
                except:
                    continue
            
            # å¦‚æœæ‰¾åˆ°äº†Kçº¿æ—¥æœŸï¼Œæ›´æ–°çŠ¶æ€æ–‡ä»¶
            if latest_kline_date:
                status_file = os.path.join(data_dir, "kline_update_status.json")
                
                # ğŸ”´ æ”¹è¿›ï¼šè¯»å–ç°æœ‰çŠ¶æ€ï¼Œç¡®ä¿æ—¥æœŸåªå¢ä¸å‡
                if os.path.exists(status_file):
                    try:
                        with open(status_file, 'r', encoding='utf-8') as f:
                            old_status = json.load(f)
                            old_date = old_status.get('last_update_date', '')
                            if old_date and old_date > latest_kline_date:
                                print(f"[INFO] çŠ¶æ€æ–‡ä»¶æ—¥æœŸ {old_date} æ™šäºå½“å‰æ‰¹æ¬¡æ—¥æœŸ {latest_kline_date}ï¼Œä¿æŒåŸæ ·")
                                latest_kline_date = old_date
                    except:
                        pass

                status_data = {
                    'last_update_date': latest_kline_date,
                    'last_update_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'update_type': 'comprehensive',  # å…¨é‡æ•°æ®æ›´æ–°
                    'data_source': 'comprehensive_data_collector'
                }
                
                with open(status_file, 'w', encoding='utf-8') as f:
                    json.dump(status_data, f, ensure_ascii=False, indent=2)
                
                print(f"[INFO] Kçº¿çŠ¶æ€å·²æ›´æ–°: {latest_kline_date}")
        except Exception as e:
            print(f"[WARN] æ›´æ–°Kçº¿çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - ä¸“é—¨åŒ–æ•°æ®æºåˆ†é…æ‰¹é‡å¤„ç†æ¨¡å¼"""
    collector = ComprehensiveDataCollector()
    
    print("Aè‚¡å…¨é¢æ•°æ®é‡‡é›†å™¨ - ä¸“é—¨åŒ–APIåˆ†é…ç­–ç•¥")
    print("=" * 60)
    print("é…ç½®: æ¯æ‰¹15åªè‚¡ç¥¨ï¼Œä¸“é—¨åŒ–æ•°æ®æºåˆ†é…")
    print("æ•°æ®æºåˆ†é…ç­–ç•¥:")
    print("  â€¢ Kçº¿æ•°æ®: Tushare â†” AKShareè½®æ¢ â†’ JoinQuant â†’ Alpha Vantage")
    print("  â€¢ åŸºç¡€ä¿¡æ¯: Baostockä¸“ä¸š â†’ Tencentå®æ—¶ â†’ AKShareå…œåº•")
    print("  â€¢ è´¢åŠ¡æ•°æ®: BaostockåŸºæœ¬é¢ â†’ YFinanceä¼°å€¼ â†’ Tencent â†’ AKShare")
    print("  â€¢ è¡Œä¸šæ¦‚å¿µ: Baostockæ ‡å‡†åˆ†ç±» â†’ AKShareæ¦‚å¿µçƒ­ç‚¹")
    print("  â€¢ èµ„é‡‘æµå‘: Tencentå®æ—¶æµå‘ â†’ AKShareä¸ªè‚¡èµ„é‡‘")
    print("  â€¢ æ–°é—»å…¬å‘Š: AKShareå®æ—¶æ”¶é›†")
    print("=" * 60)
    
    # ä½¿ç”¨ä¸“é—¨åŒ–æ‰¹é‡å¤„ç†ï¼Œæ¯æ‰¹15åª
    try:
        collector.run_batch_collection(batch_size=15, total_batches=80)
    except KeyboardInterrupt:
        print("\n[INFO] ç”¨æˆ·ä¸­æ–­é‡‡é›†")
    except Exception as e:
        print(f"\n[ERROR] é‡‡é›†è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()